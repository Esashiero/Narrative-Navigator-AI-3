Codebase Analysis for: .

Directory Structure:
└── .
    ├── ._codebase_digest.txt
    ├── backend
    │   ├── audio_capture.py
    │   ├── chat_agent.py
    │   ├── llm_processing.py
    │   ├── transcription.py
    │   └── web_search.py
    ├── constants.py
    ├── frontend
    │   └── main_window.py
    ├── llm_prompts.py
    ├── main.py
    └── style.qss

Summary:
Total files analyzed: 11
Total directories analyzed: 2
Estimated output size: 177.80 KB
Actual analyzed size: 175.75 KB
Total tokens: 38009
Actual text content size: 172.11 KB

File Contents:

==================================================
File: .\._codebase_digest.txt
==================================================
Codebase Analysis for: .

Directory Structure:
└── .
    ├── backend
    │   ├── audio_capture.py
    │   ├── chat_agent.py
    │   ├── llm_processing.py
    │   ├── transcription.py
    │   └── web_search.py
    ├── constants.py
    ├── frontend
    │   └── main_window.py
    ├── llm_prompts.py
    ├── main.py
    └── style.qss

Summary:
Total files analyzed: 10
Total directories analyzed: 2
Estimated output size: 88.85 KB
Actual analyzed size: 86.90 KB
Total tokens: 18859
Actual text content size: 85.15 KB

File Contents:

==================================================
File: .\backend\audio_capture.py
==================================================
import sys
import numpy as np
import sounddevice as sd
import queue
import threading
from PyQt5.QtCore import QThread, pyqtSignal
from constants import TRANSCRIPT_CHUNK_DURATION_SECONDS # Not directly used here, but good practice to keep context

class AudioCaptureThread(QThread):
    audio_data = pyqtSignal(np.ndarray)
    error_signal = pyqtSignal(str)

    def __init__(self, device_id=3, samplerate=16000):
        super().__init__()
        self.device_id = device_id
        self.samplerate = samplerate
        self._running = False
        self._stop_event = threading.Event()
        self.audio_queue = queue.Queue()

    def run(self):
        self._running = True
        self._stop_event.clear()

        def callback(indata, frames, time_info, status):
            if status:
                pass
            if self._running:
                self.audio_queue.put(indata.copy())

        try:
            devices = sd.query_devices()
            if self.device_id >= len(devices):
                raise ValueError(f"Device ID {self.device_id} is out of range. Available devices: {len(devices)}")
            device_info = sd.query_devices(self.device_id)
            if device_info['max_input_channels'] < 1:
                raise ValueError(f"Device {self.device_id} does not support audio input")
            
            with sd.InputStream(samplerate=self.samplerate,
                              device=self.device_id,
                              channels=1,
                              callback=callback):
                while self._running:
                    try:
                        audio_chunk = self.audio_queue.get(timeout=0.1)
                        self.audio_data.emit(audio_chunk)
                    except queue.Empty:
                        if self._stop_event.is_set():
                            break
        except Exception as e:
            error_msg = f"Audio Capture Critical Error: {str(e)}"
            if "device" in str(e).lower():
                error_msg += f"\nAvailable audio devices:\n"
                for i, dev in enumerate(sd.query_devices()):
                    if dev['max_input_channels'] > 0:
                        error_msg += f"ID {i}: {dev['name']}\n"
            self.error_signal.emit(error_msg)
            print(error_msg, file=sys.stderr)
        finally:
            self._running = False
            while not self.audio_queue.empty():
                try:
                    self.audio_queue.get_nowait()
                except queue.Empty:
                    break

    def stop(self):
        self._running = False
        self._stop_event.set()

==================================================
File: .\backend\chat_agent.py
==================================================
import json
import queue
import time
import ollama
from PyQt5.QtCore import QThread, pyqtSignal

class ChatThread(QThread):
    chat_response = pyqtSignal(str)
    chat_log = pyqtSignal(dict) 

    def __init__(self, transcript_getter, entities_getter, content_title, external_context):
        super().__init__()
        self.chat_queue = queue.Queue()
        self.running = False
        self.transcript_getter = transcript_getter
        self.entities_getter = entities_getter
        self.content_title = content_title
        self.external_context = external_context

        self.system_prompt = """
You are an AI assistant helping a user understand a story by answering questions based on the transcript history and a narrative cheat sheet.

The content is titled: "{content_title}".
External context about the content:
---
{external_context}
---

Answer user questions using the provided transcript history and cheat sheet. Provide concise, relevant answers in plain text.
""".format(content_title=self.content_title, external_context=self.external_context)

    def add_chat_query(self, query):
        self.chat_queue.put(query)

    def run(self):
        self.running = True
        while self.running:
            try:
                query = self.chat_queue.get_nowait()
                transcripts = self.transcript_getter()
                recent_transcripts = transcripts[-5:] if len(transcripts) > 5 else transcripts
                current_entities = self.entities_getter()
                current_entities_json = json.dumps(current_entities, indent=2)

                messages = [
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content":
                     f"Transcript history: {recent_transcripts}\n"
                     f"Current narrative cheat sheet: {current_entities_json}\n"
                     f"User question: {query}"}
                ]
                self.chat_log.emit({"type": "chat_prompt", "message": "Chat prompt sent:", "data": messages})
                try:
                    response = ollama.chat(model="llama3.2:latest", messages=messages, stream=False)
                    content = response['message']['content']
                    self.chat_response.emit(content)
                    self.chat_log.emit({"type": "chat_response", "message": "Chat response received.", "data": content})
                except Exception as e:
                    self.chat_response.emit(f"Error: Unable to process query - {str(e)}")
                    self.chat_log.emit({"type": "error", "message": f"Chat Error: {str(e)}"})
            except queue.Empty:
                pass
            time.sleep(0.5)

    def stop(self):
        self.running = False

==================================================
File: .\backend\llm_processing.py
==================================================
import json
import re
import threading
import time
import ollama
from PyQt5.QtCore import QThread, pyqtSignal
from constants import TRANSCRIPT_CHUNK_DURATION_SECONDS
from llm_prompts import base_system_prompt

# Define the JSON schema for the expected entity output format
entity_list_schema = {
    "type": "object",
    "properties": {
        "entities": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "name": {
                        "type": "string"
                    },
                    "type": {
                        "type": "string"
                    },
                    "description": {
                        "type": "string"
                    },
                    "base_importance_score": {
                        "type": "integer",
                        "minimum": 1,
                        "maximum": 10
                    }
                },
                "required": [
                    "name",
                    "type",
                    "description",
                    "base_importance_score"
                ]
            }
        }
    },
    "required": [
        "entities"
    ]
}

class LLMThread(QThread):
    llm_log = pyqtSignal(dict) 
    entities_updated = pyqtSignal(list)

    def __init__(self):
        super().__init__()
        try:
            self.model = "llama3.2:latest"
            ollama.chat(model=self.model, messages=[{"role": "user", "content": "hi"}], stream=False)
        except Exception as e:
            self.llm_log.emit({"type": "error", "message": f"Failed to connect to Ollama or model '{self.model}' not found: {e}"})
            self.model = None

        self.transcriptions = []
        self.entities = [] 
        self.running = False
        self.external_context = ""
        self.content_title = "Unknown Content"

        self.base_system_prompt_template = base_system_prompt
        # Debug prints to inspect template and formatted string
        print(f"DEBUG: Initializing LLMThread")
        print(f"DEBUG: base_system_prompt_template (first 500 chars):\n{self.base_system_prompt_template[:500]}...")
        print(f"DEBUG: Keys provided for initial format: content_title='{self.content_title}', external_context='No external context loaded yet...'")
        # Format the system prompt with only the expected keys
        self.system_prompt = self.base_system_prompt_template.format(
            content_title=self.content_title,
            external_context="No external context loaded yet. Please wait for the application to gather information."
        )
        print(f"DEBUG: Formatted self.system_prompt (first 500 chars):\n{self.system_prompt[:500]}...")
        self.last_transcript_processed_idx = -1
        
        self.VALID_ENTITY_TYPES = ["Characters", "Locations", "Organizations", "Key Objects", "Concepts/Events"]

    def set_content_title(self, title):
        self.content_title = title
        self._update_system_prompt()

    def set_external_context(self, context):
        self.external_context = context
        self._update_system_prompt()

    def _update_system_prompt(self):
        # Debug prints to inspect template and formatted string
        print(f"DEBUG: Updating system prompt")
        print(f"DEBUG: base_system_prompt_template (first 500 chars):\n{self.base_system_prompt_template[:500]}...")
        print(f"DEBUG: Keys provided for update format: content_title='{self.content_title}', external_context='{self.external_context[:50]}...'")
        self.system_prompt = self.base_system_prompt_template.format(
            content_title=self.content_title,
            external_context=self.external_context
        )
        print(f"DEBUG: Formatted self.system_prompt (first 500 chars):\n{self.system_prompt[:500]}...")
    
    def _normalize_entity_type(self, type_str):
        """Normalizes LLM output type strings to our canonical types."""
        if not type_str:
            return None
        type_str_lower = type_str.lower().strip()
        
        # Handle compound types by splitting and taking the first part as a primary hint
        if ',' in type_str_lower:
            type_str_lower = type_str_lower.split(',')[0].strip()
        
        # Explicitly handle combined types or singular/plural mismatches from LLM
        if type_str_lower == "concept/event":
            return "Concepts/Events"
        if type_str_lower == "locations/organizations":
            # Heuristic: if a place name, it's probably a location first.
            # We'll normalize name separately, and use the normalized name to guide this
            # For "USA" or "United States" cases, "Locations" is more appropriate.
            return "Locations" # Default to Locations for this combo
        
        # Handle new combined type seen in logs
        if type_str_lower == "locations/concepts/events":
            return "Locations" # Defaulting based on observed example ('Marines')
        
        if type_str_lower in ["characters", "characters/individuals", "character", "individual"]:
            return "Characters"
        elif type_str_lower in ["locations", "location", "countries", "country", "cities", "city", "places", "place"]:
            return "Locations"
        elif type_str_lower in ["organizations", "organization", "agencies", "agency", "governments", "government", "corporations", "corporation", "groups", "group", "factions", "faction", "allies", "powers"]:
            return "Organizations"
        elif type_str_lower in ["key objects", "key object", "objects", "object", "artifacts", "artifact", "weapons", "weapon"]:
            return "Key Objects"
        elif type_str_lower in ["concepts/events", "concepts", "concept", "events", "event", "historical events", "dates", "years", "periods", "period", "projects", "programs", "wars", "conflicts", "eras", "era", "ages", "age", "campaigns", "campaign"]:
            return "Concepts/Events"
        return None

    def _normalize_for_comparison(self, name):
        """
        Normalizes entity names for robust comparison and deduplication.
        Includes a very comprehensive mapping for common synonyms, acronyms, and known typos/variations.
        The goal is to map various inputs to a single, canonical string.
        """
        name_lower = name.lower().strip()

        # Comprehensive canonical mapping
        canonical_map = {
            # Characters
            "easterman": "hendrick joliet easterman",
            "eastman": "hendrick joliet easterman",
            "hendrick joliet easterman": "hendrick joliet easterman",
            "wernick": "rudolf gustav wernicke",
            "wernicke": "rudolf gustav wernicke",
            "rudolf gustav wernicke": "rudolf gustav wernicke",
            "jameson lawler": "jameson lawler",
            "jameson lawler (cia agent)": "jameson lawler",
            "abe bradley aviano": "abe bradley aviano",
            "abe bradley aviano's": "abe bradley aviano", # Possessive
            "stalin": "joseph stalin",
            "joseph stalin": "joseph stalin",
            "truman": "harry s truman",
            "harry s truman": "harry s truman",
            "billy": "billy", # The Outlast character
            "miles": "miles", # The Outlast character
            "hope": "hope", # The Outlast character
            "mother gooseberry": "mother gooseberry",

            # Locations
            "us": "united states",
            "usa": "united states",
            "united states": "united states",
            "united states (usa)": "united states",
            "united states of america": "united states",
            "the usa": "united states",
            "e usa (united states)": "united states", # From screenshot
            "los alamos": "los alamos",
            "los alamos national laboratory": "los alamos",
            "hong kong": "hong kong",
            "hiroshima": "hiroshima",
            "nagasaki": "nagasaki",
            "poland": "poland",
            "germany": "germany",
            "italy": "italy",
            "japan": "japan",
            "soviet union": "union of soviet socialist republics", # Map to full name
            "chicago": "chicago",
            "eniwetok atoll": "eniwetok atoll",
            "enno atoq atoll": "eniwetok atoll", # Typo from transcript
            "mount massive asylum": "mount massive asylum",

            # Organizations
            "ussr": "union of soviet socialist republics",
            "union of soviet socialist republics": "union of soviet socialist republics",
            "oss": "office of strategic services",
            "office of strategic services": "office of strategic services",
            "cia": "central intelligence agency",
            "central intelligence agency": "central intelligence agency",
            "nazi germany": "nazi germany",
            "kingdom of italy": "kingdom of italy",
            "empire of japan": "empire of japan",
            "murkoff corporation": "murkoff corporation",
            "murkov corporation": "murkoff corporation", # Typo from transcript
            "red barrels": "red barrels", # Game developer
            "axis powers": "axis powers",
            "korean people's army": "korean people's army",

            # Key Objects
            "atomic bomb": "atomic bomb",
            "hydrogen bomb": "hydrogen bomb",
            "walrider": "walrider",
            "lsd": "lsd",

            # Concepts/Events
            "cold war": "cold war era",
            "cold war era": "cold war era",
            "1939": "1939",
            "1945": "1945",
            "1947": "1947",
            "1949": "1949",
            "1951": "1951",
            "1953": "1953",
            "world war ii": "world war ii",
            "second world war": "world war ii",
            "nuclear age": "nuclear age",
            "arms race": "arms race",
            "operation paperclip": "operation paperclip",
            "project bluebird": "project bluebird",
            "project artichoke": "project artichoke",
            "project bluebird, project artichoke (cia projects)": "project bluebird", # Pick one as primary, description can be combined later
            "project bluebird, project artichoke": "project bluebird",
            "space race": "space race",
            "the outlast trials": "the outlast trials", # Canonical game title
            "the outlast trials video games": "the outlast trials",
            "outlast trials game": "the outlast trials",
            "season 1 of the outlast trials": "season 1 of the outlast trials", # Canonical season name
            "season 1 of the trials": "season 1 of the outlast trials", # Shorter form
            "season 2 of the outlast series": "season 2 of the outlast series", # Canonical season name
            "season 2 of the outlast": "season 2 of the outlast series", # Shorter form
            "season 2": "season 2 of the outlast series", # Maps to full season
            "korean war": "korean war",
        }
        
        # Check for direct map first
        if name_lower in canonical_map:
            return canonical_map[name_lower]

        # Attempt to clean further if not directly mapped.
        # This is a fallback and less reliable than explicit mappings.
        cleaned_name = re.sub(r'\s*\([^)]*\)', '', name_lower).strip() # remove parenthesized text (e.g., "(US)")
        for article in ['the ', 'a ', 'an ']:
            if cleaned_name.startswith(article):
                cleaned_name = cleaned_name[len(article):].strip()
        cleaned_name = re.sub(r"'s\b", '', cleaned_name).strip() # remove 's at end of word
        cleaned_name = re.sub(r"s'\b", 's', cleaned_name).strip() # remove s' at end of word
        cleaned_name = re.sub(r'[^a-z0-9\s]', '', cleaned_name).strip() # remove non-alphanumeric (keep spaces)
        cleaned_name = re.sub(r'\s+', ' ', cleaned_name).strip() # reduce multiple spaces

        # After cleaning, check if it now matches a canonical form
        if cleaned_name in canonical_map:
            return canonical_map[cleaned_name]

        return cleaned_name # Return cleaned name if no canonical mapping is found

    def _normalize_for_mention_check(self, text):
        """
        More aggressive normalization for checking mentions in raw text.
        Converts to lowercase, removes most punctuation, handles common plural/possessive endings.
        """
        text = text.lower()
        text = re.sub(r"['’]\s*s?\b", '', text) # Handles 's and s' (e.g., 'character's' or 'characters')
        text = re.sub(r'[^a-z0-9\s]', ' ', text) # Replace non-alphanumeric with space
        text = re.sub(r'\s+', ' ', text).strip() # Reduce multiple spaces to single space
        return text

    def _is_similar_entity(self, entity1, entity2):
        """
        Compares two entity dicts for similarity based on normalized name and canonical type.
        This function is crucial for internal deduplication.
        """
        type1 = self._normalize_entity_type(entity1.get("type", ""))
        type2 = entity2.get("type", "") 
        
        if type1 != type2 or type1 is None:
            return False
            
        name1_norm = self._normalize_for_comparison(entity1["name"])
        name2_norm = self._normalize_for_comparison(entity2["name"])
        return name1_norm == name2_norm

    def _update_importance_from_transcript(self, transcript_text):
        """
        Increments mention_count for existing entities found in the new transcript.
        Uses canonical names for matching to handle variations/typos.
        """
        normalized_transcript = self._normalize_for_mention_check(transcript_text)
        
        for entity in self.entities:
            # Get the canonical name of the *existing* entity for matching
            entity_canonical_name = self._normalize_for_comparison(entity["name"]) 
            
            # Prepare a regex pattern for the canonical name, ensuring whole word match
            # re.escape is important if entity name contains special regex characters
            pattern = r'\b' + re.escape(entity_canonical_name) + r'\b'
            
            if re.search(pattern, normalized_transcript):
                entity["mention_count"] += 1
                self.llm_log.emit({"type": "debug", "message": f"Entity '{entity['name']}' (canonical: '{entity_canonical_name}') ({entity['type']}) mention_count incremented to {entity['mention_count']}"})

    def run(self):
        self.running = True
        if self.model is None:
            self.llm_log.emit({"type": "error", "message": "LLM model not loaded, cannot process entities."})
            self.running = False
            return

        if not self.external_context:
            self.llm_log.emit({"type": "status", "message": "LLM Thread waiting for external context..."})
            while self.running and not self.external_context:
                time.sleep(1)
            if not self.running:
                return

        self.llm_log.emit({"type": "status", "message": "LLM Thread started with external context."})
        while self.running:
            if len(self.transcriptions) > self.last_transcript_processed_idx + 1:
                transcript_to_process = self.transcriptions[self.last_transcript_processed_idx + 1] # Process the next unprocessed transcript
                current_transcript_idx = self.last_transcript_processed_idx + 1 
                
                # Take recent transcripts for better context for LLM
                # Use a sliding window of the last 5 transcripts (including current)
                recent_transcripts = self.transcriptions[max(0, current_transcript_idx - 4):current_transcript_idx + 1]
                
                current_entities_for_llm_prompt = [
                    {"name": e["name"], "type": e["type"], "description": e["description"]}
                    for e in self.entities
                ]

                messages = [
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content":
                     f"Current transcript snippet: {transcript_to_process}\n"
                     f"Recent context (last {len(recent_transcripts)} snippets): {recent_transcripts}\n"
                     f"Current narrative cheat sheet: {json.dumps(current_entities_for_llm_prompt, indent=2)}\n"
                     f"Based on ALL information (current transcript, recent context, full cheat sheet), identify *all identifiable* entities. For EVERY entity you return (new or existing), provide its 'base_importance_score' (1-10) re-evaluated based on its inherent narrative relevance. Remember to include historical dates/years and specific organizations like OSS if mentioned. Ensure to correctly categorize and canonicalize names like 'Easterman'/'Eastman' to 'Hendrick Joliet Easterman', 'Wernick'/'Wernicke' to 'Rudolf Gustav Wernicke', and 'Operation Paperclip'."}
                ]
                self.llm_log.emit({"type": "prompt", "message": f"Prompt for transcript index {current_transcript_idx}", "data": messages})
                
                llm_identified_entities = []
                raw_content_from_llm = ""
                try:
                    response = ollama.chat(
                        model=self.model,
                        messages=messages,
                        stream=False,
                        # Use the new format parameter to enforce JSON schema
                        format=entity_list_schema, # Pass the schema dictionary here
                        options={
                            "temperature": 0.1, # Keep low for deterministic output
                            "top_p": 0.9,       # Keep relatively high
                            "top_k": 40,        # Default is fine
                            "repeat_penalty": 1.0 # Avoid penalizing repeated keys
                        } # Keep these options for output quality
                    )
                    raw_content_from_llm = response['message']['content']
                    self.llm_log.emit({"type": "raw_response", "message": f"Raw LLM response for transcript index {current_transcript_idx}", "data": raw_content_from_llm})

                    # --- Robust JSON Parsing ---
                    parsed_llm_output = None
                    json_string_to_parse = ""

                    try:
                        # Attempt 1: Try to parse directly (most common good case)
                        try:
                            json_string_to_parse = raw_content_from_llm.strip()
                            parsed_llm_output = json.loads(json_string_to_parse)
                        except json.JSONDecodeError:
                            # Attempt 2: Search for a JSON block (e.g., if wrapped in markdown)
                            json_match = re.search(r"```json\s*(.*?)\s*```", raw_content_from_llm, re.DOTALL)
                            if json_match:
                                json_string_to_parse = json_match.group(1).strip()
                                parsed_llm_output = json.loads(json_string_to_parse)
                            else:
                                # Attempt 3: Search for the first valid JSON object (from first { to last })
                                json_match_loose = re.search(r"\{.*\}", raw_content_from_llm, re.DOTALL)
                                if json_match_loose:
                                    json_string_to_parse = json_match_loose.group(0).strip()
                                    parsed_llm_output = json.loads(json_string_to_parse)
                                else:
                                    # Attempt 4: Search for the first valid JSON array (from first [ to last ])
                                    json_match_array_loose = re.search(r"\[.*\]", raw_content_from_llm, re.DOTALL)
                                    if json_match_array_loose:
                                        json_string_to_parse = json_match_array_loose.group(0).strip()
                                        parsed_llm_output = json.loads(json_string_to_parse)
                                    else:
                                        raise json.JSONDecodeError("No recognizable JSON structure found.", raw_content_from_llm, 0)

                    except (json.JSONDecodeError, ValueError) as e:
                        # Handle JSON parsing and structure errors
                        self.llm_log.emit({"type": "error", "message": f"JSON parsing/structure error: {str(e)}\nAttempted to parse:\n{json_string_to_parse if json_string_to_parse else raw_content_from_llm}", "data": raw_content_from_llm})
                        # Proceed with an empty entities list to avoid crashing
                        llm_identified_entities = []
                    except Exception as e:
                        # Handle other potential errors during the LLM call or processing
                        self.llm_log.emit({"type": "error", "message": f"LLM processing failed: {str(e)}"})
                        llm_identified_entities = [] # Ensure it's always a list

                    # Now process the parsed_llm_output
                    if parsed_llm_output is None:
                        self.llm_log.emit({"type": "warning", "message": f"JSON parsing attempts found no valid structure.\nAttempted to parse:\n{raw_content_from_llm}", "data": raw_content_from_llm})
                        llm_identified_entities = [] # Ensure empty list if nothing was parsed
                    elif isinstance(parsed_llm_output, list):
                        # LLM sometimes returns a list of entities directly instead of {"entities": [...]}
                        llm_identified_entities = parsed_llm_output
                    elif isinstance(parsed_llm_output, dict) and 'entities' in parsed_llm_output:
                        llm_identified_entities = parsed_llm_output.get('entities', [])
                    else:
                        raise ValueError(f"Unexpected JSON structure after parsing: {type(parsed_llm_output)} - {json_string_to_parse}")

                    if not isinstance(llm_identified_entities, list):
                        raise ValueError("Expected 'entities' to be a list after parsing.")
                            
                    self.llm_log.emit({"type": "parsed_entities", "message": f"Parsed entities from LLM for transcript index {current_transcript_idx}", "data": llm_identified_entities})

                except (json.JSONDecodeError, ValueError) as e:
                    self.llm_log.emit({"type": "error", "message": f"JSON parsing error: {str(e)}\nAttempted to parse:\n{json_string_to_parse if json_string_to_parse else raw_content_from_llm}", "data": raw_content_from_llm})
                    # Continue with empty entities list if parsing fails, but log the issue
                    llm_identified_entities = []
                except Exception as e:
                    self.llm_log.emit({"type": "error", "message": f"LLM request failed: {str(e)}"})
                    llm_identified_entities = [] # Ensure it's always a list

                # --- Entity Reconciliation and Update ---
                temp_entities_dict = {}
                for e in self.entities:
                    # Use the canonical name and type as the primary key for existing entities
                    normalized_name = self._normalize_for_comparison(e["name"])
                    temp_entities_dict[(normalized_name, e["type"])] = e

                for llm_entity_data in llm_identified_entities:
                    name = llm_entity_data.get("name")
                    raw_type = llm_entity_data.get("type")
                    description = llm_entity_data.get("description")
                    base_importance_score = llm_entity_data.get("base_importance_score")

                    canonical_type = self._normalize_entity_type(raw_type)
                    if canonical_type is None:
                        self.llm_log.emit({"type": "warning", "message": f"Skipping entity with unrecognized type '{raw_type}'.", "entity_data": llm_entity_data})
                        continue
                    type_ = canonical_type

                    if not name:
                        self.llm_log.emit({"type": "warning", "message": f"Skipping invalid entity from LLM (missing name).", "entity_data": llm_entity_data})
                        continue
                    
                    # Ensure base_importance_score is an int within range
                    if not isinstance(base_importance_score, int) or not (1 <= base_importance_score <= 10):
                        self.llm_log.emit({"type": "warning", "message": f"Invalid base_importance_score for '{name}'. Defaulting to 1.", "entity_data": llm_entity_data})
                        base_importance_score = 1

                    # Use the normalized LLM-provided name and canonical type as the key for lookup
                    normalized_key_for_llm_entity = (self._normalize_for_comparison(name), type_)
                    existing_entity = temp_entities_dict.get(normalized_key_for_llm_entity)

                    if existing_entity:
                        # Update existing entity
                        existing_entity["description"] = description if description else existing_entity["description"]
                        
                        # Prioritize update if new name is more complete or has better casing
                        # Only update if the normalized names are the same (already guaranteed by normalized_key)
                        current_normalized_name = self._normalize_for_comparison(existing_entity["name"])
                        new_normalized_name = self._normalize_for_comparison(name)

                        if current_normalized_name == new_normalized_name:
                            # Heuristic: Prefer longer name (more complete) or better casing
                            if len(name) > len(existing_entity["name"]) or \
                               (name and name[0].isupper() and not (existing_entity["name"] and existing_entity["name"][0].isupper())):
                                existing_entity["name"] = name # Update to the better raw name
                        
                        existing_entity["base_importance_score"] = base_importance_score
                        # mention_count is NOT incremented here; it's done by _update_importance_from_transcript
                    else:
                        # Add new entity
                        new_entity = {
                            "name": name,
                            "type": type_, # Use canonical type
                            "description": description if description else "",
                            "base_importance_score": base_importance_score,
                            "mention_count": 0, # Initialize to 0, will be updated by _update_importance_from_transcript later
                            "first_mentioned_idx": current_transcript_idx
                        }
                        temp_entities_dict[normalized_key_for_llm_entity] = new_entity
                
                self.entities = list(temp_entities_dict.values())
                # Now that the entities list is updated, trigger mention count update for the *current* transcript.
                # This ensures any newly identified entities in this round get their first mention counted,
                # and existing entities also get their count incremented if mentioned.
                self._update_importance_from_transcript(transcript_to_process)
                
                self.entities_updated.emit(self.entities)
                self.last_transcript_processed_idx = current_transcript_idx # Mark this index as processed

            time.sleep(2) # Wait a bit before checking for next transcript

    def add_transcription(self, text):
        # Transcriptions are appended here, but processed sequentially in run()
        self.transcriptions.append(text) 

    def get_transcriptions(self):
        return self.transcriptions

    def get_entities(self):
        return self.entities

    def stop(self):
        self.running = False

==================================================
File: .\backend\transcription.py
==================================================
import numpy as np
import whisper
import threading
import time
import queue
from PyQt5.QtCore import QThread, pyqtSignal
from constants import TRANSCRIPT_CHUNK_DURATION_SECONDS

class TranscriptionThread(QThread):
    transcription = pyqtSignal(str)
    error_signal = pyqtSignal(str)

    def __init__(self):
        super().__init__()
        try:
            self.model = whisper.load_model("small.en")
        except Exception as e:
            self.error_signal.emit(f"Failed to load Whisper model: {e}")
            self.model = None

        self.audio_buffer = np.array([], dtype=np.float32)
        self.running = False
        self.buffer_lock = threading.Lock()
        self._stop_event = threading.Event()

    def run(self):
        self.running = True
        self._stop_event.clear()

        while self.running:
            audio_to_process = None
            with self.buffer_lock:
                if len(self.audio_buffer) >= 16000 * TRANSCRIPT_CHUNK_DURATION_SECONDS: 
                    audio_to_process = self.audio_buffer[:16000 * TRANSCRIPT_CHUNK_DURATION_SECONDS].copy()
                    self.audio_buffer = self.audio_buffer[16000 * TRANSCRIPT_CHUNK_DURATION_SECONDS:]
            
            if audio_to_process is not None:
                try:
                    if audio_to_process.dtype != np.float32:
                        audio_to_process = audio_to_process.astype(np.float32) / 32768.0

                    result = self.model.transcribe(audio_to_process, language="en")
                    if result["text"].strip():
                        self.transcription.emit(result["text"])
                except Exception as e:
                    self.error_signal.emit(f"Transcription Error: {e}")
                    # print(f"Transcription Error: {e}", file=sys.stderr) # Removed sys.stderr import
            time.sleep(0.1)
            if self._stop_event.is_set():
                break

    def add_audio(self, audio_data):
        with self.buffer_lock:
            if audio_data.dtype != np.float32:
                audio_data = audio_data.astype(np.float32) / 32768.0
            self.audio_buffer = np.append(self.audio_buffer, audio_data.flatten())

    def stop(self):
        self.running = False
        self._stop_event.set()

==================================================
File: .\backend\web_search.py
==================================================
import json # Not directly used but often helpful for debugging DDGS results
from duckduckgo_search import DDGS
from PyQt5.QtCore import QThread, pyqtSignal

class WebSearchThread(QThread):
    context_ready = pyqtSignal(str)
    error_signal = pyqtSignal(str)

    def __init__(self, title):
        super().__init__()
        self.title = title

    def run(self):
        try:
            search_query = f"{self.title} plot summary OR overview"
            with DDGS() as ddgs:
                results = list(ddgs.text(search_query, max_results=5))

            context_lines = []
            for r in results:
                if r.get('body'):
                    context_lines.append(f"- {r['title']}: {r['body']}")
                elif r.get('link'):
                    context_lines.append(f"- {r['title']} ({r['link']})")
            
            full_context = "\n".join(context_lines)

            if not full_context:
                self.error_signal.emit(f"Warning: No significant web context found for '{self.title}'. LLM may operate with limited external knowledge.")
                full_context = f"No specific plot context found for the content titled '{self.title}'."

            self.context_ready.emit(full_context)
        except Exception as e:
            self.error_signal.emit(f"Error during web search for '{self.title}': {str(e)}. LLM will operate without external context.")
            self.context_ready.emit(f"Web search failed. No external context provided for '{self.title}'.")

==================================================
File: .\constants.py
==================================================
# Constants for time calculation (approximate)
# This assumes the TranscriptionThread processes fixed 10-second chunks.
TRANSCRIPT_CHUNK_DURATION_SECONDS = 10

==================================================
File: .\frontend\main_window.py
==================================================
import sys
import json
import numpy as np
import time 
from datetime import datetime

from PyQt5.QtWidgets import (
    QMainWindow, QWidget, QVBoxLayout,
    QHBoxLayout, QPushButton, QTextEdit, QTableWidget,
    QTableWidgetItem, QInputDialog, QSplitter, QLineEdit,
    QLabel, QFrame, QTabWidget, QScrollArea, QSizePolicy,
    QApplication, QStyle
)
from PyQt5.QtCore import QThread, pyqtSignal, Qt, QSize
from PyQt5.QtGui import QIcon

from backend.audio_capture import AudioCaptureThread
from backend.transcription import TranscriptionThread
from backend.web_search import WebSearchThread
from backend.llm_processing import LLMThread
from backend.chat_agent import ChatThread
from constants import TRANSCRIPT_CHUNK_DURATION_SECONDS

class NarrativeNavigator(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Narrative Navigator AI")
        self.setGeometry(100, 100, 1200, 800)
        self.setMinimumSize(800, 600)

        self.audio_thread = AudioCaptureThread()
        self.transcription_thread = TranscriptionThread()
        self.llm_thread = LLMThread()
        self.chat_thread = None
        self.web_search_thread = None
        self.content_title = ""
        self.minimum_display_score = 3 
        
        self.cheat_sheet_column_widths = {} 

        self.init_ui()

        self.audio_thread.audio_data.connect(self.transcription_thread.add_audio)
        self.audio_thread.error_signal.connect(lambda msg: self.update_llm_log_tabs({"type": "error", "message": msg})) 
        self.transcription_thread.transcription.connect(self.handle_transcription)
        self.transcription_thread.error_signal.connect(lambda msg: self.update_llm_log_tabs({"type": "error", "message": msg}))
        self.llm_thread.entities_updated.connect(self.update_entity_displays) 
        self.llm_thread.llm_log.connect(self.update_llm_log_tabs)

        self.get_content_title_and_context()

    def init_ui(self):
        main_container = QWidget()
        self.setCentralWidget(main_container)
        main_layout = QVBoxLayout(main_container)
        main_layout.setContentsMargins(0, 0, 0, 0)
        main_layout.setSpacing(0)

        header_widget = QWidget()
        header_widget.setObjectName("headerWidget")
        header_layout = QHBoxLayout(header_widget)
        header_layout.setContentsMargins(20, 10, 20, 10)
        header_layout.setSpacing(15)

        app_logo = QLabel()
        app_logo.setPixmap(self.style().standardIcon(QStyle.SP_ComputerIcon).pixmap(QSize(32, 32)))
        
        app_name_label = QLabel("Narrative Navigator")
        app_name_label.setObjectName("appNameLabel")

        self.analysis_status_label = QLabel("Analyzing: [FULL] Beyond Boiling Point - Gordon Ramsay documentary (2000)")
        self.analysis_status_label.setObjectName("analysisStatusLabel")
        self.analysis_status_label.setAlignment(Qt.AlignLeft | Qt.AlignVCenter)
        self.analysis_status_label.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred)

        header_layout.addWidget(app_logo)
        header_layout.addWidget(app_name_label)
        header_layout.addWidget(self.analysis_status_label)

        self.volume_button = QPushButton()
        self.volume_button.setIcon(self.style().standardIcon(QStyle.SP_MediaVolume))
        self.volume_button.setObjectName("iconButton")
        self.volume_button.setIconSize(QSize(20, 20))
        self.volume_button.setFixedSize(36, 36)

        self.toggle_button = QPushButton("Stop Recording")
        self.toggle_button.setObjectName("stopRecordingButton")
        self.toggle_button.clicked.connect(self.toggle_processing)
        self.toggle_button.setEnabled(False)

        self.close_button = QPushButton()
        self.close_button.setIcon(self.style().standardIcon(QStyle.SP_DialogCloseButton))
        self.close_button.setObjectName("iconButton")
        self.close_button.setIconSize(QSize(20,20))
        self.close_button.setFixedSize(36,36)
        self.close_button.clicked.connect(self.close)

        header_layout.addWidget(self.volume_button)
        header_layout.addWidget(self.toggle_button)
        header_layout.addWidget(self.close_button)

        main_layout.addWidget(header_widget)

        content_splitter = QSplitter(Qt.Horizontal)
        content_splitter.setContentsMargins(10, 0, 10, 10) 

        self.tab_widget = QTabWidget()
        self.tab_widget.setObjectName("mainTabWidget")
        content_splitter.addWidget(self.tab_widget)

        self.overview_tab_page = self._create_overview_tab()
        self.story_elements_tab_page = self._create_story_elements_tab()
        self.live_transcript_tab_page = self._create_live_transcript_tab()
        self.ai_chat_tab_page = self._create_ai_chat_tab()
        self.llm_log_tab_page = self._create_llm_log_tab() 

        self.tab_widget.addTab(self.overview_tab_page, "Overview")
        self.tab_widget.addTab(self.story_elements_tab_page, "Story Elements")
        self.tab_widget.addTab(self.live_transcript_tab_page, "Live Transcript")
        self.tab_widget.addTab(self.ai_chat_tab_page, "AI Chat")
        self.tab_widget.addTab(self.llm_log_tab_page, "LLM Log")

        right_panel = QWidget()
        right_panel.setObjectName("rightPanel")
        right_layout = QVBoxLayout(right_panel)
        right_layout.setContentsMargins(15, 15, 15, 15)
        right_layout.setSpacing(10)

        cheat_sheet_label = QLabel("Narrative Cheat Sheet")
        cheat_sheet_label.setObjectName("sectionTitle") 
        right_layout.addWidget(cheat_sheet_label)

        self.cheat_sheet_table = QTableWidget() 
        self.cheat_sheet_table.setColumnCount(6)
        self.cheat_sheet_table.setHorizontalHeaderLabels(["Name", "Type", "Description", "Base Score", "Mentions", "Current Score"])
        self.cheat_sheet_table.setEditTriggers(QTableWidget.NoEditTriggers)
        self.cheat_sheet_table.verticalHeader().setVisible(False)
        self.cheat_sheet_table.setAlternatingRowColors(True)
        self.cheat_sheet_table.setObjectName("cheatSheetTable") 
        right_layout.addWidget(self.cheat_sheet_table)

        self.cheat_sheet_column_widths = {
            0: 120,   # Name
            1: 100,   # Type
            2: 250,   # Description
            3: 80,    # Base Score
            4: 70,    # Mentions
            5: 100    # Current Score
        }
        for i, width in self.cheat_sheet_column_widths.items():
            self.cheat_sheet_table.setColumnWidth(i, width)

        self.cheat_sheet_table.horizontalHeader().sectionResized.connect(self._on_cheat_sheet_column_resized)

        content_splitter.addWidget(right_panel)
        content_splitter.setSizes([800, 400]) 
        main_layout.addWidget(content_splitter)

    def _on_cheat_sheet_column_resized(self, logicalIndex, oldSize, newSize):
        """Slot to remember user-resized column widths."""
        self.cheat_sheet_column_widths[logicalIndex] = newSize

    def _create_overview_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        title_label = QLabel("Overview")
        title_label.setObjectName("sectionTitle")
        tab_layout.addWidget(title_label)

        metrics_layout = QHBoxLayout()
        metrics_layout.setSpacing(15)
        
        self.characters_count_label = QLabel("0") 
        self.locations_count_label = QLabel("0") 
        self.transcript_lines_count_label = QLabel("0")
        self.total_elements_count_label = QLabel("0") 

        metrics_layout.addWidget(self._create_summary_card(self.characters_count_label, "Characters", QStyle.SP_MessageBoxInformation)) 
        metrics_layout.addWidget(self._create_summary_card(self.locations_count_label, "Locations", QStyle.SP_DirIcon)) 
        metrics_layout.addWidget(self._create_summary_card(self.transcript_lines_count_label, "Transcript Lines", QStyle.SP_FileIcon)) 
        metrics_layout.addWidget(self._create_summary_card(self.total_elements_count_label, "Total Elements", QStyle.SP_MessageBoxQuestion)) 
        tab_layout.addLayout(metrics_layout)

        recent_activity_widget = QFrame()
        recent_activity_widget.setProperty("class", "contentCard")
        recent_activity_layout = QVBoxLayout(recent_activity_widget)
        recent_activity_layout.setContentsMargins(15,15,15,15)
        recent_activity_layout.setSpacing(10)

        recent_activity_layout.addWidget(QLabel("Recent Activity"))
        self.recent_activity_display = QTextEdit()
        self.recent_activity_display.setReadOnly(True)
        self.recent_activity_display.setPlaceholderText("Latest story elements and transcript updates...")
        self.recent_activity_display.setFixedHeight(150)
        recent_activity_layout.addWidget(self.recent_activity_display)
        tab_layout.addWidget(recent_activity_widget)

        key_characters_widget = QFrame()
        key_characters_widget.setProperty("class", "contentCard")
        key_characters_layout = QVBoxLayout(key_characters_widget)
        key_characters_layout.setContentsMargins(15,15,15,15)
        key_characters_layout.setSpacing(10)
        
        key_characters_layout.addWidget(QLabel("Key Characters"))
        self.key_characters_container_layout = QVBoxLayout()
        self.key_characters_container_layout.setContentsMargins(0,0,0,0)
        self.key_characters_container_layout.setSpacing(8)
        
        self.key_characters_container_layout.addStretch() 

        key_characters_layout.addLayout(self.key_characters_container_layout)
        tab_layout.addWidget(key_characters_widget)

        tab_layout.addStretch() 
        return tab_page

    def _create_summary_card(self, count_label_ref, label_text, icon_style_hint):
        card = QFrame()
        card.setProperty("class", "contentCard")
        card.setFixedSize(160, 120)
        card_layout = QVBoxLayout(card)
        card_layout.setAlignment(Qt.AlignCenter)
        card_layout.setContentsMargins(10, 10, 10, 10)
        card_layout.setSpacing(5)

        icon_label = QLabel()
        icon_label.setPixmap(self.style().standardIcon(icon_style_hint).pixmap(QSize(30, 30)))
        card_layout.addWidget(icon_label, alignment=Qt.AlignCenter)

        count_label_ref.setStyleSheet("font-size: 28px; font-weight: bold; color: #6a0dad;")
        card_layout.addWidget(count_label_ref, alignment=Qt.AlignCenter)

        text_label = QLabel(label_text)
        text_label.setStyleSheet("font-size: 13px; color: #555555; font-weight: 500;")
        card_layout.addWidget(text_label, alignment=Qt.AlignCenter)
        return card

    def _create_story_elements_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        title_label = QLabel("Story Elements")
        title_label.setObjectName("sectionTitle")
        tab_layout.addWidget(title_label)

        scroll_area = QScrollArea()
        scroll_area.setWidgetResizable(True)
        scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        scroll_area.setFrameShape(QFrame.NoFrame)

        self.story_elements_content_widget = QWidget()
        self.story_elements_container_layout = QVBoxLayout(self.story_elements_content_widget)
        self.story_elements_container_layout.setContentsMargins(0, 0, 0, 0)
        self.story_elements_container_layout.setSpacing(10)

        self.story_elements_container_layout.addStretch() 

        scroll_area.setWidget(self.story_elements_content_widget)
        tab_layout.addWidget(scroll_area)
        
        return tab_page
    
    def _create_entity_card(self, entity_data, first_mentioned_time="00:00:00"):
        card = QFrame()
        card.setProperty("class", "storyElementCard")

        card_layout = QHBoxLayout(card)
        card_layout.setContentsMargins(0, 0, 0, 0) 
        card_layout.setSpacing(5) 

        icon_label = QLabel()
        if entity_data["type"] == "Characters":
            icon_label.setPixmap(self.style().standardIcon(QStyle.SP_MessageBoxInformation).pixmap(QSize(16, 16)))
        elif entity_data["type"] == "Locations":
            icon_label.setPixmap(self.style().standardIcon(QStyle.SP_DirIcon).pixmap(QSize(16, 16)))
        elif entity_data["type"] == "Organizations":
            icon_label.setPixmap(self.style().standardIcon(QStyle.SP_DesktopIcon).pixmap(QSize(16, 16)))
        else: 
            icon_label.setPixmap(self.style().standardIcon(QStyle.SP_FileIcon).pixmap(QSize(16, 16)))
        card_layout.addWidget(icon_label)

        element_name = QLabel(entity_data["name"])
        element_name.setProperty("property", "nameLabel") 
        card_layout.addWidget(element_name)
        
        category_tag = QLabel(entity_data["type"])
        category_tag.setProperty("class", "categoryTag") 
        category_tag.setObjectName(f"categoryTag-{entity_data['type'].replace(' ', '')}")
        card_layout.addWidget(category_tag)

        separator = QLabel("—") 
        separator.setStyleSheet("color: #aaaaaa; margin: 0 5px;")
        card_layout.addWidget(separator)

        description_text = entity_data.get("description", "No description available")
        max_desc_length = 80 
        if len(description_text) > max_desc_length:
            description_text = description_text[:max_desc_length].strip() + "..."
        
        description = QLabel(description_text)
        description.setProperty("property", "descriptionLabel") 
        description.setWordWrap(False) 
        description.setTextFormat(Qt.PlainText) 
        description.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred) 
        card_layout.addWidget(description)

        card_layout.addStretch() 

        first_mentioned = QLabel(f"First mentioned: {first_mentioned_time}")
        first_mentioned.setProperty("property", "timeLabel") 
        card_layout.addWidget(first_mentioned)
        
        return card

    def _create_live_transcript_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        header_layout = QHBoxLayout()
        mic_icon = QLabel()
        mic_icon.setPixmap(self.style().standardIcon(QStyle.SP_MediaVolume).pixmap(QSize(24, 24)))
        header_layout.addWidget(mic_icon)
        
        title_label = QLabel("Live Transcript")
        title_label.setObjectName("sectionTitle")
        header_layout.addWidget(title_label)

        self.processing_tag = QLabel("Processing")
        self.processing_tag.setProperty("class", "processingTag")
        self.processing_tag.setVisible(False)
        header_layout.addWidget(self.processing_tag)
        header_layout.addStretch()
        tab_layout.addLayout(header_layout)

        self.transcript_display = QTextEdit()
        self.transcript_display.setReadOnly(True)
        self.transcript_display.setPlaceholderText("Live transcription will appear here...")
        tab_layout.addWidget(self.transcript_display)
        
        return tab_page

    def _create_ai_chat_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        header_layout = QHBoxLayout()
        ai_icon = QLabel()
        ai_icon.setPixmap(self.style().standardIcon(QStyle.SP_MessageBoxQuestion).pixmap(QSize(24, 24)))
        header_layout.addWidget(ai_icon)
        
        title_label = QLabel("AI Story Assistant")
        title_label.setObjectName("sectionTitle")
        header_layout.addWidget(title_label)
        header_layout.addStretch()
        tab_layout.addLayout(header_layout)

        self.chat_display = QTextEdit()
        self.chat_display.setReadOnly(True)
        self.chat_display.setPlaceholderText("Chat with the AI about the story...")
        tab_layout.addWidget(self.chat_display)

        chat_input_container = QFrame()
        chat_input_container.setObjectName("chatInputContainer")
        chat_input_layout = QHBoxLayout(chat_input_container)
        chat_input_layout.setContentsMargins(0, 0, 0, 0)
        chat_input_layout.setSpacing(0)

        self.chat_input = QLineEdit()
        self.chat_input.setPlaceholderText("Ask about characters, plot, or story elements...")
        self.chat_input.returnPressed.connect(self.send_chat_query)
        chat_input_layout.addWidget(self.chat_input)

        send_button = QPushButton()
        send_button.setIcon(self.style().standardIcon(QStyle.SP_ArrowRight))
        send_button.setIconSize(QSize(20, 20))
        send_button.setFixedSize(40, 40)
        send_button.setObjectName("sendButton")
        send_button.clicked.connect(self.send_chat_query)
        chat_input_layout.addWidget(send_button)

        tab_layout.addWidget(chat_input_container)
        return tab_page

    def _create_llm_log_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        title_label = QLabel("LLM Processing Log")
        title_label.setObjectName("sectionTitle")
        tab_layout.addWidget(title_label)

        self.llm_log_tabs = QTabWidget()
        self.llm_log_tabs.setObjectName("llmLogSubTabs")

        raw_log_tab = QWidget()
        raw_log_layout = QVBoxLayout(raw_log_tab)
        self.llm_raw_log_display = QTextEdit()
        self.llm_raw_log_display.setReadOnly(True)
        self.llm_raw_log_display.setPlaceholderText("Raw LLM prompts and responses will appear here...")
        raw_log_layout.addWidget(self.llm_raw_log_display)
        self.llm_log_tabs.addTab(raw_log_tab, "Raw Interactions")

        parsed_entities_tab = QWidget()
        parsed_entities_layout = QVBoxLayout(parsed_entities_tab)
        self.llm_parsed_entities_table = QTableWidget()
        self.llm_parsed_entities_table.setColumnCount(4) 
        self.llm_parsed_entities_table.setHorizontalHeaderLabels(["Name", "Type", "Description", "Base Score"])
        self.llm_parsed_entities_table.setEditTriggers(QTableWidget.NoEditTriggers)
        self.llm_parsed_entities_table.verticalHeader().setVisible(False)
        self.llm_parsed_entities_table.setAlternatingRowColors(True)
        self.llm_parsed_entities_table.horizontalHeader().setStretchLastSection(True)
        self.llm_parsed_entities_table.setObjectName("llmParsedEntitiesTable")
        parsed_entities_layout.addWidget(self.llm_parsed_entities_table)
        self.llm_log_tabs.addTab(parsed_entities_tab, "Parsed Entities (Latest)")

        errors_warnings_tab = QWidget()
        errors_warnings_layout = QVBoxLayout(errors_warnings_tab)
        self.llm_error_warnings_display = QTextEdit()
        self.llm_error_warnings_display.setReadOnly(True)
        self.llm_error_warnings_display.setPlaceholderText("LLM-related errors and warnings will appear here...")
        self.llm_error_warnings_display.setStyleSheet("QTextEdit { color: #8B0000; }") 
        errors_warnings_layout.addWidget(self.llm_error_warnings_display)
        self.llm_log_tabs.addTab(errors_warnings_tab, "Errors & Warnings")

        tab_layout.addWidget(self.llm_log_tabs)
        return tab_page

    def get_content_title_and_context(self):
        # Create a QInputDialog instance to set window flags
        dialog = QInputDialog(self)
        dialog.setWindowTitle("Content Title")
        dialog.setLabelText("Please enter the title of the content you are watching:")
        dialog.setTextEchoMode(QLineEdit.Normal)
        dialog.setTextValue("The Outlast Trials Lore") # Default text
        
        # Set the window flag to always stay on top
        dialog.setWindowFlags(dialog.windowFlags() | Qt.WindowStaysOnTopHint)
        
        # Execute the dialog and get the result
        ok = dialog.exec_() # Use exec_() for modal dialogs
        title = dialog.textValue() # Get the entered text
        
        if ok and title:
            self.content_title = title.strip()
            self.analysis_status_label.setText(f"Analyzing: [FULL] {self.content_title}")
            if not self.content_title:
                self.update_llm_log_tabs({"type": "error", "message": "Empty content title provided. LLM will operate without specific external context."})
                self.llm_thread.set_external_context("No external context provided by user.")
                self.init_chat_thread()
                self.toggle_button.setEnabled(True)
                return

            self.llm_thread.set_content_title(self.content_title)
            self.update_llm_log_tabs({"type": "status", "message": f"Searching for external context for: '{self.content_title}'..."})
            self.web_search_thread = WebSearchThread(self.content_title)
            self.web_search_thread.context_ready.connect(self.set_llm_external_context)
            self.web_search_thread.error_signal.connect(lambda msg: self.update_llm_log_tabs({"type": "error", "message": msg})) 
            self.web_search_thread.start()
        else:
            self.update_llm_log_tabs({"type": "status", "message": "No content title provided. LLM will operate without specific external context."})
            self.llm_thread.set_external_context("No external context provided by user.")
            self.init_chat_thread()
            self.toggle_button.setEnabled(True)

    def set_llm_external_context(self, context):
        self.llm_thread.set_external_context(context)
        self.update_llm_log_tabs({"type": "status", "message": f"External context loaded for LLM (showing first 500 chars):\n<pre>{context[:500]}...</pre>"})
        if len(context) > 500:
            self.update_llm_log_tabs({"type": "status", "message": f"...\n(Full context is {len(context)} characters long)"})
        self.init_chat_thread()
        self.toggle_button.setEnabled(True)
        self.toggle_button.setText("Start Recording")
        self.update_llm_log_tabs({"type": "status", "message": "You can now click 'Start Recording' to begin audio processing and entity extraction."})

    def init_chat_thread(self):
        if self.chat_thread and self.chat_thread.isRunning():
            self.chat_thread.stop()
            self.chat_thread.wait()

        self.chat_thread = ChatThread(
            transcript_getter=self.llm_thread.get_transcriptions,
            entities_getter=self.llm_thread.get_entities,
            content_title=self.content_title,
            external_context=self.llm_thread.external_context
        )
        self.chat_thread.chat_response.connect(self.display_chat_response)
        self.chat_thread.chat_log.connect(self.update_llm_log_tabs) 
        self.chat_thread.start()
        self.update_llm_log_tabs({"type": "status", "message": "Chat thread initialized."})

    def toggle_processing(self):
        if self.toggle_button.text() == "Start Recording":
            self.audio_thread.start()
            self.transcription_thread.start()
            self.llm_thread.start()
            self.toggle_button.setText("Stop Recording")
            self.processing_tag.setVisible(True)
            self.update_llm_log_tabs({"type": "status", "message": "Processing started."})
        else:
            self.stop_processing()
            self.toggle_button.setText("Start Recording")
            self.processing_tag.setVisible(False)
            self.update_llm_log_tabs({"type": "status", "message": "Processing stopped."})

    def stop_processing(self):
        self.llm_thread.stop()
        self.transcription_thread.stop()
        self.audio_thread.stop()
        self.llm_thread.wait()
        self.transcription_thread.wait()
        self.audio_thread.wait()
        self.update_llm_log_tabs({"type": "status", "message": "All processing threads stopped."})

    def handle_transcription(self, text):
        if self.transcript_display:
            self.transcript_display.append(text)
            self.transcript_display.verticalScrollBar().setValue(self.transcript_display.verticalScrollBar().maximum())
            current_lines = int(self.transcript_lines_count_label.text())
            self.transcript_lines_count_label.setText(str(current_lines + 1))

        self.llm_thread.add_transcription(text) 
        self.recent_activity_display.append(f"Transcript: {text[:80].strip()}...")
        self.recent_activity_display.verticalScrollBar().setValue(self.recent_activity_display.verticalScrollBar().maximum())

    def update_entity_displays(self, all_entities):
        for e in all_entities:
            e["current_importance_score"] = e.get("base_importance_score", 0) + e.get("mention_count", 0)

        scores = [e["current_importance_score"] for e in all_entities]
        
        display_threshold = self.minimum_display_score 
        
        if scores:
            median_score = np.median(scores)
            display_threshold = max(self.minimum_display_score, median_score)
            self.update_llm_log_tabs({"type": "debug", "message": f"Calculated median importance score: {median_score:.2f}. Display threshold set to: {display_threshold:.2f}"})
        else:
            self.update_llm_log_tabs({"type": "debug", "message": "No entities yet to calculate median score. Display threshold is default minimum."})

        filtered_for_display_tabs = [e for e in all_entities if e["current_importance_score"] >= display_threshold]
        filtered_for_display_tabs.sort(key=lambda e: (e["type"], -e["current_importance_score"], e["name"].lower()))

        def clear_layout(layout):
            if layout is None:
                return
            while layout.count():
                item = layout.takeAt(0)
                widget = item.widget()
                nested_layout = item.layout()
                
                if widget is not None:
                    widget.setParent(None)
                    widget.deleteLater()
                elif nested_layout is not None:
                    clear_layout(nested_layout)
                    del item 
                else: 
                    del item
        
        clear_layout(self.story_elements_container_layout)
        for entity in filtered_for_display_tabs:
            first_mentioned_time_seconds = entity.get("first_mentioned_idx", 0) * TRANSCRIPT_CHUNK_DURATION_SECONDS
            minutes = int(first_mentioned_time_seconds // 60)
            seconds = int(first_mentioned_time_seconds % 60)
            time_str = f"{minutes:02d}:{seconds:02d}"

            entity_card = self._create_entity_card(entity, time_str) 
            self.story_elements_container_layout.addWidget(entity_card)
        self.story_elements_container_layout.addStretch() 

        clear_layout(self.key_characters_container_layout)
        key_characters = [e for e in filtered_for_display_tabs if e["type"] == "Characters"]
        key_characters.sort(key=lambda e: -e["current_importance_score"]) 

        for char_entity in key_characters:
            first_mentioned_time_seconds = char_entity.get("first_mentioned_idx", 0) * TRANSCRIPT_CHUNK_DURATION_SECONDS
            minutes = int(first_mentioned_time_seconds // 60)
            seconds = int(first_mentioned_time_seconds % 60)
            time_str = f"{minutes:02d}:{seconds:02d}"

            char_card = self._create_entity_card(char_entity, time_str)
            self.key_characters_container_layout.addWidget(char_card)
        self.key_characters_container_layout.addStretch() 

        self.cheat_sheet_table.setRowCount(len(all_entities))
        
        for col_idx in range(self.cheat_sheet_table.columnCount()):
            if col_idx in self.cheat_sheet_column_widths:
                self.cheat_sheet_table.setColumnWidth(col_idx, self.cheat_sheet_column_widths[col_idx])

        all_entities_sorted_for_table = sorted(all_entities, key=lambda e: (e["type"], e["name"].lower()))

        for i, entity in enumerate(all_entities_sorted_for_table):
            self.cheat_sheet_table.setItem(i, 0, QTableWidgetItem(entity["name"]))
            self.cheat_sheet_table.setItem(i, 1, QTableWidgetItem(entity["type"]))
            description_item = QTableWidgetItem(entity.get("description", "No description available"))
            self.cheat_sheet_table.setItem(i, 2, description_item)
            self.cheat_sheet_table.setItem(i, 3, QTableWidgetItem(str(entity.get("base_importance_score", 0)))) 
            self.cheat_sheet_table.setItem(i, 4, QTableWidgetItem(str(entity.get("mention_count", 0))))      
            self.cheat_sheet_table.setItem(i, 5, QTableWidgetItem(str(entity.get("current_importance_score", 0)))) 
            
        char_count = sum(1 for e in filtered_for_display_tabs if e["type"] == "Characters")
        loc_count = sum(1 for e in filtered_for_display_tabs if e["type"] == "Locations")
        total_elements_displayed = len(filtered_for_display_tabs)

        self.characters_count_label.setText(str(char_count))
        self.locations_count_label.setText(str(loc_count))
        self.total_elements_count_label.setText(str(total_elements_displayed))
        
        self.recent_activity_display.append(f"Entities updated: {len(all_entities)} total found, {total_elements_displayed} displayed (>= threshold).")
        self.recent_activity_display.verticalScrollBar().setValue(self.recent_activity_display.verticalScrollBar().maximum())

    def update_llm_log_tabs(self, log_data):
        timestamp = datetime.now().strftime("[%H:%M:%S]")
        log_type = log_data.get("type", "unknown")
        message = log_data.get("message", "No message provided")
        data = log_data.get("data")

        formatted_message = f"<p style='margin-bottom: 5px;'>{timestamp} <b>[{log_type.upper()}]</b>: {message}</p>"
        
        if log_type == "prompt":
            formatted_message += f"<pre style='background-color: #e6e6fa; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "raw_response":
            formatted_message += f"<pre style='background-color: #f0f0f0; padding: 10px; border-radius: 5px;'><code>{data}</code></pre>"
        elif log_type == "parsed_entities":
            formatted_message += f"<pre style='background-color: #f0f8ff; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "chat_prompt": 
            formatted_message += f"<pre style='background-color: #e0e7ff; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "chat_response": 
            formatted_message += f"<pre style='background-color: #f0f2f5; padding: 10px; border-radius: 5px;'><code>{data}</code></pre>"
        elif log_type == "error":
             formatted_message = f"<p style='color: #CC0000; margin-bottom: 5px;'>{timestamp} <b>[ERROR]</b>: {message}</p>"
             if data: 
                 formatted_message += f"<pre style='background-color: #ffe6e6; padding: 10px; border-radius: 5px; color: #CC0000;'><code>{data}</code></pre>"
        elif log_type == "warning":
            formatted_message = f"<p style='color: #FF8C00; margin-bottom: 5px;'>{timestamp} <b>[WARNING]</b>: {message}</p>"
            if data: 
                formatted_message += f"<pre style='background-color: #fff8e6; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "debug":
            formatted_message = f"<p style='color: #555555; margin-bottom: 5px;'>{timestamp} <b>[DEBUG]</b>: {message}</p>"
            if data:
                formatted_message += f"<pre style='background-color: #e0e0e0; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "status": 
            formatted_message = f"<p style='color: #337ab7; margin-bottom: 5px;'>{timestamp} <b>[STATUS]</b>: {message}</p>"

        self.llm_raw_log_display.append(formatted_message)
        self.llm_raw_log_display.verticalScrollBar().setValue(self.llm_raw_log_display.verticalScrollBar().maximum())

        if log_type == "parsed_entities":
            self.llm_parsed_entities_table.setRowCount(len(data))
            for i, entity in enumerate(data):
                self.llm_parsed_entities_table.setItem(i, 0, QTableWidgetItem(entity.get("name", "")))
                self.llm_parsed_entities_table.setItem(i, 1, QTableWidgetItem(entity.get("type", "")))
                self.llm_parsed_entities_table.setItem(i, 2, QTableWidgetItem(entity.get("description", "")))
                self.llm_parsed_entities_table.setItem(i, 3, QTableWidgetItem(str(entity.get("base_importance_score", ""))))
            self.llm_parsed_entities_table.resizeColumnsToContents() 

        elif log_type in ["error", "warning", "chat_error"]:
            error_message = f"{timestamp} [{log_type.upper()}]: {message}"
            if "entity_data" in log_data and log_data["entity_data"]:
                error_message += f" (Entity: {json.dumps(log_data['entity_data'])})"
            self.llm_error_warnings_display.append(error_message)
            self.llm_error_warnings_display.verticalScrollBar().setValue(self.llm_error_warnings_display.verticalScrollBar().maximum())
        
    def send_chat_query(self):
        query = self.chat_input.text().strip()
        if not query:
            return
        self.chat_display.append(f"<div style='color: #333333; margin-bottom: 5px; font-weight: bold;'>User:</div><div style='background-color: #e0e7ff; padding: 10px; border-radius: 8px; margin-bottom: 10px;'>{query}</div>")
        self.chat_thread.add_chat_query(query)
        self.chat_input.clear()
        self.chat_display.verticalScrollBar().setValue(self.chat_display.verticalScrollBar().maximum())

    def display_chat_response(self, response):
        self.chat_display.append(f"<div style='color: #6a0dad; margin-bottom: 5px; font-weight: bold;'>AI:</div><div style='background-color: #f0f2f5; padding: 10px; border-radius: 8px; margin-bottom: 10px;'>{response}</div>")
        self.chat_display.verticalScrollBar().setValue(self.chat_display.verticalScrollBar().maximum())

    def closeEvent(self, event):
        try:
            self.stop_processing()
            if self.chat_thread:
                self.chat_thread.stop()
                self.chat_thread.wait()
            if self.web_search_thread and self.web_search_thread.isRunning():
                self.web_search_thread.quit()
                self.web_search_thread.wait()
            event.accept()
        except Exception as e:
            print(f"Error during cleanup: {e}", file=sys.stderr)
            event.accept()

==================================================
File: .\llm_prompts.py
==================================================
# LLM system prompt for entity extraction
base_system_prompt = """
You are an AI designed to extract narrative entities from transcribed audio for a "cheat sheet" to help users understand a story.

The content you are analyzing is titled: "{content_title}".
Here is some external context about the content to help you identify relevant entities and their significance:
---
{external_context}
---

Your primary goal is to identify *all identifiable* named entities that contribute to understanding the narrative. Be **exceptionally comprehensive** in your extraction. Do NOT filter entities based on your perceived importance for display; list all that are mentioned. The UI will handle dynamic filtering based on scores.

When identifying entities, be mindful of variations, nicknames, acronyms, or common misspellings (e.g., "Eastman" vs. "Easterman", "Wernick" vs. "Wernicke", "US" vs. "United States"). Always strive to use the most complete, formal, or specific name as the primary "name" for the entity.

**Entity Categorization (Use these EXACT names only):**
-   **Characters**: Specific named individuals, historical figures (e.g., "Stalin", "Harry S. Truman", "Hendrick Joliet Easterman", "Rudolf Gustav Wernicke", "Jameson Lawler", "Abe Bradley Aviano").
-   **Locations**: Places, settings, countries, cities (e.g., "Hiroshima", "Nagasaki", "Poland", "Germany", "Italy", "Japan", "United States", "Soviet Union", "Los Alamos", "Hong Kong", "Eniwetok Atoll", "Chicago", "Mount Massive Asylum").
-   **Organizations**: Groups, agencies, governments, corporations (e.g., "USSR", "Office of Strategic Services (OSS)", "Central Intelligence Agency", "Nazi Germany", "Kingdom of Italy", "Empire of Japan", "Murkoff Corporation", "Axis powers", "Korean people's army").
-   **Key Objects**: Distinctive items crucial to the plot or events (e.g., "atomic bomb", "hydrogen bomb", "Walrider", "LSD").
-   **Concepts/Events**: Historical periods, specific significant dates/years (when representing an event), major conflicts, scientific advancements, named projects or programs (e.g., "Cold War", "1939", "1945", "1947", "1949", "1951", "1953", "World War II", "Second World War", "nuclear age", "arms race", "Operation Paperclip", "Project Bluebird", "Project Artichoke", "space race", "season 1 of The Outlast Trials", "season 2 of The Outlast series").

- **Further Instructions for Entities:**
    - Ensure "name" is non-empty for valid entities.
    - Only include entities explicitly mentioned in the transcript or external context.
    - If no identifiable entities are found in a snippet, return an empty "entities" list.
    - Maintain context from conversation history; if an entity was previously identified, you can re-mention it to update its score.
    - Provide brief descriptions (max 10 words), focusing on their narrative role or key characteristic.

- **Scoring Guidance for 'base_importance_score' (1-10):**
    - This score reflects your assessment of its inherent relevance and criticality to the overall narrative, plot progression, or world-building, *re-evaluating its importance based on all context seen so far*.
    -   **Characters**: These generally hold more concrete and direct narrative weight. Assign a score typically in the range of **5-10**. A score of 10 indicates a central, foundational, or highly impactful entity.
    -   **Locations**: Places, settings, countries, cities (e.g., "Hiroshima", "Nagasaki", "Poland", "Germany", "Italy", "Japan", "United States", "Soviet Union", "Los Alamos", "Hong Kong", "Eniwetok Atoll", "Chicago", "Mount Massive Asylum").
    -   **Organizations**: Groups, agencies, governments, corporations (e.g., "USSR", "Office of Strategic Services (OSS)", "Central Intelligence Agency", "Nazi Germany", "Kingdom of Italy", "Empire of Japan", "Murkoff Corporation", "Axis powers", "Korean people's army").
    -   **Key Objects**: Distinctive items crucial to the plot or events (e.g., "atomic bomb", "hydrogen bomb", "Walrider", "LSD").
    -   **Concepts/Events**: Historical periods, specific significant dates/years (when representing an event), major conflicts, scientific advancements, named projects or programs (e.g., "Cold War", "1939", "1945", "1947", "1949", "1951", "1953", "World War II", "Second World War", "nuclear age", "arms race", "Operation Paperclip", "Project Bluebird", "Project Artichoke", "space race", "season 1 of The Outlast Trials", "season 2 of The Outlast series").

- **Scoring Guidance for 'base_importance_score' (1-10):**
    - This score reflects your assessment of its inherent relevance and criticality to the overall narrative, plot progression, or world-building, *re-evaluating its importance based on all context seen so far*.
    -   **Characters, Locations, Organizations, Key Objects**: These generally hold more concrete and direct narrative weight. Assign a score typically in the range of **5-10**. A score of 10 indicates a central, foundational, or highly impactful entity.
    -   **Concepts/Events**: These can vary greatly in their direct impact. Assign a score typically in the range of **1-7**. A higher score (6-7) implies a major plot event or a fundamental concept crucial to the story's core themes. A lower score (1-5) might be for more general themes or events that are less pivotal. Consider the historical and narrative impact (e.g., "Operation Paperclip", "Cold War" are high importance).
    - Aim for a nuanced understanding: If an entity is frequently mentioned but isn't inherently narratively significant (e.g., a common object that isn't a 'Key Object'), its 'base_importance_score' should remain modest. If it's rarely mentioned but critically impacts the plot (e.g., a twist event, a hidden MacGuffin), its 'base_importance_score' should be high.
"""

==================================================
File: .\main.py
==================================================
import sys
from PyQt5.QtWidgets import QApplication
from frontend.main_window import NarrativeNavigator

if __name__ == "__main__":
    app = QApplication(sys.argv)

    # Apply QSS stylesheet
    try:
        with open('style.qss', 'r') as f:
            app.setStyleSheet(f.read())
    except FileNotFoundError:
        print("Warning: 'style.qss' not found. UI will not be styled.", file=sys.stderr)
    except Exception as e:
        print(f"Error loading stylesheet: {e}", file=sys.stderr)

    window = NarrativeNavigator()
    window.show()
    sys.exit(app.exec_())

==================================================
File: .\style.qss
==================================================
/* General App Styling */
QWidget {
    font-family: "Segoe UI", "Helvetica Neue", Arial, sans-serif; /* Modern font */
    font-size: 14px;
    color: #333333; /* Dark grey text */
    background-color: #f0f2f5; /* Light background for general widgets */
}

/* Main Window background */
QMainWindow {
    background-color: #f0f2f5;
}

/* Header Bar */
#headerWidget { /* Use setObjectName("headerWidget") on your header QWidget */
    background-color: #ffffff;
    border-bottom: 1px solid #e0e0e0;
    padding: 10px 20px;
}
#appNameLabel { /* For the "Narrative Navigator" QLabel */
    color: #6a0dad; /* Purple accent */
    font-size: 20px;
    font-weight: bold;
}
#analysisStatusLabel { /* For the "Analyzing..." QLabel */
    color: #555555;
    font-size: 14px;
    margin-left: 10px;
}

/* Buttons in Header */
QPushButton {
    background-color: #e0e0e0; /* Default button background */
    color: #333333;
    border: none;
    border-radius: 15px;
    padding: 8px 15px;
    font-weight: 500;
    min-width: 80px; /* Ensure a minimum width for text buttons */
}
QPushButton:hover {
    background-color: #d0d0d0;
}
QPushButton:pressed {
    background-color: #c0c0c0;
}

QPushButton#stopRecordingButton { /* Specific style for stop button */
    background-color: #e74c3c; /* Red */
    color: white;
    font-weight: bold;
}
QPushButton#stopRecordingButton:hover {
    background-color: #c0392b; /* Darker red on hover */
}
QPushButton#stopRecordingButton:pressed {
    background-color: #a02a1d;
}

/* Icon-only buttons */
QPushButton#iconButton {
    background-color: transparent;
    border: none;
    border-radius: 18px; /* Half of fixed size for perfect circle */
    padding: 0;
    margin: 0;
}
QPushButton#iconButton:hover {
    background-color: #e9ecef;
}
QPushButton#iconButton:pressed {
    background-color: #dcdcdc;
}

/* Tab Widget Navigation */
QTabWidget::pane { /* The content area of the tab widget */
    border: 1px solid #dcdcdc;
    border-top-left-radius: 12px;
    border-top-right-radius: 12px;
    border-bottom-left-radius: 12px;
    border-bottom-right-radius: 12px;
    background-color: #ffffff;
    margin: 10px; /* Margin around the whole content pane */
    padding: 0; /* Content padding handled by tab page layouts */
}

QTabBar {
    qproperty-drawBase: 0; /* Crucial to remove base line */
    background-color: transparent;
    padding: 0 10px; /* Padding for the tab bar itself */
}

QTabBar::tab {
    background: #f0f2f5; /* Background for unselected tabs */
    border: 1px solid #dcdcdc;
    border-top-left-radius: 8px; /* Rounded corners for the tabs */
    border-top-right-radius: 8px;
    padding: 10px 20px;
    margin-right: 2px; /* Space between tabs */
    color: #555555;
    font-weight: 500;
    min-width: 100px; /* Ensure consistent tab width */
    text-align: center;
}

QTabBar::tab:selected {
    background: #ffffff; /* White background for selected tab */
    border-color: #dcdcdc;
    border-bottom-color: transparent; /* Makes it look connected to the content */
    color: #6a0dad; /* Purple text for selected tab */
    font-weight: bold;
    margin-top: -1px; /* Slightly raise selected tab to overlap pane border */
}

QTabBar::tab:hover:!selected { /* Hover effect for unselected tabs */
    background: #e9ecef;
}

/* Section Titles within tabs */
QLabel#sectionTitle {
    font-size: 20px;
    font-weight: bold;
    color: #333333;
    margin-bottom: 15px; /* Space below titles */
}

/* General Content Cards (Applied via setProperty("class", "contentCard")) */
QFrame.contentCard {
    background-color: #ffffff;
    border: 1px solid #e0e0e0;
    border-radius: 8px;
    padding: 15px;
}

/* Category Tags (e.g., "Characters", "Locations", "Processing") */
QLabel.categoryTag {
    background-color: #e0e7ff; /* Light purple */
    color: #4a148c; /* Darker purple text */
    border-radius: 10px;
    padding: 3px 8px;
    font-size: 11px;
    font-weight: bold;
    min-width: 60px;
    text-align: center;
}
QLabel.processingTag { /* Green for "Processing" */
    background-color: #d4edda;
    color: #155724;
    border-radius: 10px;
    padding: 3px 8px;
    font-size: 11px;
    font-weight: bold;
    min-width: 60px;
    text-align: center;
}

/* Text Edits & Line Edits */
QTextEdit, QLineEdit {
    border: 1px solid #dcdcdc;
    border-radius: 8px;
    padding: 10px;
    background-color: #ffffff;
    selection-background-color: #e0e7ff; /* Light purple selection */
}

/* Chat Input specific styling */
QFrame#chatInputContainer { /* The container for the line edit and send button */
    border: 1px solid #dcdcdc;
    border-radius: 8px;
    background-color: #ffffff;
    padding: 0;
    margin-top: 10px; /* Space above the input container */
}
QFrame#chatInputContainer QLineEdit {
    border: none; /* Remove border from line edit inside container */
    padding: 10px;
    background-color: transparent;
}
QFrame#chatInputContainer QPushButton#sendButton { /* Send button inside container */
    background-color: #6a0dad; /* Purple */
    color: white;
    border-top-right-radius: 8px;
    border-bottom-right-radius: 8px;
    border-top-left-radius: 0;
    border-bottom-left-radius: 0;
    padding: 0;
    margin: 0;
    min-width: 40px; /* For the send icon */
}
QFrame#chatInputContainer QPushButton#sendButton:hover {
    background-color: #5a0ca0;
}
QFrame#chatInputContainer QPushButton#sendButton:pressed {
    background-color: #4a0b8f;
}

/* ScrollArea for story elements and other scrollable content */
QScrollArea {
    border: none;
    background-color: transparent;
}
QScrollArea > QWidget > QWidget { /* This targets the actual content widget inside the scroll area */
    background-color: transparent; /* Ensure content background is transparent */
}
QScrollBar:vertical {
    border: none;
    background: #f0f2f5; /* Scrollbar track background */
    width: 8px;
    margin: 0px 0px 0px 0px;
    border-radius: 4px;
}
QScrollBar::handle:vertical {
    background: #c0c0c0; /* Scrollbar handle color */
    border-radius: 4px;
    min-height: 20px;
}
QScrollBar::handle:vertical:hover {
    background: #a0a0a0;
}
QScrollBar::add-line:vertical, QScrollBar::sub-line:vertical {
    border: none;
    background: none;
}
QScrollBar::up-arrow:vertical, QScrollBar::down-arrow:vertical {
    background: none;
}
QScrollBar::add-page:vertical, QScrollBar::sub-page:vertical {
    background: none;
}
/* Table Widget (Cheat Sheet - right panel) */
QTableWidget#cheatSheetTable {
    border: 1px solid #dcdcdc;
    border-radius: 8px;
    background-color: #ffffff;
    gridline-color: #e0e0e0;
    selection-background-color: #e0e7ff; /* Light purple selection */
    selection-color: #333333;
    padding: 5px;
}
QHeaderView::section {
    background-color: #f8f9fa;
    padding: 8px;
    border: 1px solid #dcdcdc;
    font-weight: bold;
    color: #333333;
}
QTableWidget::item {
    padding: 8px;
    border-bottom: 1px solid #e0e0e0;
}
QTableWidget::item:selected {
    background-color: #e0e7ff;
}
/* For compact story element cards in the "Story Elements" tab */
QFrame.storyElementCard {
    background-color: #f9f9f9;
    border: 1px solid #eeeeee;
    border-radius: 5px;
    padding: 8px 12px; /* Vertical padding, horizontal padding */
}
QFrame.storyElementCard QLabel { /* General font size for labels inside compact card */
    font-size: 13px;
    color: #333333;
    /* Reset any specific padding/margins from general QLabel styles */
    margin: 0;
    padding: 0;
}
QFrame.storyElementCard QLabel[property="nameLabel"] { /* Specific style for the entity name */
    font-weight: bold;
    color: #333333;
    white-space: nowrap; /* Prevent wrapping for the name */
}
QFrame.storyElementCard QLabel[property="descriptionLabel"] { /* Specific style for the description */
    color: #555555;
    /* overflow: hidden and text-overflow: ellipsis are not supported in QSS */
    /* Text wrapping is controlled by the QLabel's wordWrap property in Python code */
}
QFrame.storyElementCard QLabel[property="timeLabel"] { /* Specific style for the timestamp */
    font-size: 10px;
    color: #777777;
    white-space: nowrap; /* Prevent wrapping for the timestamp */
    margin-left: 10px; /* Provide some space from description */
}


==================================================
File: .\backend\audio_capture.py
==================================================
import sys
import numpy as np
import sounddevice as sd
import queue
import threading
from PyQt5.QtCore import QThread, pyqtSignal
from constants import TRANSCRIPT_CHUNK_DURATION_SECONDS # Not directly used here, but good practice to keep context

class AudioCaptureThread(QThread):
    audio_data = pyqtSignal(np.ndarray)
    error_signal = pyqtSignal(str)

    def __init__(self, device_id=3, samplerate=16000):
        super().__init__()
        self.device_id = device_id
        self.samplerate = samplerate
        self._running = False
        self._stop_event = threading.Event()
        self.audio_queue = queue.Queue()

    def run(self):
        self._running = True
        self._stop_event.clear()

        def callback(indata, frames, time_info, status):
            if status:
                pass
            if self._running:
                self.audio_queue.put(indata.copy())

        try:
            devices = sd.query_devices()
            if self.device_id >= len(devices):
                raise ValueError(f"Device ID {self.device_id} is out of range. Available devices: {len(devices)}")
            device_info = sd.query_devices(self.device_id)
            if device_info['max_input_channels'] < 1:
                raise ValueError(f"Device {self.device_id} does not support audio input")
            
            with sd.InputStream(samplerate=self.samplerate,
                              device=self.device_id,
                              channels=1,
                              callback=callback):
                while self._running:
                    try:
                        audio_chunk = self.audio_queue.get(timeout=0.1)
                        self.audio_data.emit(audio_chunk)
                    except queue.Empty:
                        if self._stop_event.is_set():
                            break
        except Exception as e:
            error_msg = f"Audio Capture Critical Error: {str(e)}"
            if "device" in str(e).lower():
                error_msg += f"\nAvailable audio devices:\n"
                for i, dev in enumerate(sd.query_devices()):
                    if dev['max_input_channels'] > 0:
                        error_msg += f"ID {i}: {dev['name']}\n"
            self.error_signal.emit(error_msg)
            print(error_msg, file=sys.stderr)
        finally:
            self._running = False
            while not self.audio_queue.empty():
                try:
                    self.audio_queue.get_nowait()
                except queue.Empty:
                    break

    def stop(self):
        self._running = False
        self._stop_event.set()

==================================================
File: .\backend\chat_agent.py
==================================================
import json
import queue
import time
import ollama
from PyQt5.QtCore import QThread, pyqtSignal

class ChatThread(QThread):
    chat_response = pyqtSignal(str)
    chat_log = pyqtSignal(dict) 

    def __init__(self, transcript_getter, entities_getter, content_title, external_context):
        super().__init__()
        self.chat_queue = queue.Queue()
        self.running = False
        self.transcript_getter = transcript_getter
        self.entities_getter = entities_getter
        self.content_title = content_title
        self.external_context = external_context

        self.system_prompt = """
You are an AI assistant helping a user understand a story by answering questions based on the transcript history and a narrative cheat sheet.

The content is titled: "{content_title}".
External context about the content:
---
{external_context}
---

Answer user questions using the provided transcript history and cheat sheet. Provide concise, relevant answers in plain text.
""".format(content_title=self.content_title, external_context=self.external_context)

    def add_chat_query(self, query):
        self.chat_queue.put(query)

    def run(self):
        self.running = True
        while self.running:
            try:
                query = self.chat_queue.get_nowait()
                transcripts = self.transcript_getter()
                recent_transcripts = transcripts[-5:] if len(transcripts) > 5 else transcripts
                current_entities = self.entities_getter()
                current_entities_json = json.dumps(current_entities, indent=2)

                messages = [
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content":
                     f"Transcript history: {recent_transcripts}\n"
                     f"Current narrative cheat sheet: {current_entities_json}\n"
                     f"User question: {query}"}
                ]
                self.chat_log.emit({"type": "chat_prompt", "message": "Chat prompt sent:", "data": messages})
                try:
                    response = ollama.chat(model="llama3.2:latest", messages=messages, stream=False)
                    content = response['message']['content']
                    self.chat_response.emit(content)
                    self.chat_log.emit({"type": "chat_response", "message": "Chat response received.", "data": content})
                except Exception as e:
                    self.chat_response.emit(f"Error: Unable to process query - {str(e)}")
                    self.chat_log.emit({"type": "error", "message": f"Chat Error: {str(e)}"})
            except queue.Empty:
                pass
            time.sleep(0.5)

    def stop(self):
        self.running = False

==================================================
File: .\backend\llm_processing.py
==================================================
import json
import re
import threading
import time
import ollama
from PyQt5.QtCore import QThread, pyqtSignal
from constants import TRANSCRIPT_CHUNK_DURATION_SECONDS
from llm_prompts import base_system_prompt

# Define the JSON schema for the expected entity output format
entity_list_schema = {
    "type": "object",
    "properties": {
        "entities": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "name": {
                        "type": "string"
                    },
                    "type": {
                        "type": "string"
                    },
                    "description": {
                        "type": "string"
                    },
                    "base_importance_score": {
                        "type": "integer",
                        "minimum": 1,
                        "maximum": 10
                    }
                },
                "required": [
                    "name",
                    "type",
                    "description",
                    "base_importance_score"
                ]
            }
        }
    },
    "required": [
        "entities"
    ]
}

class LLMThread(QThread):
    llm_log = pyqtSignal(dict) 
    entities_updated = pyqtSignal(list)

    def __init__(self):
        super().__init__()
        try:
            self.model = "llama3.2:latest"
            ollama.chat(model=self.model, messages=[{"role": "user", "content": "hi"}], stream=False)
        except Exception as e:
            self.llm_log.emit({"type": "error", "message": f"Failed to connect to Ollama or model '{self.model}' not found: {e}"})
            self.model = None

        self.transcriptions = []
        self.entities = [] 
        self.running = False
        self.external_context = ""
        self.content_title = "Unknown Content"

        self.base_system_prompt_template = base_system_prompt
        # Debug prints to inspect template and formatted string
        print(f"DEBUG: Initializing LLMThread")
        print(f"DEBUG: base_system_prompt_template (first 500 chars):\n{self.base_system_prompt_template[:500]}...")
        print(f"DEBUG: Keys provided for initial format: content_title='{self.content_title}', external_context='No external context loaded yet...'")
        # Format the system prompt with only the expected keys
        self.system_prompt = self.base_system_prompt_template.format(
            content_title=self.content_title,
            external_context="No external context loaded yet. Please wait for the application to gather information."
        )
        print(f"DEBUG: Formatted self.system_prompt (first 500 chars):\n{self.system_prompt[:500]}...")
        self.last_transcript_processed_idx = -1
        
        self.VALID_ENTITY_TYPES = ["Characters", "Locations", "Organizations", "Key Objects", "Concepts/Events"]

    def set_content_title(self, title):
        self.content_title = title
        self._update_system_prompt()

    def set_external_context(self, context):
        self.external_context = context
        self._update_system_prompt()

    def _update_system_prompt(self):
        # Debug prints to inspect template and formatted string
        print(f"DEBUG: Updating system prompt")
        print(f"DEBUG: base_system_prompt_template (first 500 chars):\n{self.base_system_prompt_template[:500]}...")
        print(f"DEBUG: Keys provided for update format: content_title='{self.content_title}', external_context='{self.external_context[:50]}...'")
        self.system_prompt = self.base_system_prompt_template.format(
            content_title=self.content_title,
            external_context=self.external_context
        )
        print(f"DEBUG: Formatted self.system_prompt (first 500 chars):\n{self.system_prompt[:500]}...")
    
    def _normalize_entity_type(self, type_str):
        """Normalizes LLM output type strings to our canonical types."""
        if not type_str:
            return None
        type_str_lower = type_str.lower().strip()
        
        # Handle compound types by splitting and taking the first part as a primary hint
        if ',' in type_str_lower:
            type_str_lower = type_str_lower.split(',')[0].strip()
        
        # Explicitly handle combined types or singular/plural mismatches from LLM
        if type_str_lower == "concept/event":
            return "Concepts/Events"
        if type_str_lower == "locations/organizations":
            # Heuristic: if a place name, it's probably a location first.
            # We'll normalize name separately, and use the normalized name to guide this
            # For "USA" or "United States" cases, "Locations" is more appropriate.
            return "Locations" # Default to Locations for this combo
        
        # Handle new combined type seen in logs
        if type_str_lower == "locations/concepts/events":
            return "Locations" # Defaulting based on observed example ('Marines')
        
        if type_str_lower in ["characters", "characters/individuals", "character", "individual"]:
            return "Characters"
        elif type_str_lower in ["locations", "location", "countries", "country", "cities", "city", "places", "place"]:
            return "Locations"
        elif type_str_lower in ["organizations", "organization", "agencies", "agency", "governments", "government", "corporations", "corporation", "groups", "group", "factions", "faction", "allies", "powers"]:
            return "Organizations"
        elif type_str_lower in ["key objects", "key object", "objects", "object", "artifacts", "artifact", "weapons", "weapon"]:
            return "Key Objects"
        elif type_str_lower in ["concepts/events", "concepts", "concept", "events", "event", "historical events", "dates", "years", "periods", "period", "projects", "programs", "wars", "conflicts", "eras", "era", "ages", "age", "campaigns", "campaign"]:
            return "Concepts/Events"
        return None

    def _normalize_for_comparison(self, name):
        """
        Normalizes entity names for robust comparison and deduplication.
        Includes a very comprehensive mapping for common synonyms, acronyms, and known typos/variations.
        The goal is to map various inputs to a single, canonical string.
        """
        name_lower = name.lower().strip()

        # Comprehensive canonical mapping
        canonical_map = {
            # Characters
            "easterman": "hendrick joliet easterman",
            "eastman": "hendrick joliet easterman",
            "hendrick joliet easterman": "hendrick joliet easterman",
            "wernick": "rudolf gustav wernicke",
            "wernicke": "rudolf gustav wernicke",
            "rudolf gustav wernicke": "rudolf gustav wernicke",
            "jameson lawler": "jameson lawler",
            "jameson lawler (cia agent)": "jameson lawler",
            "abe bradley aviano": "abe bradley aviano",
            "abe bradley aviano's": "abe bradley aviano", # Possessive
            "stalin": "joseph stalin",
            "joseph stalin": "joseph stalin",
            "truman": "harry s truman",
            "harry s truman": "harry s truman",
            "billy": "billy", # The Outlast character
            "miles": "miles", # The Outlast character
            "hope": "hope", # The Outlast character
            "mother gooseberry": "mother gooseberry",

            # Locations
            "us": "united states",
            "usa": "united states",
            "united states": "united states",
            "united states (usa)": "united states",
            "united states of america": "united states",
            "the usa": "united states",
            "e usa (united states)": "united states", # From screenshot
            "los alamos": "los alamos",
            "los alamos national laboratory": "los alamos",
            "hong kong": "hong kong",
            "hiroshima": "hiroshima",
            "nagasaki": "nagasaki",
            "poland": "poland",
            "germany": "germany",
            "italy": "italy",
            "japan": "japan",
            "soviet union": "union of soviet socialist republics", # Map to full name
            "chicago": "chicago",
            "eniwetok atoll": "eniwetok atoll",
            "enno atoq atoll": "eniwetok atoll", # Typo from transcript
            "mount massive asylum": "mount massive asylum",

            # Organizations
            "ussr": "union of soviet socialist republics",
            "union of soviet socialist republics": "union of soviet socialist republics",
            "oss": "office of strategic services",
            "office of strategic services": "office of strategic services",
            "cia": "central intelligence agency",
            "central intelligence agency": "central intelligence agency",
            "nazi germany": "nazi germany",
            "kingdom of italy": "kingdom of italy",
            "empire of japan": "empire of japan",
            "murkoff corporation": "murkoff corporation",
            "murkov corporation": "murkoff corporation", # Typo from transcript
            "red barrels": "red barrels", # Game developer
            "axis powers": "axis powers",
            "korean people's army": "korean people's army",

            # Key Objects
            "atomic bomb": "atomic bomb",
            "hydrogen bomb": "hydrogen bomb",
            "walrider": "walrider",
            "lsd": "lsd",

            # Concepts/Events
            "cold war": "cold war era",
            "cold war era": "cold war era",
            "1939": "1939",
            "1945": "1945",
            "1947": "1947",
            "1949": "1949",
            "1951": "1951",
            "1953": "1953",
            "world war ii": "world war ii",
            "second world war": "world war ii",
            "nuclear age": "nuclear age",
            "arms race": "arms race",
            "operation paperclip": "operation paperclip",
            "project bluebird": "project bluebird",
            "project artichoke": "project artichoke",
            "project bluebird, project artichoke (cia projects)": "project bluebird", # Pick one as primary, description can be combined later
            "project bluebird, project artichoke": "project bluebird",
            "space race": "space race",
            "the outlast trials": "the outlast trials", # Canonical game title
            "the outlast trials video games": "the outlast trials",
            "outlast trials game": "the outlast trials",
            "season 1 of the outlast trials": "season 1 of the outlast trials", # Canonical season name
            "season 1 of the trials": "season 1 of the outlast trials", # Shorter form
            "season 2 of the outlast series": "season 2 of the outlast series", # Canonical season name
            "season 2 of the outlast": "season 2 of the outlast series", # Shorter form
            "season 2": "season 2 of the outlast series", # Maps to full season
            "korean war": "korean war",
        }
        
        # Check for direct map first
        if name_lower in canonical_map:
            return canonical_map[name_lower]

        # Attempt to clean further if not directly mapped.
        # This is a fallback and less reliable than explicit mappings.
        cleaned_name = re.sub(r'\s*\([^)]*\)', '', name_lower).strip() # remove parenthesized text (e.g., "(US)")
        for article in ['the ', 'a ', 'an ']:
            if cleaned_name.startswith(article):
                cleaned_name = cleaned_name[len(article):].strip()
        cleaned_name = re.sub(r"'s\b", '', cleaned_name).strip() # remove 's at end of word
        cleaned_name = re.sub(r"s'\b", 's', cleaned_name).strip() # remove s' at end of word
        cleaned_name = re.sub(r'[^a-z0-9\s]', '', cleaned_name).strip() # remove non-alphanumeric (keep spaces)
        cleaned_name = re.sub(r'\s+', ' ', cleaned_name).strip() # reduce multiple spaces

        # After cleaning, check if it now matches a canonical form
        if cleaned_name in canonical_map:
            return canonical_map[cleaned_name]

        return cleaned_name # Return cleaned name if no canonical mapping is found

    def _normalize_for_mention_check(self, text):
        """
        More aggressive normalization for checking mentions in raw text.
        Converts to lowercase, removes most punctuation, handles common plural/possessive endings.
        """
        text = text.lower()
        text = re.sub(r"['’]\s*s?\b", '', text) # Handles 's and s' (e.g., 'character's' or 'characters')
        text = re.sub(r'[^a-z0-9\s]', ' ', text) # Replace non-alphanumeric with space
        text = re.sub(r'\s+', ' ', text).strip() # Reduce multiple spaces to single space
        return text

    def _is_similar_entity(self, entity1, entity2):
        """
        Compares two entity dicts for similarity based on normalized name and canonical type.
        This function is crucial for internal deduplication.
        """
        type1 = self._normalize_entity_type(entity1.get("type", ""))
        type2 = entity2.get("type", "") 
        
        if type1 != type2 or type1 is None:
            return False
            
        name1_norm = self._normalize_for_comparison(entity1["name"])
        name2_norm = self._normalize_for_comparison(entity2["name"])
        return name1_norm == name2_norm

    def _update_importance_from_transcript(self, transcript_text):
        """
        Increments mention_count for existing entities found in the new transcript.
        Uses canonical names for matching to handle variations/typos.
        """
        normalized_transcript = self._normalize_for_mention_check(transcript_text)
        
        for entity in self.entities:
            # Get the canonical name of the *existing* entity for matching
            entity_canonical_name = self._normalize_for_comparison(entity["name"]) 
            
            # Prepare a regex pattern for the canonical name, ensuring whole word match
            # re.escape is important if entity name contains special regex characters
            pattern = r'\b' + re.escape(entity_canonical_name) + r'\b'
            
            if re.search(pattern, normalized_transcript):
                entity["mention_count"] += 1
                self.llm_log.emit({"type": "debug", "message": f"Entity '{entity['name']}' (canonical: '{entity_canonical_name}') ({entity['type']}) mention_count incremented to {entity['mention_count']}"})

    def run(self):
        self.running = True
        if self.model is None:
            self.llm_log.emit({"type": "error", "message": "LLM model not loaded, cannot process entities."})
            self.running = False
            return

        if not self.external_context:
            self.llm_log.emit({"type": "status", "message": "LLM Thread waiting for external context..."})
            while self.running and not self.external_context:
                time.sleep(1)
            if not self.running:
                return

        self.llm_log.emit({"type": "status", "message": "LLM Thread started with external context."})
        while self.running:
            if len(self.transcriptions) > self.last_transcript_processed_idx + 1:
                transcript_to_process = self.transcriptions[self.last_transcript_processed_idx + 1] # Process the next unprocessed transcript
                current_transcript_idx = self.last_transcript_processed_idx + 1 
                
                # Take recent transcripts for better context for LLM
                # Use a sliding window of the last 5 transcripts (including current)
                recent_transcripts = self.transcriptions[max(0, current_transcript_idx - 4):current_transcript_idx + 1]
                
                current_entities_for_llm_prompt = [
                    {"name": e["name"], "type": e["type"], "description": e["description"]}
                    for e in self.entities
                ]

                messages = [
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content":
                     f"Current transcript snippet: {transcript_to_process}\n"
                     f"Recent context (last {len(recent_transcripts)} snippets): {recent_transcripts}\n"
                     f"Current narrative cheat sheet: {json.dumps(current_entities_for_llm_prompt, indent=2)}\n"
                     f"Based on ALL information (current transcript, recent context, full cheat sheet), identify *all identifiable* entities. For EVERY entity you return (new or existing), provide its 'base_importance_score' (1-10) re-evaluated based on its inherent narrative relevance. Remember to include historical dates/years and specific organizations like OSS if mentioned. Ensure to correctly categorize and canonicalize names like 'Easterman'/'Eastman' to 'Hendrick Joliet Easterman', 'Wernick'/'Wernicke' to 'Rudolf Gustav Wernicke', and 'Operation Paperclip'."}
                ]
                self.llm_log.emit({"type": "prompt", "message": f"Prompt for transcript index {current_transcript_idx}", "data": messages})
                
                llm_identified_entities = []
                raw_content_from_llm = ""
                try:
                    response = ollama.chat(
                        model=self.model,
                        messages=messages,
                        stream=False,
                        # Use the new format parameter to enforce JSON schema
                        format=entity_list_schema, # Pass the schema dictionary here
                        options={
                            "temperature": 0.1, # Keep low for deterministic output
                            "top_p": 0.9,       # Keep relatively high
                            "top_k": 40,        # Default is fine
                            "repeat_penalty": 1.0 # Avoid penalizing repeated keys
                        } # Keep these options for output quality
                    )
                    raw_content_from_llm = response['message']['content']
                    self.llm_log.emit({"type": "raw_response", "message": f"Raw LLM response for transcript index {current_transcript_idx}", "data": raw_content_from_llm})

                    # --- Robust JSON Parsing ---
                    parsed_llm_output = None
                    json_string_to_parse = ""

                    try:
                        # Attempt 1: Try to parse directly (most common good case)
                        try:
                            json_string_to_parse = raw_content_from_llm.strip()
                            parsed_llm_output = json.loads(json_string_to_parse)
                        except json.JSONDecodeError:
                            # Attempt 2: Search for a JSON block (e.g., if wrapped in markdown)
                            json_match = re.search(r"```json\s*(.*?)\s*```", raw_content_from_llm, re.DOTALL)
                            if json_match:
                                json_string_to_parse = json_match.group(1).strip()
                                parsed_llm_output = json.loads(json_string_to_parse)
                            else:
                                # Attempt 3: Search for the first valid JSON object (from first { to last })
                                json_match_loose = re.search(r"\{.*\}", raw_content_from_llm, re.DOTALL)
                                if json_match_loose:
                                    json_string_to_parse = json_match_loose.group(0).strip()
                                    parsed_llm_output = json.loads(json_string_to_parse)
                                else:
                                    # Attempt 4: Search for the first valid JSON array (from first [ to last ])
                                    json_match_array_loose = re.search(r"\[.*\]", raw_content_from_llm, re.DOTALL)
                                    if json_match_array_loose:
                                        json_string_to_parse = json_match_array_loose.group(0).strip()
                                        parsed_llm_output = json.loads(json_string_to_parse)
                                    else:
                                        raise json.JSONDecodeError("No recognizable JSON structure found.", raw_content_from_llm, 0)

                    except (json.JSONDecodeError, ValueError) as e:
                        # Handle JSON parsing and structure errors
                        self.llm_log.emit({"type": "error", "message": f"JSON parsing/structure error: {str(e)}\nAttempted to parse:\n{json_string_to_parse if json_string_to_parse else raw_content_from_llm}", "data": raw_content_from_llm})
                        # Proceed with an empty entities list to avoid crashing
                        llm_identified_entities = []
                    except Exception as e:
                        # Handle other potential errors during the LLM call or processing
                        self.llm_log.emit({"type": "error", "message": f"LLM processing failed: {str(e)}"})
                        llm_identified_entities = [] # Ensure it's always a list

                    # Now process the parsed_llm_output
                    if parsed_llm_output is None:
                        self.llm_log.emit({"type": "warning", "message": f"JSON parsing attempts found no valid structure.\nAttempted to parse:\n{raw_content_from_llm}", "data": raw_content_from_llm})
                        llm_identified_entities = [] # Ensure empty list if nothing was parsed
                    elif isinstance(parsed_llm_output, list):
                        # LLM sometimes returns a list of entities directly instead of {"entities": [...]}
                        llm_identified_entities = parsed_llm_output
                    elif isinstance(parsed_llm_output, dict) and 'entities' in parsed_llm_output:
                        llm_identified_entities = parsed_llm_output.get('entities', [])
                    else:
                        raise ValueError(f"Unexpected JSON structure after parsing: {type(parsed_llm_output)} - {json_string_to_parse}")

                    if not isinstance(llm_identified_entities, list):
                        raise ValueError("Expected 'entities' to be a list after parsing.")
                            
                    self.llm_log.emit({"type": "parsed_entities", "message": f"Parsed entities from LLM for transcript index {current_transcript_idx}", "data": llm_identified_entities})

                except (json.JSONDecodeError, ValueError) as e:
                    self.llm_log.emit({"type": "error", "message": f"JSON parsing error: {str(e)}\nAttempted to parse:\n{json_string_to_parse if json_string_to_parse else raw_content_from_llm}", "data": raw_content_from_llm})
                    # Continue with empty entities list if parsing fails, but log the issue
                    llm_identified_entities = []
                except Exception as e:
                    self.llm_log.emit({"type": "error", "message": f"LLM request failed: {str(e)}"})
                    llm_identified_entities = [] # Ensure it's always a list

                # --- Entity Reconciliation and Update ---
                temp_entities_dict = {}
                for e in self.entities:
                    # Use the canonical name and type as the primary key for existing entities
                    normalized_name = self._normalize_for_comparison(e["name"])
                    temp_entities_dict[(normalized_name, e["type"])] = e

                for llm_entity_data in llm_identified_entities:
                    name = llm_entity_data.get("name")
                    raw_type = llm_entity_data.get("type")
                    description = llm_entity_data.get("description")
                    base_importance_score = llm_entity_data.get("base_importance_score")

                    canonical_type = self._normalize_entity_type(raw_type)
                    if canonical_type is None:
                        self.llm_log.emit({"type": "warning", "message": f"Skipping entity with unrecognized type '{raw_type}'.", "entity_data": llm_entity_data})
                        continue
                    type_ = canonical_type

                    if not name:
                        self.llm_log.emit({"type": "warning", "message": f"Skipping invalid entity from LLM (missing name).", "entity_data": llm_entity_data})
                        continue
                    
                    # Ensure base_importance_score is an int within range
                    if not isinstance(base_importance_score, int) or not (1 <= base_importance_score <= 10):
                        self.llm_log.emit({"type": "warning", "message": f"Invalid base_importance_score for '{name}'. Defaulting to 1.", "entity_data": llm_entity_data})
                        base_importance_score = 1

                    # Use the normalized LLM-provided name and canonical type as the key for lookup
                    normalized_key_for_llm_entity = (self._normalize_for_comparison(name), type_)
                    existing_entity = temp_entities_dict.get(normalized_key_for_llm_entity)

                    if existing_entity:
                        # Update existing entity
                        existing_entity["description"] = description if description else existing_entity["description"]
                        
                        # Prioritize update if new name is more complete or has better casing
                        # Only update if the normalized names are the same (already guaranteed by normalized_key)
                        current_normalized_name = self._normalize_for_comparison(existing_entity["name"])
                        new_normalized_name = self._normalize_for_comparison(name)

                        if current_normalized_name == new_normalized_name:
                            # Heuristic: Prefer longer name (more complete) or better casing
                            if len(name) > len(existing_entity["name"]) or \
                               (name and name[0].isupper() and not (existing_entity["name"] and existing_entity["name"][0].isupper())):
                                existing_entity["name"] = name # Update to the better raw name
                        
                        existing_entity["base_importance_score"] = base_importance_score
                        # mention_count is NOT incremented here; it's done by _update_importance_from_transcript
                    else:
                        # Add new entity
                        new_entity = {
                            "name": name,
                            "type": type_, # Use canonical type
                            "description": description if description else "",
                            "base_importance_score": base_importance_score,
                            "mention_count": 0, # Initialize to 0, will be updated by _update_importance_from_transcript later
                            "first_mentioned_idx": current_transcript_idx
                        }
                        temp_entities_dict[normalized_key_for_llm_entity] = new_entity
                
                self.entities = list(temp_entities_dict.values())
                # Now that the entities list is updated, trigger mention count update for the *current* transcript.
                # This ensures any newly identified entities in this round get their first mention counted,
                # and existing entities also get their count incremented if mentioned.
                self._update_importance_from_transcript(transcript_to_process)
                
                self.entities_updated.emit(self.entities)
                self.last_transcript_processed_idx = current_transcript_idx # Mark this index as processed

            time.sleep(2) # Wait a bit before checking for next transcript

    def add_transcription(self, text):
        # Transcriptions are appended here, but processed sequentially in run()
        self.transcriptions.append(text) 

    def get_transcriptions(self):
        return self.transcriptions

    def get_entities(self):
        return self.entities

    def stop(self):
        self.running = False

==================================================
File: .\backend\transcription.py
==================================================
import numpy as np
import whisper
import threading
import time
import queue
from PyQt5.QtCore import QThread, pyqtSignal
from constants import TRANSCRIPT_CHUNK_DURATION_SECONDS

class TranscriptionThread(QThread):
    transcription = pyqtSignal(str)
    error_signal = pyqtSignal(str)

    def __init__(self):
        super().__init__()
        try:
            self.model = whisper.load_model("small.en")
        except Exception as e:
            self.error_signal.emit(f"Failed to load Whisper model: {e}")
            self.model = None

        self.audio_buffer = np.array([], dtype=np.float32)
        self.running = False
        self.buffer_lock = threading.Lock()
        self._stop_event = threading.Event()

    def run(self):
        self.running = True
        self._stop_event.clear()

        while self.running:
            audio_to_process = None
            with self.buffer_lock:
                if len(self.audio_buffer) >= 16000 * TRANSCRIPT_CHUNK_DURATION_SECONDS: 
                    audio_to_process = self.audio_buffer[:16000 * TRANSCRIPT_CHUNK_DURATION_SECONDS].copy()
                    self.audio_buffer = self.audio_buffer[16000 * TRANSCRIPT_CHUNK_DURATION_SECONDS:]
            
            if audio_to_process is not None:
                try:
                    if audio_to_process.dtype != np.float32:
                        audio_to_process = audio_to_process.astype(np.float32) / 32768.0

                    result = self.model.transcribe(audio_to_process, language="en")
                    if result["text"].strip():
                        self.transcription.emit(result["text"])
                except Exception as e:
                    self.error_signal.emit(f"Transcription Error: {e}")
                    # print(f"Transcription Error: {e}", file=sys.stderr) # Removed sys.stderr import
            time.sleep(0.1)
            if self._stop_event.is_set():
                break

    def add_audio(self, audio_data):
        with self.buffer_lock:
            if audio_data.dtype != np.float32:
                audio_data = audio_data.astype(np.float32) / 32768.0
            self.audio_buffer = np.append(self.audio_buffer, audio_data.flatten())

    def stop(self):
        self.running = False
        self._stop_event.set()

==================================================
File: .\backend\web_search.py
==================================================
import json # Not directly used but often helpful for debugging DDGS results
from duckduckgo_search import DDGS
from PyQt5.QtCore import QThread, pyqtSignal

class WebSearchThread(QThread):
    context_ready = pyqtSignal(str)
    error_signal = pyqtSignal(str)

    def __init__(self, title):
        super().__init__()
        self.title = title

    def run(self):
        try:
            search_query = f"{self.title} plot summary OR overview"
            with DDGS() as ddgs:
                results = list(ddgs.text(search_query, max_results=5))

            context_lines = []
            for r in results:
                if r.get('body'):
                    context_lines.append(f"- {r['title']}: {r['body']}")
                elif r.get('link'):
                    context_lines.append(f"- {r['title']} ({r['link']})")
            
            full_context = "\n".join(context_lines)

            if not full_context:
                self.error_signal.emit(f"Warning: No significant web context found for '{self.title}'. LLM may operate with limited external knowledge.")
                full_context = f"No specific plot context found for the content titled '{self.title}'."

            self.context_ready.emit(full_context)
        except Exception as e:
            self.error_signal.emit(f"Error during web search for '{self.title}': {str(e)}. LLM will operate without external context.")
            self.context_ready.emit(f"Web search failed. No external context provided for '{self.title}'.")

==================================================
File: .\constants.py
==================================================
# Constants for time calculation (approximate)
# This assumes the TranscriptionThread processes fixed 10-second chunks.
TRANSCRIPT_CHUNK_DURATION_SECONDS = 10

==================================================
File: .\frontend\main_window.py
==================================================
import sys
import json
import numpy as np
import time 
from datetime import datetime

from PyQt5.QtWidgets import (
    QMainWindow, QWidget, QVBoxLayout,
    QHBoxLayout, QPushButton, QTextEdit, QTableWidget,
    QTableWidgetItem, QInputDialog, QSplitter, QLineEdit,
    QLabel, QFrame, QTabWidget, QScrollArea, QSizePolicy,
    QApplication, QStyle
)
from PyQt5.QtCore import QThread, pyqtSignal, Qt, QSize
from PyQt5.QtGui import QIcon

from backend.audio_capture import AudioCaptureThread
from backend.transcription import TranscriptionThread
from backend.web_search import WebSearchThread
from backend.llm_processing import LLMThread
from backend.chat_agent import ChatThread
from constants import TRANSCRIPT_CHUNK_DURATION_SECONDS

class NarrativeNavigator(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Narrative Navigator AI")
        self.setGeometry(100, 100, 1200, 800)
        self.setMinimumSize(800, 600)

        self.audio_thread = AudioCaptureThread()
        self.transcription_thread = TranscriptionThread()
        self.llm_thread = LLMThread()
        self.chat_thread = None
        self.web_search_thread = None
        self.content_title = ""
        self.minimum_display_score = 3 
        
        self.cheat_sheet_column_widths = {} 

        self.init_ui()

        self.audio_thread.audio_data.connect(self.transcription_thread.add_audio)
        self.audio_thread.error_signal.connect(lambda msg: self.update_llm_log_tabs({"type": "error", "message": msg})) 
        self.transcription_thread.transcription.connect(self.handle_transcription)
        self.transcription_thread.error_signal.connect(lambda msg: self.update_llm_log_tabs({"type": "error", "message": msg}))
        self.llm_thread.entities_updated.connect(self.update_entity_displays) 
        self.llm_thread.llm_log.connect(self.update_llm_log_tabs)

        self.get_content_title_and_context()

    def init_ui(self):
        main_container = QWidget()
        self.setCentralWidget(main_container)
        main_layout = QVBoxLayout(main_container)
        main_layout.setContentsMargins(0, 0, 0, 0)
        main_layout.setSpacing(0)

        header_widget = QWidget()
        header_widget.setObjectName("headerWidget")
        header_layout = QHBoxLayout(header_widget)
        header_layout.setContentsMargins(20, 10, 20, 10)
        header_layout.setSpacing(15)

        app_logo = QLabel()
        app_logo.setPixmap(self.style().standardIcon(QStyle.SP_ComputerIcon).pixmap(QSize(32, 32)))
        
        app_name_label = QLabel("Narrative Navigator")
        app_name_label.setObjectName("appNameLabel")

        self.analysis_status_label = QLabel("Analyzing: [FULL] Beyond Boiling Point - Gordon Ramsay documentary (2000)")
        self.analysis_status_label.setObjectName("analysisStatusLabel")
        self.analysis_status_label.setAlignment(Qt.AlignLeft | Qt.AlignVCenter)
        self.analysis_status_label.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred)

        header_layout.addWidget(app_logo)
        header_layout.addWidget(app_name_label)
        header_layout.addWidget(self.analysis_status_label)

        self.volume_button = QPushButton()
        self.volume_button.setIcon(self.style().standardIcon(QStyle.SP_MediaVolume))
        self.volume_button.setObjectName("iconButton")
        self.volume_button.setIconSize(QSize(20, 20))
        self.volume_button.setFixedSize(36, 36)

        self.toggle_button = QPushButton("Stop Recording")
        self.toggle_button.setObjectName("stopRecordingButton")
        self.toggle_button.clicked.connect(self.toggle_processing)
        self.toggle_button.setEnabled(False)

        self.close_button = QPushButton()
        self.close_button.setIcon(self.style().standardIcon(QStyle.SP_DialogCloseButton))
        self.close_button.setObjectName("iconButton")
        self.close_button.setIconSize(QSize(20,20))
        self.close_button.setFixedSize(36,36)
        self.close_button.clicked.connect(self.close)

        header_layout.addWidget(self.volume_button)
        header_layout.addWidget(self.toggle_button)
        header_layout.addWidget(self.close_button)

        main_layout.addWidget(header_widget)

        content_splitter = QSplitter(Qt.Horizontal)
        content_splitter.setContentsMargins(10, 0, 10, 10) 

        self.tab_widget = QTabWidget()
        self.tab_widget.setObjectName("mainTabWidget")
        content_splitter.addWidget(self.tab_widget)

        self.overview_tab_page = self._create_overview_tab()
        self.story_elements_tab_page = self._create_story_elements_tab()
        self.live_transcript_tab_page = self._create_live_transcript_tab()
        self.ai_chat_tab_page = self._create_ai_chat_tab()
        self.llm_log_tab_page = self._create_llm_log_tab() 

        self.tab_widget.addTab(self.overview_tab_page, "Overview")
        self.tab_widget.addTab(self.story_elements_tab_page, "Story Elements")
        self.tab_widget.addTab(self.live_transcript_tab_page, "Live Transcript")
        self.tab_widget.addTab(self.ai_chat_tab_page, "AI Chat")
        self.tab_widget.addTab(self.llm_log_tab_page, "LLM Log")

        right_panel = QWidget()
        right_panel.setObjectName("rightPanel")
        right_layout = QVBoxLayout(right_panel)
        right_layout.setContentsMargins(15, 15, 15, 15)
        right_layout.setSpacing(10)

        cheat_sheet_label = QLabel("Narrative Cheat Sheet")
        cheat_sheet_label.setObjectName("sectionTitle") 
        right_layout.addWidget(cheat_sheet_label)

        self.cheat_sheet_table = QTableWidget() 
        self.cheat_sheet_table.setColumnCount(6)
        self.cheat_sheet_table.setHorizontalHeaderLabels(["Name", "Type", "Description", "Base Score", "Mentions", "Current Score"])
        self.cheat_sheet_table.setEditTriggers(QTableWidget.NoEditTriggers)
        self.cheat_sheet_table.verticalHeader().setVisible(False)
        self.cheat_sheet_table.setAlternatingRowColors(True)
        self.cheat_sheet_table.setObjectName("cheatSheetTable") 
        right_layout.addWidget(self.cheat_sheet_table)

        self.cheat_sheet_column_widths = {
            0: 120,   # Name
            1: 100,   # Type
            2: 250,   # Description
            3: 80,    # Base Score
            4: 70,    # Mentions
            5: 100    # Current Score
        }
        for i, width in self.cheat_sheet_column_widths.items():
            self.cheat_sheet_table.setColumnWidth(i, width)

        self.cheat_sheet_table.horizontalHeader().sectionResized.connect(self._on_cheat_sheet_column_resized)

        content_splitter.addWidget(right_panel)
        content_splitter.setSizes([800, 400]) 
        main_layout.addWidget(content_splitter)

    def _on_cheat_sheet_column_resized(self, logicalIndex, oldSize, newSize):
        """Slot to remember user-resized column widths."""
        self.cheat_sheet_column_widths[logicalIndex] = newSize

    def _create_overview_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        title_label = QLabel("Overview")
        title_label.setObjectName("sectionTitle")
        tab_layout.addWidget(title_label)

        metrics_layout = QHBoxLayout()
        metrics_layout.setSpacing(15)
        
        self.characters_count_label = QLabel("0") 
        self.locations_count_label = QLabel("0") 
        self.transcript_lines_count_label = QLabel("0")
        self.total_elements_count_label = QLabel("0") 

        metrics_layout.addWidget(self._create_summary_card(self.characters_count_label, "Characters", QStyle.SP_MessageBoxInformation)) 
        metrics_layout.addWidget(self._create_summary_card(self.locations_count_label, "Locations", QStyle.SP_DirIcon)) 
        metrics_layout.addWidget(self._create_summary_card(self.transcript_lines_count_label, "Transcript Lines", QStyle.SP_FileIcon)) 
        metrics_layout.addWidget(self._create_summary_card(self.total_elements_count_label, "Total Elements", QStyle.SP_MessageBoxQuestion)) 
        tab_layout.addLayout(metrics_layout)

        recent_activity_widget = QFrame()
        recent_activity_widget.setProperty("class", "contentCard")
        recent_activity_layout = QVBoxLayout(recent_activity_widget)
        recent_activity_layout.setContentsMargins(15,15,15,15)
        recent_activity_layout.setSpacing(10)

        recent_activity_layout.addWidget(QLabel("Recent Activity"))
        self.recent_activity_display = QTextEdit()
        self.recent_activity_display.setReadOnly(True)
        self.recent_activity_display.setPlaceholderText("Latest story elements and transcript updates...")
        self.recent_activity_display.setFixedHeight(150)
        recent_activity_layout.addWidget(self.recent_activity_display)
        tab_layout.addWidget(recent_activity_widget)

        key_characters_widget = QFrame()
        key_characters_widget.setProperty("class", "contentCard")
        key_characters_layout = QVBoxLayout(key_characters_widget)
        key_characters_layout.setContentsMargins(15,15,15,15)
        key_characters_layout.setSpacing(10)
        
        key_characters_layout.addWidget(QLabel("Key Characters"))
        self.key_characters_container_layout = QVBoxLayout()
        self.key_characters_container_layout.setContentsMargins(0,0,0,0)
        self.key_characters_container_layout.setSpacing(8)
        
        self.key_characters_container_layout.addStretch() 

        key_characters_layout.addLayout(self.key_characters_container_layout)
        tab_layout.addWidget(key_characters_widget)

        tab_layout.addStretch() 
        return tab_page

    def _create_summary_card(self, count_label_ref, label_text, icon_style_hint):
        card = QFrame()
        card.setProperty("class", "contentCard")
        card.setFixedSize(160, 120)
        card_layout = QVBoxLayout(card)
        card_layout.setAlignment(Qt.AlignCenter)
        card_layout.setContentsMargins(10, 10, 10, 10)
        card_layout.setSpacing(5)

        icon_label = QLabel()
        icon_label.setPixmap(self.style().standardIcon(icon_style_hint).pixmap(QSize(30, 30)))
        card_layout.addWidget(icon_label, alignment=Qt.AlignCenter)

        count_label_ref.setStyleSheet("font-size: 28px; font-weight: bold; color: #6a0dad;")
        card_layout.addWidget(count_label_ref, alignment=Qt.AlignCenter)

        text_label = QLabel(label_text)
        text_label.setStyleSheet("font-size: 13px; color: #555555; font-weight: 500;")
        card_layout.addWidget(text_label, alignment=Qt.AlignCenter)
        return card

    def _create_story_elements_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        title_label = QLabel("Story Elements")
        title_label.setObjectName("sectionTitle")
        tab_layout.addWidget(title_label)

        scroll_area = QScrollArea()
        scroll_area.setWidgetResizable(True)
        scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        scroll_area.setFrameShape(QFrame.NoFrame)

        self.story_elements_content_widget = QWidget()
        self.story_elements_container_layout = QVBoxLayout(self.story_elements_content_widget)
        self.story_elements_container_layout.setContentsMargins(0, 0, 0, 0)
        self.story_elements_container_layout.setSpacing(10)

        self.story_elements_container_layout.addStretch() 

        scroll_area.setWidget(self.story_elements_content_widget)
        tab_layout.addWidget(scroll_area)
        
        return tab_page
    
    def _create_entity_card(self, entity_data, first_mentioned_time="00:00:00"):
        card = QFrame()
        card.setProperty("class", "storyElementCard")

        card_layout = QHBoxLayout(card)
        card_layout.setContentsMargins(0, 0, 0, 0) 
        card_layout.setSpacing(5) 

        icon_label = QLabel()
        if entity_data["type"] == "Characters":
            icon_label.setPixmap(self.style().standardIcon(QStyle.SP_MessageBoxInformation).pixmap(QSize(16, 16)))
        elif entity_data["type"] == "Locations":
            icon_label.setPixmap(self.style().standardIcon(QStyle.SP_DirIcon).pixmap(QSize(16, 16)))
        elif entity_data["type"] == "Organizations":
            icon_label.setPixmap(self.style().standardIcon(QStyle.SP_DesktopIcon).pixmap(QSize(16, 16)))
        else: 
            icon_label.setPixmap(self.style().standardIcon(QStyle.SP_FileIcon).pixmap(QSize(16, 16)))
        card_layout.addWidget(icon_label)

        element_name = QLabel(entity_data["name"])
        element_name.setProperty("property", "nameLabel") 
        card_layout.addWidget(element_name)
        
        category_tag = QLabel(entity_data["type"])
        category_tag.setProperty("class", "categoryTag") 
        category_tag.setObjectName(f"categoryTag-{entity_data['type'].replace(' ', '')}")
        card_layout.addWidget(category_tag)

        separator = QLabel("—") 
        separator.setStyleSheet("color: #aaaaaa; margin: 0 5px;")
        card_layout.addWidget(separator)

        description_text = entity_data.get("description", "No description available")
        max_desc_length = 80 
        if len(description_text) > max_desc_length:
            description_text = description_text[:max_desc_length].strip() + "..."
        
        description = QLabel(description_text)
        description.setProperty("property", "descriptionLabel") 
        description.setWordWrap(False) 
        description.setTextFormat(Qt.PlainText) 
        description.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred) 
        card_layout.addWidget(description)

        card_layout.addStretch() 

        first_mentioned = QLabel(f"First mentioned: {first_mentioned_time}")
        first_mentioned.setProperty("property", "timeLabel") 
        card_layout.addWidget(first_mentioned)
        
        return card

    def _create_live_transcript_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        header_layout = QHBoxLayout()
        mic_icon = QLabel()
        mic_icon.setPixmap(self.style().standardIcon(QStyle.SP_MediaVolume).pixmap(QSize(24, 24)))
        header_layout.addWidget(mic_icon)
        
        title_label = QLabel("Live Transcript")
        title_label.setObjectName("sectionTitle")
        header_layout.addWidget(title_label)

        self.processing_tag = QLabel("Processing")
        self.processing_tag.setProperty("class", "processingTag")
        self.processing_tag.setVisible(False)
        header_layout.addWidget(self.processing_tag)
        header_layout.addStretch()
        tab_layout.addLayout(header_layout)

        self.transcript_display = QTextEdit()
        self.transcript_display.setReadOnly(True)
        self.transcript_display.setPlaceholderText("Live transcription will appear here...")
        tab_layout.addWidget(self.transcript_display)
        
        return tab_page

    def _create_ai_chat_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        header_layout = QHBoxLayout()
        ai_icon = QLabel()
        ai_icon.setPixmap(self.style().standardIcon(QStyle.SP_MessageBoxQuestion).pixmap(QSize(24, 24)))
        header_layout.addWidget(ai_icon)
        
        title_label = QLabel("AI Story Assistant")
        title_label.setObjectName("sectionTitle")
        header_layout.addWidget(title_label)
        header_layout.addStretch()
        tab_layout.addLayout(header_layout)

        self.chat_display = QTextEdit()
        self.chat_display.setReadOnly(True)
        self.chat_display.setPlaceholderText("Chat with the AI about the story...")
        tab_layout.addWidget(self.chat_display)

        chat_input_container = QFrame()
        chat_input_container.setObjectName("chatInputContainer")
        chat_input_layout = QHBoxLayout(chat_input_container)
        chat_input_layout.setContentsMargins(0, 0, 0, 0)
        chat_input_layout.setSpacing(0)

        self.chat_input = QLineEdit()
        self.chat_input.setPlaceholderText("Ask about characters, plot, or story elements...")
        self.chat_input.returnPressed.connect(self.send_chat_query)
        chat_input_layout.addWidget(self.chat_input)

        send_button = QPushButton()
        send_button.setIcon(self.style().standardIcon(QStyle.SP_ArrowRight))
        send_button.setIconSize(QSize(20, 20))
        send_button.setFixedSize(40, 40)
        send_button.setObjectName("sendButton")
        send_button.clicked.connect(self.send_chat_query)
        chat_input_layout.addWidget(send_button)

        tab_layout.addWidget(chat_input_container)
        return tab_page

    def _create_llm_log_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        title_label = QLabel("LLM Processing Log")
        title_label.setObjectName("sectionTitle")
        tab_layout.addWidget(title_label)

        self.llm_log_tabs = QTabWidget()
        self.llm_log_tabs.setObjectName("llmLogSubTabs")

        raw_log_tab = QWidget()
        raw_log_layout = QVBoxLayout(raw_log_tab)
        self.llm_raw_log_display = QTextEdit()
        self.llm_raw_log_display.setReadOnly(True)
        self.llm_raw_log_display.setPlaceholderText("Raw LLM prompts and responses will appear here...")
        raw_log_layout.addWidget(self.llm_raw_log_display)
        self.llm_log_tabs.addTab(raw_log_tab, "Raw Interactions")

        parsed_entities_tab = QWidget()
        parsed_entities_layout = QVBoxLayout(parsed_entities_tab)
        self.llm_parsed_entities_table = QTableWidget()
        self.llm_parsed_entities_table.setColumnCount(4) 
        self.llm_parsed_entities_table.setHorizontalHeaderLabels(["Name", "Type", "Description", "Base Score"])
        self.llm_parsed_entities_table.setEditTriggers(QTableWidget.NoEditTriggers)
        self.llm_parsed_entities_table.verticalHeader().setVisible(False)
        self.llm_parsed_entities_table.setAlternatingRowColors(True)
        self.llm_parsed_entities_table.horizontalHeader().setStretchLastSection(True)
        self.llm_parsed_entities_table.setObjectName("llmParsedEntitiesTable")
        parsed_entities_layout.addWidget(self.llm_parsed_entities_table)
        self.llm_log_tabs.addTab(parsed_entities_tab, "Parsed Entities (Latest)")

        errors_warnings_tab = QWidget()
        errors_warnings_layout = QVBoxLayout(errors_warnings_tab)
        self.llm_error_warnings_display = QTextEdit()
        self.llm_error_warnings_display.setReadOnly(True)
        self.llm_error_warnings_display.setPlaceholderText("LLM-related errors and warnings will appear here...")
        self.llm_error_warnings_display.setStyleSheet("QTextEdit { color: #8B0000; }") 
        errors_warnings_layout.addWidget(self.llm_error_warnings_display)
        self.llm_log_tabs.addTab(errors_warnings_tab, "Errors & Warnings")

        tab_layout.addWidget(self.llm_log_tabs)
        return tab_page

    def get_content_title_and_context(self):
        # Create a QInputDialog instance to set window flags
        dialog = QInputDialog(self)
        dialog.setWindowTitle("Content Title")
        dialog.setLabelText("Please enter the title of the content you are watching:")
        dialog.setTextEchoMode(QLineEdit.Normal)
        dialog.setTextValue("The Outlast Trials Lore") # Default text
        
        # Set the window flag to always stay on top
        dialog.setWindowFlags(dialog.windowFlags() | Qt.WindowStaysOnTopHint)
        
        # Execute the dialog and get the result
        ok = dialog.exec_() # Use exec_() for modal dialogs
        title = dialog.textValue() # Get the entered text
        
        if ok and title:
            self.content_title = title.strip()
            self.analysis_status_label.setText(f"Analyzing: [FULL] {self.content_title}")
            if not self.content_title:
                self.update_llm_log_tabs({"type": "error", "message": "Empty content title provided. LLM will operate without specific external context."})
                self.llm_thread.set_external_context("No external context provided by user.")
                self.init_chat_thread()
                self.toggle_button.setEnabled(True)
                return

            self.llm_thread.set_content_title(self.content_title)
            self.update_llm_log_tabs({"type": "status", "message": f"Searching for external context for: '{self.content_title}'..."})
            self.web_search_thread = WebSearchThread(self.content_title)
            self.web_search_thread.context_ready.connect(self.set_llm_external_context)
            self.web_search_thread.error_signal.connect(lambda msg: self.update_llm_log_tabs({"type": "error", "message": msg})) 
            self.web_search_thread.start()
        else:
            self.update_llm_log_tabs({"type": "status", "message": "No content title provided. LLM will operate without specific external context."})
            self.llm_thread.set_external_context("No external context provided by user.")
            self.init_chat_thread()
            self.toggle_button.setEnabled(True)

    def set_llm_external_context(self, context):
        self.llm_thread.set_external_context(context)
        self.update_llm_log_tabs({"type": "status", "message": f"External context loaded for LLM (showing first 500 chars):\n<pre>{context[:500]}...</pre>"})
        if len(context) > 500:
            self.update_llm_log_tabs({"type": "status", "message": f"...\n(Full context is {len(context)} characters long)"})
        self.init_chat_thread()
        self.toggle_button.setEnabled(True)
        self.toggle_button.setText("Start Recording")
        self.update_llm_log_tabs({"type": "status", "message": "You can now click 'Start Recording' to begin audio processing and entity extraction."})

    def init_chat_thread(self):
        if self.chat_thread and self.chat_thread.isRunning():
            self.chat_thread.stop()
            self.chat_thread.wait()

        self.chat_thread = ChatThread(
            transcript_getter=self.llm_thread.get_transcriptions,
            entities_getter=self.llm_thread.get_entities,
            content_title=self.content_title,
            external_context=self.llm_thread.external_context
        )
        self.chat_thread.chat_response.connect(self.display_chat_response)
        self.chat_thread.chat_log.connect(self.update_llm_log_tabs) 
        self.chat_thread.start()
        self.update_llm_log_tabs({"type": "status", "message": "Chat thread initialized."})

    def toggle_processing(self):
        if self.toggle_button.text() == "Start Recording":
            self.audio_thread.start()
            self.transcription_thread.start()
            self.llm_thread.start()
            self.toggle_button.setText("Stop Recording")
            self.processing_tag.setVisible(True)
            self.update_llm_log_tabs({"type": "status", "message": "Processing started."})
        else:
            self.stop_processing()
            self.toggle_button.setText("Start Recording")
            self.processing_tag.setVisible(False)
            self.update_llm_log_tabs({"type": "status", "message": "Processing stopped."})

    def stop_processing(self):
        self.llm_thread.stop()
        self.transcription_thread.stop()
        self.audio_thread.stop()
        self.llm_thread.wait()
        self.transcription_thread.wait()
        self.audio_thread.wait()
        self.update_llm_log_tabs({"type": "status", "message": "All processing threads stopped."})

    def handle_transcription(self, text):
        if self.transcript_display:
            self.transcript_display.append(text)
            self.transcript_display.verticalScrollBar().setValue(self.transcript_display.verticalScrollBar().maximum())
            current_lines = int(self.transcript_lines_count_label.text())
            self.transcript_lines_count_label.setText(str(current_lines + 1))

        self.llm_thread.add_transcription(text) 
        self.recent_activity_display.append(f"Transcript: {text[:80].strip()}...")
        self.recent_activity_display.verticalScrollBar().setValue(self.recent_activity_display.verticalScrollBar().maximum())

    def update_entity_displays(self, all_entities):
        for e in all_entities:
            e["current_importance_score"] = e.get("base_importance_score", 0) + e.get("mention_count", 0)

        scores = [e["current_importance_score"] for e in all_entities]
        
        display_threshold = self.minimum_display_score 
        
        if scores:
            median_score = np.median(scores)
            display_threshold = max(self.minimum_display_score, median_score)
            self.update_llm_log_tabs({"type": "debug", "message": f"Calculated median importance score: {median_score:.2f}. Display threshold set to: {display_threshold:.2f}"})
        else:
            self.update_llm_log_tabs({"type": "debug", "message": "No entities yet to calculate median score. Display threshold is default minimum."})

        filtered_for_display_tabs = [e for e in all_entities if e["current_importance_score"] >= display_threshold]
        filtered_for_display_tabs.sort(key=lambda e: (e["type"], -e["current_importance_score"], e["name"].lower()))

        def clear_layout(layout):
            if layout is None:
                return
            while layout.count():
                item = layout.takeAt(0)
                widget = item.widget()
                nested_layout = item.layout()
                
                if widget is not None:
                    widget.setParent(None)
                    widget.deleteLater()
                elif nested_layout is not None:
                    clear_layout(nested_layout)
                    del item 
                else: 
                    del item
        
        clear_layout(self.story_elements_container_layout)
        for entity in filtered_for_display_tabs:
            first_mentioned_time_seconds = entity.get("first_mentioned_idx", 0) * TRANSCRIPT_CHUNK_DURATION_SECONDS
            minutes = int(first_mentioned_time_seconds // 60)
            seconds = int(first_mentioned_time_seconds % 60)
            time_str = f"{minutes:02d}:{seconds:02d}"

            entity_card = self._create_entity_card(entity, time_str) 
            self.story_elements_container_layout.addWidget(entity_card)
        self.story_elements_container_layout.addStretch() 

        clear_layout(self.key_characters_container_layout)
        key_characters = [e for e in filtered_for_display_tabs if e["type"] == "Characters"]
        key_characters.sort(key=lambda e: -e["current_importance_score"]) 

        for char_entity in key_characters:
            first_mentioned_time_seconds = char_entity.get("first_mentioned_idx", 0) * TRANSCRIPT_CHUNK_DURATION_SECONDS
            minutes = int(first_mentioned_time_seconds // 60)
            seconds = int(first_mentioned_time_seconds % 60)
            time_str = f"{minutes:02d}:{seconds:02d}"

            char_card = self._create_entity_card(char_entity, time_str)
            self.key_characters_container_layout.addWidget(char_card)
        self.key_characters_container_layout.addStretch() 

        self.cheat_sheet_table.setRowCount(len(all_entities))
        
        for col_idx in range(self.cheat_sheet_table.columnCount()):
            if col_idx in self.cheat_sheet_column_widths:
                self.cheat_sheet_table.setColumnWidth(col_idx, self.cheat_sheet_column_widths[col_idx])

        all_entities_sorted_for_table = sorted(all_entities, key=lambda e: (e["type"], e["name"].lower()))

        for i, entity in enumerate(all_entities_sorted_for_table):
            self.cheat_sheet_table.setItem(i, 0, QTableWidgetItem(entity["name"]))
            self.cheat_sheet_table.setItem(i, 1, QTableWidgetItem(entity["type"]))
            description_item = QTableWidgetItem(entity.get("description", "No description available"))
            self.cheat_sheet_table.setItem(i, 2, description_item)
            self.cheat_sheet_table.setItem(i, 3, QTableWidgetItem(str(entity.get("base_importance_score", 0)))) 
            self.cheat_sheet_table.setItem(i, 4, QTableWidgetItem(str(entity.get("mention_count", 0))))      
            self.cheat_sheet_table.setItem(i, 5, QTableWidgetItem(str(entity.get("current_importance_score", 0)))) 
            
        char_count = sum(1 for e in filtered_for_display_tabs if e["type"] == "Characters")
        loc_count = sum(1 for e in filtered_for_display_tabs if e["type"] == "Locations")
        total_elements_displayed = len(filtered_for_display_tabs)

        self.characters_count_label.setText(str(char_count))
        self.locations_count_label.setText(str(loc_count))
        self.total_elements_count_label.setText(str(total_elements_displayed))
        
        self.recent_activity_display.append(f"Entities updated: {len(all_entities)} total found, {total_elements_displayed} displayed (>= threshold).")
        self.recent_activity_display.verticalScrollBar().setValue(self.recent_activity_display.verticalScrollBar().maximum())

    def update_llm_log_tabs(self, log_data):
        timestamp = datetime.now().strftime("[%H:%M:%S]")
        log_type = log_data.get("type", "unknown")
        message = log_data.get("message", "No message provided")
        data = log_data.get("data")

        formatted_message = f"<p style='margin-bottom: 5px;'>{timestamp} <b>[{log_type.upper()}]</b>: {message}</p>"
        
        if log_type == "prompt":
            formatted_message += f"<pre style='background-color: #e6e6fa; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "raw_response":
            formatted_message += f"<pre style='background-color: #f0f0f0; padding: 10px; border-radius: 5px;'><code>{data}</code></pre>"
        elif log_type == "parsed_entities":
            formatted_message += f"<pre style='background-color: #f0f8ff; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "chat_prompt": 
            formatted_message += f"<pre style='background-color: #e0e7ff; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "chat_response": 
            formatted_message += f"<pre style='background-color: #f0f2f5; padding: 10px; border-radius: 5px;'><code>{data}</code></pre>"
        elif log_type == "error":
             formatted_message = f"<p style='color: #CC0000; margin-bottom: 5px;'>{timestamp} <b>[ERROR]</b>: {message}</p>"
             if data: 
                 formatted_message += f"<pre style='background-color: #ffe6e6; padding: 10px; border-radius: 5px; color: #CC0000;'><code>{data}</code></pre>"
        elif log_type == "warning":
            formatted_message = f"<p style='color: #FF8C00; margin-bottom: 5px;'>{timestamp} <b>[WARNING]</b>: {message}</p>"
            if data: 
                formatted_message += f"<pre style='background-color: #fff8e6; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "debug":
            formatted_message = f"<p style='color: #555555; margin-bottom: 5px;'>{timestamp} <b>[DEBUG]</b>: {message}</p>"
            if data:
                formatted_message += f"<pre style='background-color: #e0e0e0; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "status": 
            formatted_message = f"<p style='color: #337ab7; margin-bottom: 5px;'>{timestamp} <b>[STATUS]</b>: {message}</p>"

        self.llm_raw_log_display.append(formatted_message)
        self.llm_raw_log_display.verticalScrollBar().setValue(self.llm_raw_log_display.verticalScrollBar().maximum())

        if log_type == "parsed_entities":
            self.llm_parsed_entities_table.setRowCount(len(data))
            for i, entity in enumerate(data):
                self.llm_parsed_entities_table.setItem(i, 0, QTableWidgetItem(entity.get("name", "")))
                self.llm_parsed_entities_table.setItem(i, 1, QTableWidgetItem(entity.get("type", "")))
                self.llm_parsed_entities_table.setItem(i, 2, QTableWidgetItem(entity.get("description", "")))
                self.llm_parsed_entities_table.setItem(i, 3, QTableWidgetItem(str(entity.get("base_importance_score", ""))))
            self.llm_parsed_entities_table.resizeColumnsToContents() 

        elif log_type in ["error", "warning", "chat_error"]:
            error_message = f"{timestamp} [{log_type.upper()}]: {message}"
            if "entity_data" in log_data and log_data["entity_data"]:
                error_message += f" (Entity: {json.dumps(log_data['entity_data'])})"
            self.llm_error_warnings_display.append(error_message)
            self.llm_error_warnings_display.verticalScrollBar().setValue(self.llm_error_warnings_display.verticalScrollBar().maximum())
        
    def send_chat_query(self):
        query = self.chat_input.text().strip()
        if not query:
            return
        self.chat_display.append(f"<div style='color: #333333; margin-bottom: 5px; font-weight: bold;'>User:</div><div style='background-color: #e0e7ff; padding: 10px; border-radius: 8px; margin-bottom: 10px;'>{query}</div>")
        self.chat_thread.add_chat_query(query)
        self.chat_input.clear()
        self.chat_display.verticalScrollBar().setValue(self.chat_display.verticalScrollBar().maximum())

    def display_chat_response(self, response):
        self.chat_display.append(f"<div style='color: #6a0dad; margin-bottom: 5px; font-weight: bold;'>AI:</div><div style='background-color: #f0f2f5; padding: 10px; border-radius: 8px; margin-bottom: 10px;'>{response}</div>")
        self.chat_display.verticalScrollBar().setValue(self.chat_display.verticalScrollBar().maximum())

    def closeEvent(self, event):
        try:
            self.stop_processing()
            if self.chat_thread:
                self.chat_thread.stop()
                self.chat_thread.wait()
            if self.web_search_thread and self.web_search_thread.isRunning():
                self.web_search_thread.quit()
                self.web_search_thread.wait()
            event.accept()
        except Exception as e:
            print(f"Error during cleanup: {e}", file=sys.stderr)
            event.accept()

==================================================
File: .\llm_prompts.py
==================================================
# LLM system prompt for entity extraction
base_system_prompt = """
You are an AI designed to extract narrative entities from transcribed audio for a "cheat sheet" to help users understand a story.

The content you are analyzing is titled: "{content_title}".
Here is some external context about the content to help you identify relevant entities and their significance:
---
{external_context}
---

Your primary goal is to identify *all identifiable* named entities that contribute to understanding the narrative. Be **exceptionally comprehensive** in your extraction. Do NOT filter entities based on your perceived importance for display; list all that are mentioned. The UI will handle dynamic filtering based on scores.

When identifying entities, be mindful of variations, nicknames, acronyms, or common misspellings (e.g., "Eastman" vs. "Easterman", "Wernick" vs. "Wernicke", "US" vs. "United States"). Always strive to use the most complete, formal, or specific name as the primary "name" for the entity.

**Entity Categorization (Use these EXACT names only):**
-   **Characters**: Specific named individuals, historical figures (e.g., "Stalin", "Harry S. Truman", "Hendrick Joliet Easterman", "Rudolf Gustav Wernicke", "Jameson Lawler", "Abe Bradley Aviano").
-   **Locations**: Places, settings, countries, cities (e.g., "Hiroshima", "Nagasaki", "Poland", "Germany", "Italy", "Japan", "United States", "Soviet Union", "Los Alamos", "Hong Kong", "Eniwetok Atoll", "Chicago", "Mount Massive Asylum").
-   **Organizations**: Groups, agencies, governments, corporations (e.g., "USSR", "Office of Strategic Services (OSS)", "Central Intelligence Agency", "Nazi Germany", "Kingdom of Italy", "Empire of Japan", "Murkoff Corporation", "Axis powers", "Korean people's army").
-   **Key Objects**: Distinctive items crucial to the plot or events (e.g., "atomic bomb", "hydrogen bomb", "Walrider", "LSD").
-   **Concepts/Events**: Historical periods, specific significant dates/years (when representing an event), major conflicts, scientific advancements, named projects or programs (e.g., "Cold War", "1939", "1945", "1947", "1949", "1951", "1953", "World War II", "Second World War", "nuclear age", "arms race", "Operation Paperclip", "Project Bluebird", "Project Artichoke", "space race", "season 1 of The Outlast Trials", "season 2 of The Outlast series").

- **Further Instructions for Entities:**
    - Ensure "name" is non-empty for valid entities.
    - Only include entities explicitly mentioned in the transcript or external context.
    - If no identifiable entities are found in a snippet, return an empty "entities" list.
    - Maintain context from conversation history; if an entity was previously identified, you can re-mention it to update its score.
    - Provide brief descriptions (max 10 words), focusing on their narrative role or key characteristic.

- **Scoring Guidance for 'base_importance_score' (1-10):**
    - This score reflects your assessment of its inherent relevance and criticality to the overall narrative, plot progression, or world-building, *re-evaluating its importance based on all context seen so far*.
    -   **Characters**: These generally hold more concrete and direct narrative weight. Assign a score typically in the range of **5-10**. A score of 10 indicates a central, foundational, or highly impactful entity.
    -   **Locations**: Places, settings, countries, cities (e.g., "Hiroshima", "Nagasaki", "Poland", "Germany", "Italy", "Japan", "United States", "Soviet Union", "Los Alamos", "Hong Kong", "Eniwetok Atoll", "Chicago", "Mount Massive Asylum").
    -   **Organizations**: Groups, agencies, governments, corporations (e.g., "USSR", "Office of Strategic Services (OSS)", "Central Intelligence Agency", "Nazi Germany", "Kingdom of Italy", "Empire of Japan", "Murkoff Corporation", "Axis powers", "Korean people's army").
    -   **Key Objects**: Distinctive items crucial to the plot or events (e.g., "atomic bomb", "hydrogen bomb", "Walrider", "LSD").
    -   **Concepts/Events**: Historical periods, specific significant dates/years (when representing an event), major conflicts, scientific advancements, named projects or programs (e.g., "Cold War", "1939", "1945", "1947", "1949", "1951", "1953", "World War II", "Second World War", "nuclear age", "arms race", "Operation Paperclip", "Project Bluebird", "Project Artichoke", "space race", "season 1 of The Outlast Trials", "season 2 of The Outlast series").

- **Scoring Guidance for 'base_importance_score' (1-10):**
    - This score reflects your assessment of its inherent relevance and criticality to the overall narrative, plot progression, or world-building, *re-evaluating its importance based on all context seen so far*.
    -   **Characters, Locations, Organizations, Key Objects**: These generally hold more concrete and direct narrative weight. Assign a score typically in the range of **5-10**. A score of 10 indicates a central, foundational, or highly impactful entity.
    -   **Concepts/Events**: These can vary greatly in their direct impact. Assign a score typically in the range of **1-7**. A higher score (6-7) implies a major plot event or a fundamental concept crucial to the story's core themes. A lower score (1-5) might be for more general themes or events that are less pivotal. Consider the historical and narrative impact (e.g., "Operation Paperclip", "Cold War" are high importance).
    - Aim for a nuanced understanding: If an entity is frequently mentioned but isn't inherently narratively significant (e.g., a common object that isn't a 'Key Object'), its 'base_importance_score' should remain modest. If it's rarely mentioned but critically impacts the plot (e.g., a twist event, a hidden MacGuffin), its 'base_importance_score' should be high.
"""

==================================================
File: .\main.py
==================================================
import sys
from PyQt5.QtWidgets import QApplication
from frontend.main_window import NarrativeNavigator

if __name__ == "__main__":
    app = QApplication(sys.argv)

    # Apply QSS stylesheet
    try:
        with open('style.qss', 'r') as f:
            app.setStyleSheet(f.read())
    except FileNotFoundError:
        print("Warning: 'style.qss' not found. UI will not be styled.", file=sys.stderr)
    except Exception as e:
        print(f"Error loading stylesheet: {e}", file=sys.stderr)

    window = NarrativeNavigator()
    window.show()
    sys.exit(app.exec_())

==================================================
File: .\style.qss
==================================================
/* General App Styling */
QWidget {
    font-family: "Segoe UI", "Helvetica Neue", Arial, sans-serif; /* Modern font */
    font-size: 14px;
    color: #333333; /* Dark grey text */
    background-color: #f0f2f5; /* Light background for general widgets */
}

/* Main Window background */
QMainWindow {
    background-color: #f0f2f5;
}

/* Header Bar */
#headerWidget { /* Use setObjectName("headerWidget") on your header QWidget */
    background-color: #ffffff;
    border-bottom: 1px solid #e0e0e0;
    padding: 10px 20px;
}
#appNameLabel { /* For the "Narrative Navigator" QLabel */
    color: #6a0dad; /* Purple accent */
    font-size: 20px;
    font-weight: bold;
}
#analysisStatusLabel { /* For the "Analyzing..." QLabel */
    color: #555555;
    font-size: 14px;
    margin-left: 10px;
}

/* Buttons in Header */
QPushButton {
    background-color: #e0e0e0; /* Default button background */
    color: #333333;
    border: none;
    border-radius: 15px;
    padding: 8px 15px;
    font-weight: 500;
    min-width: 80px; /* Ensure a minimum width for text buttons */
}
QPushButton:hover {
    background-color: #d0d0d0;
}
QPushButton:pressed {
    background-color: #c0c0c0;
}

QPushButton#stopRecordingButton { /* Specific style for stop button */
    background-color: #e74c3c; /* Red */
    color: white;
    font-weight: bold;
}
QPushButton#stopRecordingButton:hover {
    background-color: #c0392b; /* Darker red on hover */
}
QPushButton#stopRecordingButton:pressed {
    background-color: #a02a1d;
}

/* Icon-only buttons */
QPushButton#iconButton {
    background-color: transparent;
    border: none;
    border-radius: 18px; /* Half of fixed size for perfect circle */
    padding: 0;
    margin: 0;
}
QPushButton#iconButton:hover {
    background-color: #e9ecef;
}
QPushButton#iconButton:pressed {
    background-color: #dcdcdc;
}

/* Tab Widget Navigation */
QTabWidget::pane { /* The content area of the tab widget */
    border: 1px solid #dcdcdc;
    border-top-left-radius: 12px;
    border-top-right-radius: 12px;
    border-bottom-left-radius: 12px;
    border-bottom-right-radius: 12px;
    background-color: #ffffff;
    margin: 10px; /* Margin around the whole content pane */
    padding: 0; /* Content padding handled by tab page layouts */
}

QTabBar {
    qproperty-drawBase: 0; /* Crucial to remove base line */
    background-color: transparent;
    padding: 0 10px; /* Padding for the tab bar itself */
}

QTabBar::tab {
    background: #f0f2f5; /* Background for unselected tabs */
    border: 1px solid #dcdcdc;
    border-top-left-radius: 8px; /* Rounded corners for the tabs */
    border-top-right-radius: 8px;
    padding: 10px 20px;
    margin-right: 2px; /* Space between tabs */
    color: #555555;
    font-weight: 500;
    min-width: 100px; /* Ensure consistent tab width */
    text-align: center;
}

QTabBar::tab:selected {
    background: #ffffff; /* White background for selected tab */
    border-color: #dcdcdc;
    border-bottom-color: transparent; /* Makes it look connected to the content */
    color: #6a0dad; /* Purple text for selected tab */
    font-weight: bold;
    margin-top: -1px; /* Slightly raise selected tab to overlap pane border */
}

QTabBar::tab:hover:!selected { /* Hover effect for unselected tabs */
    background: #e9ecef;
}

/* Section Titles within tabs */
QLabel#sectionTitle {
    font-size: 20px;
    font-weight: bold;
    color: #333333;
    margin-bottom: 15px; /* Space below titles */
}

/* General Content Cards (Applied via setProperty("class", "contentCard")) */
QFrame.contentCard {
    background-color: #ffffff;
    border: 1px solid #e0e0e0;
    border-radius: 8px;
    padding: 15px;
}

/* Category Tags (e.g., "Characters", "Locations", "Processing") */
QLabel.categoryTag {
    background-color: #e0e7ff; /* Light purple */
    color: #4a148c; /* Darker purple text */
    border-radius: 10px;
    padding: 3px 8px;
    font-size: 11px;
    font-weight: bold;
    min-width: 60px;
    text-align: center;
}
QLabel.processingTag { /* Green for "Processing" */
    background-color: #d4edda;
    color: #155724;
    border-radius: 10px;
    padding: 3px 8px;
    font-size: 11px;
    font-weight: bold;
    min-width: 60px;
    text-align: center;
}

/* Text Edits & Line Edits */
QTextEdit, QLineEdit {
    border: 1px solid #dcdcdc;
    border-radius: 8px;
    padding: 10px;
    background-color: #ffffff;
    selection-background-color: #e0e7ff; /* Light purple selection */
}

/* Chat Input specific styling */
QFrame#chatInputContainer { /* The container for the line edit and send button */
    border: 1px solid #dcdcdc;
    border-radius: 8px;
    background-color: #ffffff;
    padding: 0;
    margin-top: 10px; /* Space above the input container */
}
QFrame#chatInputContainer QLineEdit {
    border: none; /* Remove border from line edit inside container */
    padding: 10px;
    background-color: transparent;
}
QFrame#chatInputContainer QPushButton#sendButton { /* Send button inside container */
    background-color: #6a0dad; /* Purple */
    color: white;
    border-top-right-radius: 8px;
    border-bottom-right-radius: 8px;
    border-top-left-radius: 0;
    border-bottom-left-radius: 0;
    padding: 0;
    margin: 0;
    min-width: 40px; /* For the send icon */
}
QFrame#chatInputContainer QPushButton#sendButton:hover {
    background-color: #5a0ca0;
}
QFrame#chatInputContainer QPushButton#sendButton:pressed {
    background-color: #4a0b8f;
}

/* ScrollArea for story elements and other scrollable content */
QScrollArea {
    border: none;
    background-color: transparent;
}
QScrollArea > QWidget > QWidget { /* This targets the actual content widget inside the scroll area */
    background-color: transparent; /* Ensure content background is transparent */
}
QScrollBar:vertical {
    border: none;
    background: #f0f2f5; /* Scrollbar track background */
    width: 8px;
    margin: 0px 0px 0px 0px;
    border-radius: 4px;
}
QScrollBar::handle:vertical {
    background: #c0c0c0; /* Scrollbar handle color */
    border-radius: 4px;
    min-height: 20px;
}
QScrollBar::handle:vertical:hover {
    background: #a0a0a0;
}
QScrollBar::add-line:vertical, QScrollBar::sub-line:vertical {
    border: none;
    background: none;
}
QScrollBar::up-arrow:vertical, QScrollBar::down-arrow:vertical {
    background: none;
}
QScrollBar::add-page:vertical, QScrollBar::sub-page:vertical {
    background: none;
}
/* Table Widget (Cheat Sheet - right panel) */
QTableWidget#cheatSheetTable {
    border: 1px solid #dcdcdc;
    border-radius: 8px;
    background-color: #ffffff;
    gridline-color: #e0e0e0;
    selection-background-color: #e0e7ff; /* Light purple selection */
    selection-color: #333333;
    padding: 5px;
}
QHeaderView::section {
    background-color: #f8f9fa;
    padding: 8px;
    border: 1px solid #dcdcdc;
    font-weight: bold;
    color: #333333;
}
QTableWidget::item {
    padding: 8px;
    border-bottom: 1px solid #e0e0e0;
}
QTableWidget::item:selected {
    background-color: #e0e7ff;
}
/* For compact story element cards in the "Story Elements" tab */
QFrame.storyElementCard {
    background-color: #f9f9f9;
    border: 1px solid #eeeeee;
    border-radius: 5px;
    padding: 8px 12px; /* Vertical padding, horizontal padding */
}
QFrame.storyElementCard QLabel { /* General font size for labels inside compact card */
    font-size: 13px;
    color: #333333;
    /* Reset any specific padding/margins from general QLabel styles */
    margin: 0;
    padding: 0;
}
QFrame.storyElementCard QLabel[property="nameLabel"] { /* Specific style for the entity name */
    font-weight: bold;
    color: #333333;
    white-space: nowrap; /* Prevent wrapping for the name */
}
QFrame.storyElementCard QLabel[property="descriptionLabel"] { /* Specific style for the description */
    color: #555555;
    /* overflow: hidden and text-overflow: ellipsis are not supported in QSS */
    /* Text wrapping is controlled by the QLabel's wordWrap property in Python code */
}
QFrame.storyElementCard QLabel[property="timeLabel"] { /* Specific style for the timestamp */
    font-size: 10px;
    color: #777777;
    white-space: nowrap; /* Prevent wrapping for the timestamp */
    margin-left: 10px; /* Provide some space from description */
}
