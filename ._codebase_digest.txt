Codebase Analysis for: .

Directory Structure:
└── .
    ├── backend
    │   ├── audio_capture.py
    │   ├── chat_agent.py
    │   ├── llm_processing.py
    │   ├── transcription.py
    │   └── web_search.py
    ├── constants.py
    ├── frontend
    │   └── main_window.py
    ├── llm_prompts.py
    ├── main.py
    └── style.qss

Summary:
Total files analyzed: 10
Total directories analyzed: 2
Estimated output size: 95.80 KB
Actual analyzed size: 93.85 KB
Total tokens: 19895
Actual text content size: 92.05 KB

File Contents:

==================================================
File: .\backend\audio_capture.py
==================================================
import sys
import numpy as np
import sounddevice as sd
import queue
import threading
from PyQt5.QtCore import QThread, pyqtSignal
from constants import TRANSCRIPT_CHUNK_DURATION_SECONDS # Not directly used here, but good practice to keep context

class AudioCaptureThread(QThread):
    audio_data = pyqtSignal(np.ndarray)
    error_signal = pyqtSignal(str)

    def __init__(self, device_id=3, samplerate=16000):
        super().__init__()
        self.device_id = device_id
        self.samplerate = samplerate
        self._running = False
        self._stop_event = threading.Event()
        self.audio_queue = queue.Queue()

    def run(self):
        self._running = True
        self._stop_event.clear()

        def callback(indata, frames, time_info, status):
            if status:
                pass
            if self._running:
                self.audio_queue.put(indata.copy())

        try:
            devices = sd.query_devices()
            if self.device_id >= len(devices):
                raise ValueError(f"Device ID {self.device_id} is out of range. Available devices: {len(devices)}")
            device_info = sd.query_devices(self.device_id)
            if device_info['max_input_channels'] < 1:
                raise ValueError(f"Device {self.device_id} does not support audio input")
            
            with sd.InputStream(samplerate=self.samplerate,
                              device=self.device_id,
                              channels=1,
                              callback=callback):
                while self._running:
                    try:
                        audio_chunk = self.audio_queue.get(timeout=0.1)
                        self.audio_data.emit(audio_chunk)
                    except queue.Empty:
                        if self._stop_event.is_set():
                            break
        except Exception as e:
            error_msg = f"Audio Capture Critical Error: {str(e)}"
            if "device" in str(e).lower():
                error_msg += f"\nAvailable audio devices:\n"
                for i, dev in enumerate(sd.query_devices()):
                    if dev['max_input_channels'] > 0:
                        error_msg += f"ID {i}: {dev['name']}\n"
            self.error_signal.emit(error_msg)
            print(error_msg, file=sys.stderr)
        finally:
            self._running = False
            while not self.audio_queue.empty():
                try:
                    self.audio_queue.get_nowait()
                except queue.Empty:
                    break

    def stop(self):
        self._running = False
        self._stop_event.set()

==================================================
File: .\backend\chat_agent.py
==================================================
import threading
import json
import queue
import time
import ollama
from PyQt5.QtCore import QThread, pyqtSignal

class ChatThread(QThread):
    chat_response = pyqtSignal(str)
    chat_log = pyqtSignal(dict) 

    def __init__(self, transcript_getter, entities_getter, content_title, external_context):
        super().__init__()
        self.chat_queue = queue.Queue()
        self.running = False
        self.transcript_getter = transcript_getter
        self.entities_getter = entities_getter
        self.content_title = content_title
        self.external_context = external_context

        # ADDED: Event for responsive shutdown
        self._stop_event = threading.Event()

        self.system_prompt = """
You are an AI assistant helping a user understand a story by answering questions based on the transcript history and a narrative cheat sheet.

The content is titled: "{content_title}".
External context about the content:
---
{external_context}
---

Answer user questions using the provided transcript history and cheat sheet. Provide detailled, relevant answers in plain text.
""".format(content_title=self.content_title, external_context=self.external_context)

    def add_chat_query(self, query):
        self.chat_queue.put(query)

    def run(self):
        self.running = True
        # ADDED: Clear stop event at the start of run
        self._stop_event.clear()

        while self.running:
            try:
                # Changed to get with timeout to be responsive to stop signals
                query = self.chat_queue.get(timeout=0.1) 
                
                transcripts = self.transcript_getter()
                recent_transcripts = transcripts[-5:] if len(transcripts) > 5 else transcripts
                current_entities = self.entities_getter()
                current_entities_json = json.dumps(current_entities, indent=2)

                messages = [
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content":
                     f"Transcript history: {recent_transcripts}\n"
                     f"Current narrative cheat sheet: {current_entities_json}\n"
                     f"User question: {query}"}
                ]
                self.chat_log.emit({"type": "chat_prompt", "message": "Chat prompt sent:", "data": messages})
                try:
                    response = ollama.chat(model="llama3.2:latest", messages=messages, stream=False)
                    content = response['message']['content']
                    self.chat_response.emit(content)
                    self.chat_log.emit({"type": "chat_response", "message": "Chat response received.", "data": content})
                except Exception as e:
                    self.chat_response.emit(f"Error: Unable to process query - {str(e)}")
                    self.chat_log.emit({"type": "error", "message": f"Chat Error: {str(e)}"})
            except queue.Empty:
                # If queue is empty (no chat query), check if stop event is set
                if self._stop_event.is_set():
                    self.chat_log.emit({"type": "status", "message": "Chat Thread received stop signal during idle, exiting."})
                    break # Exit the loop immediately
            # REMOVED: original time.sleep(0.5) as get(timeout) handles idle waiting.
            # If the queue wasn't empty, processing might take time, so no additional sleep is needed.

    def stop(self):
        self.running = False
        # ADDED: Set stop event to signal termination
        self._stop_event.set()

==================================================
File: .\backend\llm_processing.py
==================================================
import json
import re
import threading
import time
import ollama
import Levenshtein # Used for robust string similarity comparison
from PyQt5.QtCore import QThread, pyqtSignal
from constants import TRANSCRIPT_CHUNK_DURATION_SECONDS
from llm_prompts import base_system_prompt

# Define the JSON schema for the expected entity output format
entity_list_schema = {
    "type": "object",
    "properties": {
        "entities": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "name": {
                        "type": "string"
                    },
                    "type": {
                        "type": "string"
                    },
                    "description": {
                        "type": "string"
                    },
                    "base_importance_score": {
                        "type": "integer",
                        "minimum": 1,
                        "maximum": 10
                    },
                    "aliases": { # NEW: Optional list of aliases
                        "type": "array",
                        "items": {
                            "type": "string"
                        },
                        "default": []
                    }
                },
                "required": [
                    "name",
                    "type",
                    "description",
                    "base_importance_score"
                ]
            }
        }
    },
    "required": [
        "entities"
    ]
}

class LLMThread(QThread):
    llm_log = pyqtSignal(dict) 
    entities_updated = pyqtSignal(list)

    def __init__(self):
        super().__init__()
        try:
            self.model = "llama3.2:latest"
            # Attempt a simple chat to ensure Ollama is running and model exists
            ollama.chat(model=self.model, messages=[{"role": "user", "content": "hi"}], stream=False)
            self.llm_log.emit({"type": "status", "message": f"Successfully connected to Ollama model '{self.model}'."})
        except Exception as e:
            self.llm_log.emit({"type": "error", "message": f"Failed to connect to Ollama or model '{self.model}' not found: {e}"})
            self.model = None

        self.transcriptions = []
        self.entities = [] # This will hold the canonical entities (with combined info)
        self.dynamic_alias_map = {} # Maps alias (normalized string) -> canonical name (actual string from entities list)
        self.running = False
        self.external_context = ""
        self.content_title = "Unknown Content"

        self.base_system_prompt_template = base_system_prompt
        
        # Initial formatting of the system prompt
        self.system_prompt = self.base_system_prompt_template.format(
            content_title=self.content_title,
            external_context="No external context loaded yet. Please wait for the application to gather information."
        )
        self.last_transcript_processed_idx = -1
        
        self.VALID_ENTITY_TYPES = ["Characters", "Locations", "Organizations", "Key Objects", "Concepts/Events"]

    def set_content_title(self, title):
        self.content_title = title
        self._update_system_prompt()

    def set_external_context(self, context):
        self.external_context = context
        self._update_system_prompt()

    def _update_system_prompt(self):
        self.system_prompt = self.base_system_prompt_template.format(
            content_title=self.content_title,
            external_context=self.external_context
        )
    
    def _normalize_entity_type(self, type_str):
        """Normalizes LLM output type strings to our canonical types."""
        if not type_str:
            return None
        type_str_lower = type_str.lower().strip()
        
        # Handle compound types by splitting and taking the first part as a primary hint
        if ',' in type_str_lower:
            type_str_lower = type_str_lower.split(',')[0].strip()
        
        if type_str_lower == "concept/event":
            return "Concepts/Events"
        if type_str_lower == "locations/organizations":
            return "Locations" 
        if type_str_lower == "locations/concepts/events":
            return "Locations" 
        
        if type_str_lower in ["characters", "characters/individuals", "character", "individual"]:
            return "Characters"
        elif type_str_lower in ["locations", "location", "countries", "country", "cities", "city", "places", "place"]:
            return "Locations"
        elif type_str_lower in ["organizations", "organization", "agencies", "agency", "governments", "government", "corporations", "corporation", "groups", "group", "factions", "faction", "allies", "powers"]:
            return "Organizations"
        elif type_str_lower in ["key objects", "key object", "objects", "object", "artifacts", "artifact", "weapons", "weapon"]:
            return "Key Objects"
        elif type_str_lower in ["concepts/events", "concepts", "concept", "events", "event", "historical events", "dates", "years", "periods", "period", "projects", "programs", "wars", "conflicts", "eras", "era", "ages", "age", "campaigns", "campaign"]:
            return "Concepts/Events"
        return None

    def _normalize_for_comparison(self, name, entity_type=None):
        """
        Normalizes entity names for robust comparison and deduplication.
        It uses a dynamic alias map, then string similarity, and finally a fallback cleaning.
        `entity_type` (canonical type) is crucial for disambiguation.
        Returns the canonical name (actual string) or a cleaned string if no match found.
        """
        if not name:
            return ""

        # Step 1: Basic cleaning for lookup in alias map and similarity comparison
        # Remove parenthesized content for a cleaner base name
        cleaned_base_name = re.sub(r'\s*\([^)]*\)', '', name).strip()
        name_lower_stripped = re.sub(r'[^a-z0-9\s]', '', cleaned_base_name.lower()).strip()
        name_lower_stripped = re.sub(r'\s+', ' ', name_lower_stripped).strip()

        # Step 2: Check dynamic alias map for direct lookup
        if name_lower_stripped in self.dynamic_alias_map:
            # We found a canonical name, return it
            canonical_name = self.dynamic_alias_map[name_lower_stripped]
            self.llm_log.emit({"type": "debug", "message": f"Alias map hit: '{name}' (cleaned: '{name_lower_stripped}') mapped to '{canonical_name}'."})
            return canonical_name

        # Step 3: If not in alias map, try to find a similar existing canonical entity
        # This acts as a fallback for aliases LLM might miss, or minor transcription errors.
        best_match_canonical_name = None
        highest_similarity = 0.88 # Threshold for considering a strong match (0.0 to 1.0)

        for existing_entity in self.entities:
            # Ensure entity type is comparable or ignored if not provided
            if entity_type is not None and self._normalize_entity_type(existing_entity["type"]) != self._normalize_entity_type(entity_type):
                continue # Skip if types are known and don't match

            existing_canonical_name_cleaned = re.sub(r'[^a-z0-9\s]', '', existing_entity["name"].lower()).strip()
            existing_canonical_name_cleaned = re.sub(r'\s+', ' ', existing_canonical_name_cleaned).strip()
            
            # Use Levenshtein distance ratio for similarity
            similarity = Levenshtein.ratio(name_lower_stripped, existing_canonical_name_cleaned)
            
            if similarity > highest_similarity:
                highest_similarity = similarity
                best_match_canonical_name = existing_entity["name"] # Keep the actual canonical name from our entity list

        if best_match_canonical_name:
            # If a strong similarity match is found, add the current name as an alias
            # to the best_match_canonical_name for future faster lookups.
            self.dynamic_alias_map[name_lower_stripped] = best_match_canonical_name
            self.llm_log.emit({"type": "debug", "message": f"Similarity match: '{name}' (cleaned: '{name_lower_stripped}') strongly similar to '{best_match_canonical_name}' (similarity: {highest_similarity:.2f}). Added to alias map."})
            return best_match_canonical_name
        
        # Step 4: No direct alias or strong similarity match found.
        # This is a new potential canonical entity name. Apply more aggressive cleaning.
        # This cleaning is done *after* alias/similarity check to preserve LLM's raw name if it's the canonical one.
        final_canonical_candidate = cleaned_base_name # Start with the name without parenthesized text

        # Remove common articles and possessive endings for robust canonicalization
        for article in ['the ', 'a ', 'an ']:
            if final_canonical_candidate.lower().startswith(article):
                final_canonical_candidate = final_canonical_candidate[len(article):].strip()
        final_canonical_candidate = re.sub(r"'s?\b", '', final_canonical_candidate, flags=re.IGNORECASE).strip() # remove 's or s' at end of word
        final_canonical_candidate = re.sub(r'[^a-zA-Z0-9\s]', '', final_canonical_candidate).strip() # remove non-alphanumeric (keep spaces)
        final_canonical_candidate = re.sub(r'\s+', ' ', final_canonical_candidate).strip() # reduce multiple spaces

        if not final_canonical_candidate: # If cleaning resulted in empty string, use original
            final_canonical_candidate = name.strip()
            
        # Add this new canonical candidate to the alias map, pointing to itself
        self.dynamic_alias_map[final_canonical_candidate.lower()] = final_canonical_candidate
        self.llm_log.emit({"type": "debug", "message": f"New canonical candidate: '{name}' mapped to cleaned '{final_canonical_candidate}'. Added to alias map."})
        return final_canonical_candidate

    def _normalize_for_mention_check(self, text):
        """
        More aggressive normalization for checking mentions in raw text.
        Converts to lowercase, removes most punctuation, handles common plural/possessive endings.
        """
        text = text.lower()
        text = re.sub(r"['’]\s*s?\b", '', text) # Handles 's and s' (e.g., 'character's' or 'characters')
        text = re.sub(r'[^a-z0-9\s]', ' ', text) # Replace non-alphanumeric with space
        text = re.sub(r'\s+', ' ', text).strip() # Reduce multiple spaces to single space
        return text

    # _is_similar_entity is removed as its logic is now primarily handled by _normalize_for_comparison
    # during entity reconciliation for deduplication.

    def _update_importance_from_transcript(self, transcript_text):
        """
        Increments mention_count for existing entities found in the new transcript.
        Uses canonical names for matching to handle variations/typos.
        """
        normalized_transcript_for_check = self._normalize_for_mention_check(transcript_text)
        
        for entity in self.entities:
            # Get the canonical name of the *existing* entity for matching
            # Ensure it's in the form used for mention checking.
            entity_canonical_name_for_check = self._normalize_for_mention_check(entity["name"]) 
            
            # Prepare a regex pattern for the canonical name, ensuring whole word match
            # re.escape is important if entity name contains special regex characters
            pattern = r'\b' + re.escape(entity_canonical_name_for_check) + r'\b'
            
            if re.search(pattern, normalized_transcript_for_check):
                entity["mention_count"] += 1
                self.llm_log.emit({"type": "debug", "message": f"Entity '{entity['name']}' (canonical: '{entity_canonical_name_for_check}') ({entity['type']}) mention_count incremented to {entity['mention_count']}"})

    def run(self):
        self.running = True
        if self.model is None:
            self.llm_log.emit({"type": "error", "message": "LLM model not loaded, cannot process entities."})
            self.running = False
            return

        if not self.external_context:
            self.llm_log.emit({"type": "status", "message": "LLM Thread waiting for external context..."})
            while self.running and not self.external_context:
                time.sleep(1)
            if not self.running:
                return

        self.llm_log.emit({"type": "status", "message": "LLM Thread started with external context."})
        while self.running:
            if len(self.transcriptions) > self.last_transcript_processed_idx + 1:
                transcript_to_process = self.transcriptions[self.last_transcript_processed_idx + 1] 
                current_transcript_idx = self.last_transcript_processed_idx + 1 
                
                recent_transcripts = self.transcriptions[max(0, current_transcript_idx - 4):current_transcript_idx + 1]
                
                current_entities_for_llm_prompt = [
                    {"name": e["name"], "type": e["type"], "description": e["description"]}
                    for e in self.entities
                ]

                # Combine current and recent transcripts for a robust mention check later
                all_relevant_transcript_text = "\n".join(recent_transcripts)
                normalized_all_relevant_transcript_text = self._normalize_for_mention_check(all_relevant_transcript_text)


                messages = [
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content":
                     f"Current transcript snippet: {transcript_to_process}\n"
                     f"Recent context (last {len(recent_transcripts)} snippets): {recent_transcripts}\n"
                     f"Current narrative cheat sheet: {json.dumps(current_entities_for_llm_prompt, indent=2)}\n"
                     f"Based on ALL information (current transcript, recent context, full cheat sheet), identify *all identifiable* entities. For EVERY entity you return (new or existing), provide its 'base_importance_score' (1-10) re-evaluated based on its inherent narrative relevance. Also, include an 'aliases' array for any recognized alternative names, nicknames, or common variations. Remember to include historical dates/years and specific organizations if mentioned. Ensure to correctly categorize and canonicalize names."}
                ]
                self.llm_log.emit({"type": "prompt", "message": f"Prompt for transcript index {current_transcript_idx}", "data": messages})
                
                llm_identified_entities = []
                raw_content_from_llm = ""
                try:
                    response = ollama.chat(
                        model=self.model,
                        messages=messages,
                        stream=False,
                        format=entity_list_schema, 
                        options={
                            "temperature": 0.1, 
                            "top_p": 0.9,       
                            "top_k": 40,        
                            "repeat_penalty": 1.0 
                        }
                    )
                    raw_content_from_llm = response['message']['content']
                    self.llm_log.emit({"type": "raw_response", "message": f"Raw LLM response for transcript index {current_transcript_idx}", "data": raw_content_from_llm})

                    # --- Robust JSON Parsing ---
                    parsed_llm_output = None
                    json_string_to_parse = ""

                    try:
                        json_string_to_parse = raw_content_from_llm.strip()
                        parsed_llm_output = json.loads(json_string_to_parse)
                    except json.JSONDecodeError:
                        json_match = re.search(r"```json\s*(.*?)\s*```", raw_content_from_llm, re.DOTALL)
                        if json_match:
                            json_string_to_parse = json_match.group(1).strip()
                            parsed_llm_output = json.loads(json_string_to_parse)
                        else:
                            json_match_loose = re.search(r"\{.*\}", raw_content_from_llm, re.DOTALL)
                            if json_match_loose:
                                json_string_to_parse = json_match_loose.group(0).strip()
                                parsed_llm_output = json.loads(json_string_to_parse)
                            else:
                                json_match_array_loose = re.search(r"\[.*\]", raw_content_from_llm, re.DOTALL)
                                if json_match_array_loose:
                                    json_string_to_parse = json_match_array_loose.group(0).strip()
                                    parsed_llm_output = json.loads(json_string_to_parse)
                                else:
                                    raise json.JSONDecodeError("No recognizable JSON structure found.", raw_content_from_llm, 0)

                    if parsed_llm_output is None:
                        self.llm_log.emit({"type": "warning", "message": f"JSON parsing attempts found no valid structure.\nAttempted to parse:\n{raw_content_from_llm}", "data": raw_content_from_llm})
                        llm_identified_entities = [] 
                    elif isinstance(parsed_llm_output, list):
                        llm_identified_entities = parsed_llm_output
                    elif isinstance(parsed_llm_output, dict) and 'entities' in parsed_llm_output:
                        llm_identified_entities = parsed_llm_output.get('entities', [])
                    else:
                        raise ValueError(f"Unexpected JSON structure after parsing: {type(parsed_llm_output)} - {json_string_to_parse}")

                    if not isinstance(llm_identified_entities, list):
                        raise ValueError("Expected 'entities' to be a list after parsing.")
                            
                    self.llm_log.emit({"type": "parsed_entities", "message": f"Parsed entities from LLM for transcript index {current_transcript_idx}", "data": llm_identified_entities})

                except (json.JSONDecodeError, ValueError) as e:
                    self.llm_log.emit({"type": "error", "message": f"JSON parsing error: {str(e)}\nAttempted to parse:\n{json_string_to_parse if json_string_to_parse else raw_content_from_llm}", "data": raw_content_from_llm})
                    llm_identified_entities = []
                except Exception as e:
                    self.llm_log.emit({"type": "error", "message": f"LLM request failed: {str(e)}"})
                    llm_identified_entities = [] 

                # --- Entity Reconciliation and Update ---
                temp_entities_dict = {}
                for e in self.entities:
                    # Key by canonical name and canonical type to ensure uniqueness
                    normalized_name_key = self._normalize_for_comparison(e["name"], e["type"])
                    canonical_type = self._normalize_entity_type(e["type"]) # Ensure type is canonical too
                    temp_entities_dict[(normalized_name_key, canonical_type)] = e

                filtered_llm_identified_entities = []
                for llm_entity_data in llm_identified_entities:
                    name = llm_entity_data.get("name")
                    raw_type = llm_entity_data.get("type")
                    
                    if not name:
                        self.llm_log.emit({"type": "warning", "message": f"Skipping invalid entity from LLM (missing name).", "entity_data": llm_entity_data})
                        continue

                    canonical_type = self._normalize_entity_type(raw_type)
                    if canonical_type is None:
                        self.llm_log.emit({"type": "warning", "message": f"Skipping entity with unrecognized type '{raw_type}'.", "entity_data": llm_entity_data})
                        continue
                    
                    # New strict mention filter:
                    # Check if the LLM-provided name (or its normalized form) is in the transcript text
                    # We check both the raw name and the more aggressively normalized name
                    mention_found = False
                    
                    # Check raw LLM name directly (case-insensitive, basic cleaning)
                    # This targets the actual string mentioned by the LLM
                    normalized_llm_name = self._normalize_for_mention_check(name)
                    if normalized_llm_name and normalized_llm_name in normalized_all_relevant_transcript_text:
                        mention_found = True
                    else:
                        # Also check any aliases provided by the LLM for mention
                        for alias in llm_entity_data.get("aliases", []):
                            normalized_alias = self._normalize_for_mention_check(alias)
                            if normalized_alias and normalized_alias in normalized_all_relevant_transcript_text:
                                mention_found = True
                                break # Found a mention via an alias, no need to check further aliases for THIS entity
                            
                    if not mention_found:
                        self.llm_log.emit({"type": "warning", "message": f"LLM proposed entity '{name}' ({raw_type}) not found explicitly in transcript or its aliases. Skipping.", "entity_data": llm_entity_data})
                        continue # Skip this entity if not actually mentioned
                    
                    filtered_llm_identified_entities.append(llm_entity_data)

                # Process only the entities that were actually mentioned in the transcript
                for llm_entity_data in filtered_llm_identified_entities:
                    name = llm_entity_data.get("name")
                    raw_type = llm_entity_data.get("type")
                    description = llm_entity_data.get("description")
                    base_importance_score = llm_entity_data.get("base_importance_score")
                    aliases = llm_entity_data.get("aliases", []) 

                    canonical_type = self._normalize_entity_type(raw_type) # Already checked above, but keep for clarity
                    
                    if not isinstance(base_importance_score, int) or not (1 <= base_importance_score <= 10):
                        self.llm_log.emit({"type": "warning", "message": f"Invalid base_importance_score for '{name}'. Defaulting to 1.", "entity_data": llm_entity_data})
                        base_importance_score = 1

                    # Get the canonical name for the LLM-provided name
                    # IMPORTANT: Use the _normalize_for_comparison method here for the LLM's primary name
                    llm_provided_canonical_name = self._normalize_for_comparison(name, canonical_type)
                    
                    # Use this canonical name and type as the key for lookup in our temp dict
                    entity_key = (llm_provided_canonical_name, canonical_type)
                    existing_entity = temp_entities_dict.get(entity_key)

                    if existing_entity:
                        # Update existing entity
                        # Prioritize update if new name is more complete or has better casing
                        # Only update if the normalized names are the same (already guaranteed by entity_key)
                        current_normalized_name = self._normalize_for_comparison(existing_entity["name"], existing_entity["type"])
                        new_normalized_name = self._normalize_for_comparison(name, canonical_type)

                        if current_normalized_name == new_normalized_name:
                            # Heuristic: Prefer longer name (more complete) or better casing
                            if len(name) > len(existing_entity["name"]) or \
                               (name and name[0].isupper() and not (existing_entity["name"] and existing_entity["name"][0].isupper())):
                                existing_entity["name"] = name # Update to the better raw name
                        
                        existing_entity["description"] = description if description else existing_entity["description"]
                        existing_entity["base_importance_score"] = max(existing_entity["base_importance_score"], base_importance_score) # Take max score

                        # Add all provided aliases to the dynamic alias map for the existing entity's canonical name
                        # Ensure the existing canonical name itself is mapped to its cleaned form
                        # This ensures the canonical name always maps to itself in its cleaned form
                        self.dynamic_alias_map[self._normalize_for_comparison(existing_entity["name"], existing_entity["type"]).lower()] = existing_entity["name"]
                        for alias_name in aliases:
                            alias_lower = self._normalize_for_comparison(alias_name, canonical_type).lower() # Normalize alias string as well
                            # Add alias to map IF it's not already pointing to a different canonical entity
                            # This prevents "Apple" (fruit) mapping to "Apple" (company) if both exist.
                            if alias_lower not in self.dynamic_alias_map or \
                               self.dynamic_alias_map[alias_lower] == existing_entity["name"]:
                                self.dynamic_alias_map[alias_lower] = existing_entity["name"]
                                self.llm_log.emit({"type": "debug", "message": f"Added alias '{alias_name}' (norm: '{alias_lower}') for existing entity '{existing_entity['name']}'"})

                    else:
                        # Add new entity
                        new_entity_canonical_name = self._normalize_for_comparison(name, canonical_type) # Already computed
                        new_entity = {
                            "name": new_entity_canonical_name, # Use the derived canonical name for the new entity
                            "type": canonical_type,
                            "description": description if description else "",
                            "base_importance_score": base_importance_score,
                            "mention_count": 0, # Initialize to 0, will be updated by _update_importance_from_transcript later (if also mentioned in current transcript)
                            "first_mentioned_idx": current_transcript_idx
                        }
                        temp_entities_dict[entity_key] = new_entity

                        # Add current name and all its aliases to the dynamic alias map
                        self.dynamic_alias_map[new_entity_canonical_name.lower()] = new_entity_canonical_name
                        for alias_name in aliases:
                            alias_lower = self._normalize_for_comparison(alias_name, canonical_type).lower() # Normalize alias string as well
                            if alias_lower not in self.dynamic_alias_map or \
                               self.dynamic_alias_map[alias_lower] == new_entity_canonical_name: # Check to avoid overwriting
                                self.dynamic_alias_map[alias_lower] = new_entity_canonical_name
                                self.llm_log.emit({"type": "debug", "message": f"Added alias '{alias_name}' (norm: '{alias_lower}') for new entity '{new_entity_canonical_name}'"})

                self.entities = list(temp_entities_dict.values())
                # Now that the entities list is updated, trigger mention count update for the *current* transcript.
                # This ensures any newly identified entities in this round get their first mention counted,
                # and existing entities also get their count incremented if mentioned.
                # The _update_importance_from_transcript method handles the mention_count, including setting 1 for first mention.
                self._update_importance_from_transcript(transcript_to_process)
                
                self.entities_updated.emit(self.entities)
                self.last_transcript_processed_idx = current_transcript_idx 

            time.sleep(2) 

    def add_transcription(self, text):
        self.transcriptions.append(text) 

    def get_transcriptions(self):
        return self.transcriptions

    def get_entities(self):
        return self.entities

    def get_alias_map(self):
        """Returns the current dynamic alias map."""
        return self.dynamic_alias_map

    def stop(self):
        self.running = False

==================================================
File: .\backend\transcription.py
==================================================
import numpy as np
import whisper
import threading
import time
import queue
from PyQt5.QtCore import QThread, pyqtSignal
from constants import TRANSCRIPT_CHUNK_DURATION_SECONDS

class TranscriptionThread(QThread):
    transcription = pyqtSignal(str)
    error_signal = pyqtSignal(str)

    def __init__(self):
        super().__init__()
        try:
            self.model = whisper.load_model("small.en")
        except Exception as e:
            self.error_signal.emit(f"Failed to load Whisper model: {e}")
            self.model = None

        self.audio_buffer = np.array([], dtype=np.float32)
        self.running = False
        self.buffer_lock = threading.Lock()
        self._stop_event = threading.Event()

    def run(self):
        self.running = True
        self._stop_event.clear()

        while self.running:
            audio_to_process = None
            with self.buffer_lock:
                if len(self.audio_buffer) >= 16000 * TRANSCRIPT_CHUNK_DURATION_SECONDS: 
                    audio_to_process = self.audio_buffer[:16000 * TRANSCRIPT_CHUNK_DURATION_SECONDS].copy()
                    self.audio_buffer = self.audio_buffer[16000 * TRANSCRIPT_CHUNK_DURATION_SECONDS:]
            
            if audio_to_process is not None:
                try:
                    if audio_to_process.dtype != np.float32:
                        audio_to_process = audio_to_process.astype(np.float32) / 32768.0

                    result = self.model.transcribe(audio_to_process, language="en")
                    if result["text"].strip():
                        self.transcription.emit(result["text"])
                except Exception as e:
                    self.error_signal.emit(f"Transcription Error: {e}")
                    # print(f"Transcription Error: {e}", file=sys.stderr) # Removed sys.stderr import
            time.sleep(0.1)
            if self._stop_event.is_set():
                break

    def add_audio(self, audio_data):
        with self.buffer_lock:
            if audio_data.dtype != np.float32:
                audio_data = audio_data.astype(np.float32) / 32768.0
            self.audio_buffer = np.append(self.audio_buffer, audio_data.flatten())

    def stop(self):
        self.running = False
        self._stop_event.set()

==================================================
File: .\backend\web_search.py
==================================================
import json # Not directly used but often helpful for debugging DDGS results
from duckduckgo_search import DDGS
from PyQt5.QtCore import QThread, pyqtSignal

class WebSearchThread(QThread):
    context_ready = pyqtSignal(str)
    error_signal = pyqtSignal(str)

    def __init__(self, title):
        super().__init__()
        self.title = title

    def run(self):
        try:
            search_query = f"{self.title} plot summary OR overview"
            with DDGS() as ddgs:
                results = list(ddgs.text(search_query, max_results=5))

            context_lines = []
            for r in results:
                if r.get('body'):
                    context_lines.append(f"- {r['title']}: {r['body']}")
                elif r.get('link'):
                    context_lines.append(f"- {r['title']} ({r['link']})")
            
            full_context = "\n".join(context_lines)

            if not full_context:
                self.error_signal.emit(f"Warning: No significant web context found for '{self.title}'. LLM may operate with limited external knowledge.")
                full_context = f"No specific plot context found for the content titled '{self.title}'."

            self.context_ready.emit(full_context)
        except Exception as e:
            self.error_signal.emit(f"Error during web search for '{self.title}': {str(e)}. LLM will operate without external context.")
            self.context_ready.emit(f"Web search failed. No external context provided for '{self.title}'.")

==================================================
File: .\constants.py
==================================================
# Constants for time calculation (approximate)
# This assumes the TranscriptionThread processes fixed 10-second chunks.
TRANSCRIPT_CHUNK_DURATION_SECONDS = 10

==================================================
File: .\frontend\main_window.py
==================================================
import sys
import json
import numpy as np
import time 
from datetime import datetime
import os # Import the os module for path operations

from PyQt5.QtWidgets import (
    QMainWindow, QWidget, QVBoxLayout,
    QHBoxLayout, QPushButton, QTextEdit, QTableWidget,
    QTableWidgetItem, QInputDialog, QSplitter, QLineEdit,
    QLabel, QFrame, QTabWidget, QScrollArea, QSizePolicy,
    QApplication, QStyle
)
from PyQt5.QtCore import QThread, pyqtSignal, Qt, QSize
from PyQt5.QtGui import QIcon

from backend.audio_capture import AudioCaptureThread
from backend.transcription import TranscriptionThread
from backend.web_search import WebSearchThread
from backend.llm_processing import LLMThread
from backend.chat_agent import ChatThread
from constants import TRANSCRIPT_CHUNK_DURATION_SECONDS

class NarrativeNavigator(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Narrative Navigator AI")
        self.setGeometry(100, 100, 1200, 800)
        self.setMinimumSize(800, 600)

        self.audio_thread = AudioCaptureThread()
        self.transcription_thread = TranscriptionThread()
        self.llm_thread = LLMThread()
        self.chat_thread = None
        self.web_search_thread = None
        self.content_title = ""
        self.minimum_display_score = 3 
        
        self.cheat_sheet_column_widths = {} 

        # File paths for output
        self.output_dir = None
        self.transcript_file_path = None
        self.cheat_sheet_file_path = None
        self.alias_map_file_path = None
        self.raw_llm_log_file_path = None 
        self.error_warnings_file_path = None 

        self.init_ui()

        # Connect signals from backend threads to UI update slots
        self.audio_thread.audio_data.connect(self.transcription_thread.add_audio)
        self.audio_thread.error_signal.connect(lambda msg: self.update_llm_log_tabs({"type": "error", "message": msg})) 
        
        self.transcription_thread.transcription.connect(self.handle_transcription)
        self.transcription_thread.error_signal.connect(lambda msg: self.update_llm_log_tabs({"type": "error", "message": msg}))
        
        self.llm_thread.entities_updated.connect(self.update_entity_displays) 
        self.llm_thread.llm_log.connect(self.update_llm_log_tabs)

        self.get_content_title_and_context()

    def init_ui(self):
        main_container = QWidget()
        self.setCentralWidget(main_container)
        main_layout = QVBoxLayout(main_container)
        main_layout.setContentsMargins(0, 0, 0, 0)
        main_layout.setSpacing(0)

        header_widget = QWidget()
        header_widget.setObjectName("headerWidget")
        header_layout = QHBoxLayout(header_widget)
        header_layout.setContentsMargins(20, 10, 20, 10)
        header_layout.setSpacing(15)

        app_logo = QLabel()
        app_logo.setPixmap(self.style().standardIcon(QStyle.SP_ComputerIcon).pixmap(QSize(32, 32)))
        
        app_name_label = QLabel("Narrative Navigator")
        app_name_label.setObjectName("appNameLabel")

        self.analysis_status_label = QLabel("Analyzing: [Awaiting Content Title]") 
        self.analysis_status_label.setObjectName("analysisStatusLabel")
        self.analysis_status_label.setAlignment(Qt.AlignLeft | Qt.AlignVCenter)
        self.analysis_status_label.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred)

        header_layout.addWidget(app_logo)
        header_layout.addWidget(app_name_label)
        header_layout.addWidget(self.analysis_status_label)

        self.volume_button = QPushButton()
        self.volume_button.setIcon(self.style().standardIcon(QStyle.SP_MediaVolume))
        self.volume_button.setObjectName("iconButton")
        self.volume_button.setIconSize(QSize(20, 20))
        self.volume_button.setFixedSize(36, 36)

        self.toggle_button = QPushButton("Start Recording") 
        self.toggle_button.setObjectName("stopRecordingButton")
        self.toggle_button.clicked.connect(self.toggle_processing)
        self.toggle_button.setEnabled(False) 

        self.close_button = QPushButton()
        self.close_button.setIcon(self.style().standardIcon(QStyle.SP_DialogCloseButton))
        self.close_button.setObjectName("iconButton")
        self.close_button.setIconSize(QSize(20,20))
        self.close_button.setFixedSize(36,36)
        self.close_button.clicked.connect(self.close)

        header_layout.addWidget(self.volume_button)
        header_layout.addWidget(self.toggle_button)
        header_layout.addWidget(self.close_button)

        main_layout.addWidget(header_widget)

        content_splitter = QSplitter(Qt.Horizontal)
        content_splitter.setContentsMargins(10, 0, 10, 10) 

        self.tab_widget = QTabWidget()
        self.tab_widget.setObjectName("mainTabWidget")
        content_splitter.addWidget(self.tab_widget)

        self.overview_tab_page = self._create_overview_tab()
        self.story_elements_tab_page = self._create_story_elements_tab()
        self.live_transcript_tab_page = self._create_live_transcript_tab()
        self.ai_chat_tab_page = self._create_ai_chat_tab()
        self.llm_log_tab_page = self._create_llm_log_tab() 

        self.tab_widget.addTab(self.overview_tab_page, "Overview")
        self.tab_widget.addTab(self.story_elements_tab_page, "Story Elements")
        self.tab_widget.addTab(self.live_transcript_tab_page, "Live Transcript")
        self.tab_widget.addTab(self.ai_chat_tab_page, "AI Chat")
        self.tab_widget.addTab(self.llm_log_tab_page, "LLM Log")

        right_panel = QWidget()
        right_panel.setObjectName("rightPanel")
        right_layout = QVBoxLayout(right_panel)
        right_layout.setContentsMargins(15, 15, 15, 15)
        right_layout.setSpacing(10)

        cheat_sheet_label = QLabel("Narrative Cheat Sheet")
        cheat_sheet_label.setObjectName("sectionTitle") 
        right_layout.addWidget(cheat_sheet_label)

        self.cheat_sheet_table = QTableWidget() 
        self.cheat_sheet_table.setColumnCount(6)
        self.cheat_sheet_table.setHorizontalHeaderLabels(["Name", "Type", "Description", "Base Score", "Mentions", "Current Score"])
        self.cheat_sheet_table.setEditTriggers(QTableWidget.NoEditTriggers)
        self.cheat_sheet_table.verticalHeader().setVisible(False)
        self.cheat_sheet_table.setAlternatingRowColors(True)
        self.cheat_sheet_table.setObjectName("cheatSheetTable") 
        right_layout.addWidget(self.cheat_sheet_table)

        self.cheat_sheet_column_widths = {
            0: 120,   # Name
            1: 100,   # Type
            2: 250,   # Description
            3: 80,    # Base Score
            4: 70,    # Mentions
            5: 100    # Current Score
        }
        for i, width in self.cheat_sheet_column_widths.items():
            self.cheat_sheet_table.setColumnWidth(i, width)

        self.cheat_sheet_table.horizontalHeader().sectionResized.connect(self._on_cheat_sheet_column_resized)

        content_splitter.addWidget(right_panel)
        content_splitter.setSizes([800, 400]) 
        main_layout.addWidget(content_splitter)

    def _on_cheat_sheet_column_resized(self, logicalIndex, oldSize, newSize):
        """Slot to remember user-resized column widths."""
        self.cheat_sheet_column_widths[logicalIndex] = newSize

    def _create_overview_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        title_label = QLabel("Overview")
        title_label.setObjectName("sectionTitle")
        tab_layout.addWidget(title_label)

        metrics_layout = QHBoxLayout()
        metrics_layout.setSpacing(15)
        
        self.characters_count_label = QLabel("0") 
        self.locations_count_label = QLabel("0") 
        self.transcript_lines_count_label = QLabel("0")
        self.total_elements_count_label = QLabel("0") 

        metrics_layout.addWidget(self._create_summary_card(self.characters_count_label, "Characters", QStyle.SP_MessageBoxInformation)) 
        metrics_layout.addWidget(self._create_summary_card(self.locations_count_label, "Locations", QStyle.SP_DirIcon)) 
        metrics_layout.addWidget(self._create_summary_card(self.transcript_lines_count_label, "Transcript Lines", QStyle.SP_FileIcon)) 
        metrics_layout.addWidget(self._create_summary_card(self.total_elements_count_label, "Total Elements", QStyle.SP_MessageBoxQuestion)) 
        tab_layout.addLayout(metrics_layout)

        recent_activity_widget = QFrame()
        recent_activity_widget.setProperty("class", "contentCard")
        recent_activity_layout = QVBoxLayout(recent_activity_widget)
        recent_activity_layout.setContentsMargins(15,15,15,15)
        recent_activity_layout.setSpacing(10)

        recent_activity_layout.addWidget(QLabel("Recent Activity"))
        self.recent_activity_display = QTextEdit()
        self.recent_activity_display.setReadOnly(True)
        self.recent_activity_display.setPlaceholderText("Latest story elements and transcript updates...")
        self.recent_activity_display.setFixedHeight(150)
        recent_activity_layout.addWidget(self.recent_activity_display)
        tab_layout.addWidget(recent_activity_widget)

        key_characters_widget = QFrame()
        key_characters_widget.setProperty("class", "contentCard")
        key_characters_layout = QVBoxLayout(key_characters_widget)
        key_characters_layout.setContentsMargins(15,15,15,15)
        key_characters_layout.setSpacing(10)
        
        key_characters_layout.addWidget(QLabel("Key Characters"))
        self.key_characters_container_layout = QVBoxLayout()
        self.key_characters_container_layout.setContentsMargins(0,0,0,0)
        self.key_characters_container_layout.setSpacing(8)
        
        self.key_characters_container_layout.addStretch() 

        key_characters_layout.addLayout(self.key_characters_container_layout)
        tab_layout.addWidget(key_characters_widget)

        tab_layout.addStretch() 
        return tab_page

    def _create_summary_card(self, count_label_ref, label_text, icon_style_hint):
        card = QFrame()
        card.setProperty("class", "contentCard")
        card.setFixedSize(160, 120)
        card_layout = QVBoxLayout(card)
        card_layout.setAlignment(Qt.AlignCenter)
        card_layout.setContentsMargins(10, 10, 10, 10)
        card_layout.setSpacing(5)

        icon_label = QLabel()
        icon_label.setPixmap(self.style().standardIcon(icon_style_hint).pixmap(QSize(30, 30)))
        card_layout.addWidget(icon_label, alignment=Qt.AlignCenter)

        count_label_ref.setStyleSheet("font-size: 28px; font-weight: bold; color: #6a0dad;")
        card_layout.addWidget(count_label_ref, alignment=Qt.AlignCenter)

        text_label = QLabel(label_text)
        text_label.setStyleSheet("font-size: 13px; color: #555555; font-weight: 500;")
        card_layout.addWidget(text_label, alignment=Qt.AlignCenter)
        return card

    def _create_story_elements_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        title_label = QLabel("Story Elements")
        title_label.setObjectName("sectionTitle")
        tab_layout.addWidget(title_label)

        scroll_area = QScrollArea()
        scroll_area.setWidgetResizable(True)
        scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        scroll_area.setFrameShape(QFrame.NoFrame)

        self.story_elements_content_widget = QWidget()
        self.story_elements_container_layout = QVBoxLayout(self.story_elements_content_widget)
        self.story_elements_container_layout.setContentsMargins(0, 0, 0, 0)
        self.story_elements_container_layout.setSpacing(10)

        self.story_elements_container_layout.addStretch() 

        scroll_area.setWidget(self.story_elements_content_widget)
        tab_layout.addWidget(scroll_area)
        
        return tab_page
    
    def _create_entity_card(self, entity_data, first_mentioned_time="00:00:00"):
        card = QFrame()
        card.setProperty("class", "storyElementCard")

        card_layout = QHBoxLayout(card)
        card_layout.setContentsMargins(0, 0, 0, 0) 
        card_layout.setSpacing(5) 

        icon_label = QLabel()
        if entity_data["type"] == "Characters":
            icon_label.setPixmap(self.style().standardIcon(QStyle.SP_MessageBoxInformation).pixmap(QSize(16, 16)))
        elif entity_data["type"] == "Locations":
            icon_label.setPixmap(self.style().standardIcon(QStyle.SP_DirIcon).pixmap(QSize(16, 16)))
        elif entity_data["type"] == "Organizations":
            icon_label.setPixmap(self.style().standardIcon(QStyle.SP_DesktopIcon).pixmap(QSize(16, 16)))
        else: 
            icon_label.setPixmap(self.style().standardIcon(QStyle.SP_FileIcon).pixmap(QSize(16, 16)))
        card_layout.addWidget(icon_label)

        element_name = QLabel(entity_data["name"])
        element_name.setProperty("property", "nameLabel") 
        card_layout.addWidget(element_name)
        
        category_tag = QLabel(entity_data["type"])
        category_tag.setProperty("class", "categoryTag") 
        category_tag.setObjectName(f"categoryTag-{entity_data['type'].replace(' ', '')}")
        card_layout.addWidget(category_tag)

        separator = QLabel("—") 
        separator.setStyleSheet("color: #aaaaaa; margin: 0 5px;")
        card_layout.addWidget(separator)

        description_text = entity_data.get("description", "No description available")
        max_desc_length = 80 
        if len(description_text) > max_desc_length:
            description_text = description_text[:max_desc_length].strip() + "..."
        
        description = QLabel(description_text)
        description.setProperty("property", "descriptionLabel") 
        description.setWordWrap(False) 
        description.setTextFormat(Qt.PlainText) 
        description.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred) 
        card_layout.addWidget(description)

        card_layout.addStretch() 

        first_mentioned = QLabel(f"First mentioned: {first_mentioned_time}")
        first_mentioned.setProperty("property", "timeLabel") 
        card_layout.addWidget(first_mentioned)
        
        return card

    def _create_live_transcript_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        header_layout = QHBoxLayout()
        mic_icon = QLabel()
        mic_icon.setPixmap(self.style().standardIcon(QStyle.SP_MediaVolume).pixmap(QSize(24, 24)))
        header_layout.addWidget(mic_icon)
        
        title_label = QLabel("Live Transcript")
        title_label.setObjectName("sectionTitle")
        header_layout.addWidget(title_label)

        self.processing_tag = QLabel("Processing")
        self.processing_tag.setProperty("class", "processingTag")
        self.processing_tag.setVisible(False)
        header_layout.addWidget(self.processing_tag)
        header_layout.addStretch()
        tab_layout.addLayout(header_layout)

        self.transcript_display = QTextEdit()
        self.transcript_display.setReadOnly(True)
        self.transcript_display.setPlaceholderText("Live transcription will appear here...")
        tab_layout.addWidget(self.transcript_display)
        
        return tab_page

    def _create_ai_chat_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        header_layout = QHBoxLayout()
        ai_icon = QLabel()
        ai_icon.setPixmap(self.style().standardIcon(QStyle.SP_MessageBoxQuestion).pixmap(QSize(24, 24)))
        header_layout.addWidget(ai_icon)
        
        title_label = QLabel("AI Story Assistant")
        title_label.setObjectName("sectionTitle")
        header_layout.addWidget(title_label)
        header_layout.addStretch()
        tab_layout.addLayout(header_layout)

        self.chat_display = QTextEdit()
        self.chat_display.setReadOnly(True)
        self.chat_display.setPlaceholderText("Chat with the AI about the story...")
        tab_layout.addWidget(self.chat_display)

        chat_input_container = QFrame()
        chat_input_container.setObjectName("chatInputContainer")
        chat_input_layout = QHBoxLayout(chat_input_container)
        chat_input_layout.setContentsMargins(0, 0, 0, 0)
        chat_input_layout.setSpacing(0)

        self.chat_input = QLineEdit()
        self.chat_input.setPlaceholderText("Ask about characters, plot, or story elements...")
        self.chat_input.returnPressed.connect(self.send_chat_query)
        chat_input_layout.addWidget(self.chat_input)

        send_button = QPushButton()
        send_button.setIcon(self.style().standardIcon(QStyle.SP_ArrowRight))
        send_button.setIconSize(QSize(20, 20))
        send_button.setFixedSize(40, 40)
        send_button.setObjectName("sendButton")
        send_button.clicked.connect(self.send_chat_query)
        chat_input_layout.addWidget(send_button)

        tab_layout.addWidget(chat_input_container)
        return tab_page

    def _create_llm_log_tab(self):
        tab_page = QWidget()
        tab_layout = QVBoxLayout(tab_page)
        tab_layout.setContentsMargins(20, 20, 20, 20)
        tab_layout.setSpacing(15)

        title_label = QLabel("LLM Processing Log")
        title_label.setObjectName("sectionTitle")
        tab_layout.addWidget(title_label)

        self.llm_log_tabs = QTabWidget()
        self.llm_log_tabs.setObjectName("llmLogSubTabs")

        raw_log_tab = QWidget()
        raw_log_layout = QVBoxLayout(raw_log_tab)
        self.llm_raw_log_display = QTextEdit()
        self.llm_raw_log_display.setReadOnly(True)
        self.llm_raw_log_display.setPlaceholderText("Raw LLM prompts and responses will appear here...")
        raw_log_layout.addWidget(self.llm_raw_log_display)
        self.llm_log_tabs.addTab(raw_log_tab, "Raw Interactions")

        parsed_entities_tab = QWidget()
        parsed_entities_layout = QVBoxLayout(parsed_entities_tab)
        self.llm_parsed_entities_table = QTableWidget()
        self.llm_parsed_entities_table.setColumnCount(4) 
        self.llm_parsed_entities_table.setHorizontalHeaderLabels(["Name", "Type", "Description", "Base Score"])
        self.llm_parsed_entities_table.setEditTriggers(QTableWidget.NoEditTriggers)
        self.llm_parsed_entities_table.verticalHeader().setVisible(False)
        self.llm_parsed_entities_table.setAlternatingRowColors(True)
        self.llm_parsed_entities_table.horizontalHeader().setStretchLastSection(True)
        self.llm_parsed_entities_table.setObjectName("llmParsedEntitiesTable")
        parsed_entities_layout.addWidget(self.llm_parsed_entities_table)
        self.llm_log_tabs.addTab(parsed_entities_tab, "Parsed Entities (Latest)")

        errors_warnings_tab = QWidget()
        errors_warnings_layout = QVBoxLayout(errors_warnings_tab)
        self.llm_error_warnings_display = QTextEdit()
        self.llm_error_warnings_display.setReadOnly(True)
        self.llm_error_warnings_display.setPlaceholderText("LLM-related errors and warnings will appear here...")
        self.llm_error_warnings_display.setStyleSheet("QTextEdit { color: #8B0000; }") 
        errors_warnings_layout.addWidget(self.llm_error_warnings_display)
        self.llm_log_tabs.addTab(errors_warnings_tab, "Errors & Warnings")

        tab_layout.addWidget(self.llm_log_tabs)
        return tab_page

    def _setup_output_directory(self, base_title):
        """
        Creates a unique output directory for the current session.
        Handles existing directories by appending a number.
        Sets all file paths.
        """
        base_output_folder = "output"
        os.makedirs(base_output_folder, exist_ok=True)

        # Sanitize title for directory name
        safe_title = "".join(c for c in base_title if c.isalnum() or c in (' ', '_', '-')).rstrip()
        safe_title = safe_title.replace(' ', '_').replace('-', '_')
        if not safe_title:
            safe_title = "Untitled_Content"

        output_path_candidate = os.path.join(base_output_folder, safe_title)
        counter = 1
        while os.path.exists(output_path_candidate):
            output_path_candidate = os.path.join(base_output_folder, f"{safe_title}_{counter}")
            counter += 1
        
        try:
            os.makedirs(output_path_candidate)
            self.output_dir = output_path_candidate
            self.transcript_file_path = os.path.join(self.output_dir, "transcript.txt")
            self.cheat_sheet_file_path = os.path.join(self.output_dir, "narrative_cheat_sheet.json")
            self.alias_map_file_path = os.path.join(self.output_dir, "aliases_map.json")
            self.raw_llm_log_file_path = os.path.join(self.output_dir, "llm_raw_interactions.txt") # Changed to .txt
            self.error_warnings_file_path = os.path.join(self.output_dir, "errors_and_warnings.txt") # Changed to .txt
            self.update_llm_log_tabs({"type": "status", "message": f"Output directory created: {self.output_dir}"})
        except Exception as e:
            self.update_llm_log_tabs({"type": "error", "message": f"Failed to create output directory {output_path_candidate}: {e}"})
            self.output_dir = None # Clear paths if directory creation failed

    def _write_transcript_line(self, text):
        if not self.transcript_file_path:
            return
        try:
            with open(self.transcript_file_path, 'a', encoding='utf-8') as f:
                f.write(text + "\n")
        except Exception as e:
            self.update_llm_log_tabs({"type": "error", "message": f"Failed to write transcript to file: {e}"})

    def _write_cheat_sheet(self, entities_data):
        if not self.cheat_sheet_file_path:
            return
        try:
            with open(self.cheat_sheet_file_path, 'w', encoding='utf-8') as f:
                json.dump(entities_data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.update_llm_log_tabs({"type": "error", "message": f"Failed to write cheat sheet to file: {e}"})

    def _write_alias_map(self, alias_map_data):
        if not self.alias_map_file_path:
            return
        try:
            with open(self.alias_map_file_path, 'w', encoding='utf-8') as f:
                json.dump(alias_map_data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.update_llm_log_tabs({"type": "error", "message": f"Failed to write alias map to file: {e}"})

    def _write_llm_raw_log_line(self, timestamp, log_type, message, data):
        if not self.raw_llm_log_file_path:
            return
        try:
            with open(self.raw_llm_log_file_path, 'a', encoding='utf-8') as f:
                f.write(f"{timestamp} [{log_type.upper()}]: {message}\n")
                if data:
                    if isinstance(data, dict) or isinstance(data, list):
                        f.write(json.dumps(data, indent=2, ensure_ascii=False) + "\n")
                    else:
                        f.write(str(data) + "\n")
                f.write("---\n") # Separator for readability
        except Exception as e:
            self.update_llm_log_tabs({"type": "error", "message": f"Failed to write raw LLM log to file: {e}"})

    def _write_error_warning_log_line(self, timestamp, log_type, message, data):
        if not self.error_warnings_file_path:
            return
        try:
            with open(self.error_warnings_file_path, 'a', encoding='utf-8') as f:
                error_message = f"{timestamp} [{log_type.upper()}]: {message}"
                if data:
                    if isinstance(data, dict) or isinstance(data, list):
                        error_message += f" (Data: {json.dumps(data, ensure_ascii=False)})"
                    else:
                        error_message += f" (Data: {str(data)})"
                f.write(error_message + "\n")
        except Exception as e:
            self.update_llm_log_tabs({"type": "error", "message": f"Failed to write error/warning log to file: {e}"})


    def get_content_title_and_context(self):
        dialog = QInputDialog(self)
        dialog.setWindowTitle("Content Title")
        dialog.setLabelText("Please enter the title of the content you are watching:")
        dialog.setTextEchoMode(QLineEdit.Normal)
        dialog.setTextValue("All Season 1 Lore from The Outlast Trials") 
        dialog.setWindowFlags(dialog.windowFlags() | Qt.WindowStaysOnTopHint)
        
        ok = dialog.exec_()
        title = dialog.textValue()
        
        if ok and title:
            self.content_title = title.strip()
            self.analysis_status_label.setText(f"Analyzing: [FULL] {self.content_title}")
            
            # Setup output directory immediately after getting title
            self._setup_output_directory(self.content_title)

            if not self.content_title:
                self.update_llm_log_tabs({"type": "error", "message": "Empty content title provided. LLM will operate without specific external context."})
                self.llm_thread.set_external_context("No external context provided by user.")
                self.init_chat_thread()
                self.toggle_button.setEnabled(True)
                return

            self.llm_thread.set_content_title(self.content_title)
            self.update_llm_log_tabs({"type": "status", "message": f"Searching for external context for: '{self.content_title}'..."})
            self.web_search_thread = WebSearchThread(self.content_title)
            self.web_search_thread.context_ready.connect(self.set_llm_external_context)
            self.web_search_thread.error_signal.connect(lambda msg: self.update_llm_log_tabs({"type": "error", "message": msg})) 
            self.web_search_thread.start()
        else:
            self.update_llm_log_tabs({"type": "status", "message": "No content title provided. LLM will operate without specific external context."})
            self.llm_thread.set_external_context("No external context provided by user.")
            self.init_chat_thread()
            self.toggle_button.setEnabled(True)

    def set_llm_external_context(self, context):
        self.llm_thread.set_external_context(context)
        self.update_llm_log_tabs({"type": "status", "message": f"External context loaded for LLM (showing first 500 chars):\n<pre>{context[:500]}...</pre>"})
        if len(context) > 500:
            self.update_llm_log_tabs({"type": "status", "message": f"...\n(Full context is {len(context)} characters long)"})
        self.init_chat_thread()
        self.toggle_button.setEnabled(True)
        self.toggle_button.setText("Start Recording")
        self.update_llm_log_tabs({"type": "status", "message": "You can now click 'Start Recording' to begin audio processing and entity extraction."})

    def init_chat_thread(self):
        if self.chat_thread and self.chat_thread.isRunning():
            self.chat_thread.stop()
            self.chat_thread.wait()

        self.chat_thread = ChatThread(
            transcript_getter=self.llm_thread.get_transcriptions,
            entities_getter=self.llm_thread.get_entities,
            content_title=self.content_title,
            external_context=self.llm_thread.external_context
        )
        self.chat_thread.chat_response.connect(self.display_chat_response)
        self.chat_thread.chat_log.connect(self.update_llm_log_tabs) 
        self.chat_thread.start()
        self.update_llm_log_tabs({"type": "status", "message": "Chat thread initialized."})

    def toggle_processing(self):
        if self.toggle_button.text() == "Start Recording":
            self.update_llm_log_tabs({"type": "debug", "message": "Starting AudioCaptureThread..."})
            self.audio_thread.start()
            self.update_llm_log_tabs({"type": "debug", "message": "Starting TranscriptionThread..."})
            self.transcription_thread.start()
            self.update_llm_log_tabs({"type": "debug", "message": "Starting LLMThread..."})
            self.llm_thread.start()

            self.toggle_button.setText("Stop Recording")
            self.processing_tag.setVisible(True)
            self.update_llm_log_tabs({"type": "status", "message": "Processing started."})
        else:
            self.stop_processing()
            self.toggle_button.setText("Start Recording")
            self.processing_tag.setVisible(False)
            self.update_llm_log_tabs({"type": "status", "message": "Processing stopped."})

    def stop_processing(self):
        self.update_llm_log_tabs({"type": "debug", "message": "Stopping LLMThread..."})
        self.llm_thread.stop()
        self.llm_thread.wait(5000)
        if self.llm_thread.isRunning():
            self.update_llm_log_tabs({"type": "warning", "message": "LLMThread did not stop gracefully."})

        self.update_llm_log_tabs({"type": "debug", "message": "Stopping TranscriptionThread..."})
        self.transcription_thread.stop()
        self.transcription_thread.wait(5000)
        if self.transcription_thread.isRunning():
            self.update_llm_log_tabs({"type": "warning", "message": "TranscriptionThread did not stop gracefully."})

        self.update_llm_log_tabs({"type": "debug", "message": "Stopping AudioCaptureThread..."})
        self.audio_thread.stop()
        self.audio_thread.wait(5000)
        if self.audio_thread.isRunning():
            self.update_llm_log_tabs({"type": "warning", "message": "AudioCaptureThread did not stop gracefully."})
        
        self.update_llm_log_tabs({"type": "status", "message": "All processing threads requested to stop."})

    def handle_transcription(self, text):
        if self.transcript_display:
            self.transcript_display.append(text)
            self.transcript_display.verticalScrollBar().setValue(self.transcript_display.verticalScrollBar().maximum())
            current_lines = int(self.transcript_lines_count_label.text())
            self.transcript_lines_count_label.setText(str(current_lines + 1))

        self.llm_thread.add_transcription(text) 
        self.recent_activity_display.append(f"Transcript: {text[:80].strip()}...")
        self.recent_activity_display.verticalScrollBar().setValue(self.recent_activity_display.verticalScrollBar().maximum())
        
        self._write_transcript_line(text)

    def update_entity_displays(self, all_entities):
        for e in all_entities:
            e["current_importance_score"] = e.get("base_importance_score", 0) + e.get("mention_count", 0)

        scores = [e["current_importance_score"] for e in all_entities]
        
        display_threshold = self.minimum_display_score 
        
        if scores:
            median_score = np.median(scores)
            display_threshold = max(self.minimum_display_score, median_score)
            self.update_llm_log_tabs({"type": "debug", "message": f"Calculated median importance score: {median_score:.2f}. Display threshold set to: {display_threshold:.2f}"})
        else:
            self.update_llm_log_tabs({"type": "debug", "message": "No entities yet to calculate median score. Display threshold is default minimum."})

        filtered_for_display_tabs = [e for e in all_entities if e["current_importance_score"] >= display_threshold]
        filtered_for_display_tabs.sort(key=lambda e: (e["type"], -e["current_importance_score"], e["name"].lower()))

        # Clear and re-populate story elements
        # Using the robust clear_layout_recursively helper
        self.clear_layout_recursively(self.story_elements_container_layout)
        
        # Then add new widgets
        for entity in filtered_for_display_tabs:
            first_mentioned_time_seconds = entity.get("first_mentioned_idx", 0) * TRANSCRIPT_CHUNK_DURATION_SECONDS
            minutes = int(first_mentioned_time_seconds // 60)
            seconds = int(first_mentioned_time_seconds % 60)
            time_str = f"{minutes:02d}:{seconds:02d}"

            entity_card = self._create_entity_card(entity, time_str) 
            self.story_elements_container_layout.addWidget(entity_card)
        self.story_elements_container_layout.addStretch() # Add stretch back after clearing all and re-adding


        # Clear and re-populate key characters
        # Using the robust clear_layout_recursively helper
        self.clear_layout_recursively(self.key_characters_container_layout)

        key_characters = [e for e in filtered_for_display_tabs if e["type"] == "Characters"]
        key_characters.sort(key=lambda e: -e["current_importance_score"]) 

        for char_entity in key_characters:
            first_mentioned_time_seconds = char_entity.get("first_mentioned_idx", 0) * TRANSCRIPT_CHUNK_DURATION_SECONDS
            minutes = int(first_mentioned_time_seconds // 60)
            seconds = int(first_mentioned_time_seconds % 60)
            time_str = f"{minutes:02d}:{seconds:02d}"

            char_card = self._create_entity_card(char_entity, time_str)
            self.key_characters_container_layout.addWidget(char_card)
        self.key_characters_container_layout.addStretch() # Add stretch back after clearing all and re-adding

        self.cheat_sheet_table.setRowCount(len(all_entities))
        
        for col_idx in range(self.cheat_sheet_table.columnCount()):
            if col_idx in self.cheat_sheet_column_widths:
                self.cheat_sheet_table.setColumnWidth(col_idx, self.cheat_sheet_column_widths[col_idx])

        all_entities_sorted_for_table = sorted(all_entities, key=lambda e: (e["type"], e["name"].lower()))

        for i, entity in enumerate(all_entities_sorted_for_table):
            self.cheat_sheet_table.setItem(i, 0, QTableWidgetItem(entity["name"]))
            self.cheat_sheet_table.setItem(i, 1, QTableWidgetItem(entity["type"]))
            description_item = QTableWidgetItem(entity.get("description", "No description available"))
            self.cheat_sheet_table.setItem(i, 2, description_item)
            self.cheat_sheet_table.setItem(i, 3, QTableWidgetItem(str(entity.get("base_importance_score", 0)))) 
            self.cheat_sheet_table.setItem(i, 4, QTableWidgetItem(str(entity.get("mention_count", 0))))      
            self.cheat_sheet_table.setItem(i, 5, QTableWidgetItem(str(entity.get("current_importance_score", 0)))) 
            
        char_count = sum(1 for e in filtered_for_display_tabs if e["type"] == "Characters")
        loc_count = sum(1 for e in filtered_for_display_tabs if e["type"] == "Locations")
        total_elements_displayed = len(filtered_for_display_tabs)

        self.characters_count_label.setText(str(char_count))
        self.locations_count_label.setText(str(loc_count))
        self.total_elements_count_label.setText(str(total_elements_displayed))
        
        self.recent_activity_display.append(f"Entities updated: {len(all_entities)} total found, {total_elements_displayed} displayed (>= threshold).")
        self.recent_activity_display.verticalScrollBar().setValue(self.recent_activity_display.verticalScrollBar().maximum())

        # Real-time saving to files
        self._write_cheat_sheet(all_entities)
        self._write_alias_map(self.llm_thread.get_alias_map())

    def clear_layout_recursively(self, layout):
        if layout is None:
            return
        # Iterate in reverse to safely remove items
        # Taking items from index 0 repeatedly can be inefficient; iterating in reverse is better.
        for i in reversed(range(layout.count())):
            item = layout.takeAt(i)
            if item.widget() is not None:
                # If the item is a widget, remove it from the layout and delete it
                item.widget().setParent(None)
                item.widget().deleteLater()
            elif item.layout() is not None:
                # If the item is a nested layout, clear it recursively
                self.clear_layout_recursively(item.layout())
            else:
                # Handle spacer items or other types without widget/layout
                del item


    def update_llm_log_tabs(self, log_data):
        timestamp = datetime.now().strftime("[%H:%M:%S]")
        log_type = log_data.get("type", "unknown")
        message = log_data.get("message", "No message provided")
        data = log_data.get("data")

        # Update UI display in LLM Log tab
        formatted_message = f"<p style='margin-bottom: 5px;'>{timestamp} <b>[{log_type.upper()}]</b>: {message}</p>"
        if log_type == "prompt":
            formatted_message += f"<pre style='background-color: #e6e6fa; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "raw_response":
            formatted_message += f"<pre style='background-color: #f0f0f0; padding: 10px; border-radius: 5px;'><code>{data}</code></pre>"
        elif log_type == "parsed_entities":
            formatted_message += f"<pre style='background-color: #f0f8ff; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "chat_prompt": 
            formatted_message += f"<pre style='background-color: #e0e7ff; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "chat_response": 
            formatted_message += f"<pre style='background-color: #f0f2f5; padding: 10px; border-radius: 5px;'><code>{data}</code></pre>"
        elif log_type == "error":
             formatted_message = f"<p style='color: #CC0000; margin-bottom: 5px;'>{timestamp} <b>[ERROR]</b>: {message}</p>"
             if data: 
                 formatted_message += f"<pre style='background-color: #ffe6e6; padding: 10px; border-radius: 5px; color: #CC0000;'><code>{data}</code></pre>"
        elif log_type == "warning":
            formatted_message = f"<p style='color: #FF8C00; margin-bottom: 5px;'>{timestamp} <b>[WARNING]</b>: {message}</p>"
            if data: 
                formatted_message += f"<pre style='background-color: #fff8e6; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "debug":
            formatted_message = f"<p style='color: #555555; margin-bottom: 5px;'>{timestamp} <b>[DEBUG]</b>: {message}</p>"
            if data:
                formatted_message += f"<pre style='background-color: #e0e0e0; padding: 10px; border-radius: 5px;'><code>{json.dumps(data, indent=2)}</code></pre>"
        elif log_type == "status": 
            formatted_message = f"<p style='color: #337ab7; margin-bottom: 5px;'>{timestamp} <b>[STATUS]</b>: {message}</p>"

        self.llm_raw_log_display.append(formatted_message)
        self.llm_raw_log_display.verticalScrollBar().setValue(self.llm_raw_log_display.verticalScrollBar().maximum())

        if log_type == "parsed_entities":
            self.llm_parsed_entities_table.setRowCount(len(data))
            for i, entity in enumerate(data):
                self.llm_parsed_entities_table.setItem(i, 0, QTableWidgetItem(entity.get("name", "")))
                self.llm_parsed_entities_table.setItem(i, 1, QTableWidgetItem(entity.get("type", "")))
                self.llm_parsed_entities_table.setItem(i, 2, QTableWidgetItem(entity.get("description", "")))
                self.llm_parsed_entities_table.setItem(i, 3, QTableWidgetItem(str(entity.get("base_importance_score", ""))))
            self.llm_parsed_entities_table.resizeColumnsToContents() 

        # Write to dedicated log files
        if log_type in ["prompt", "raw_response", "parsed_entities", "chat_prompt", "chat_response", "debug", "status"]:
            self._write_llm_raw_log_line(timestamp, log_type, message, data)
        elif log_type in ["error", "warning"]:
            self._write_error_warning_log_line(timestamp, log_type, message, data)
        
    def send_chat_query(self):
        query = self.chat_input.text().strip()
        if not query:
            return
        self.chat_display.append(f"<div style='color: #333333; margin-bottom: 5px; font-weight: bold;'>User:</div><div style='background-color: #e0e7ff; padding: 10px; border-radius: 8px; margin-bottom: 10px;'>{query}</div>")
        self.chat_thread.add_chat_query(query)
        self.chat_input.clear()
        self.chat_display.verticalScrollBar().setValue(self.chat_display.verticalScrollBar().maximum())

    def display_chat_response(self, response):
        self.chat_display.append(f"<div style='color: #6a0dad; margin-bottom: 5px; font-weight: bold;'>AI:</div><div style='background-color: #f0f2f5; padding: 10px; border-radius: 8px; margin-bottom: 10px;'>{response}</div>")
        self.chat_display.verticalScrollBar().setValue(self.chat_display.verticalScrollBar().maximum())

    def closeEvent(self, event):
        try:
            self.update_llm_log_tabs({"type": "status", "message": "Application closing. Initiating graceful shutdown of threads."})
            self.stop_processing() # Ensure core processing threads are stopped

            if self.chat_thread and self.chat_thread.isRunning():
                self.update_llm_log_tabs({"type": "debug", "message": "Stopping ChatThread..."})
                self.chat_thread.stop()
                self.chat_thread.wait(5000)
                if self.chat_thread.isRunning():
                    self.update_llm_log_tabs({"type": "warning", "message": "ChatThread did not stop gracefully."})

            if self.web_search_thread and self.web_search_thread.isRunning():
                self.update_llm_log_tabs({"type": "debug", "message": "Stopping WebSearchThread..."})
                self.web_search_thread.quit() 
                self.web_search_thread.wait(5000)
                if self.web_search_thread.isRunning():
                    self.update_llm_log_tabs({"type": "warning", "message": "WebSearchThread did not stop gracefully."})

            self.update_llm_log_tabs({"type": "status", "message": "All threads stopped. Application exiting."})
            event.accept()
        except Exception as e:
            error_msg = f"Error during cleanup: {e}"
            self.update_llm_log_tabs({"type": "error", "message": error_msg})
            print(error_msg, file=sys.stderr)
            event.accept()

==================================================
File: .\llm_prompts.py
==================================================
# LLM system prompt for entity extraction
base_system_prompt = """
You are an AI designed to extract narrative entities from transcribed audio for a "cheat sheet" to help users understand a story.

The content you are analyzing is titled: "{content_title}".
Here is some external context about the content to help you identify relevant entities and their significance:
---
{external_context}
---

Your primary goal is to identify *all identifiable* named entities that contribute to understanding the narrative. Be **exceptionally comprehensive** in your extraction. Do NOT filter entities based on your perceived importance for display; list all that are mentioned. The UI will handle dynamic filtering based on scores.

When identifying entities, be mindful of variations, nicknames, acronyms, or common misspellings. Always strive to use the most complete, formal, or specific name as the primary "name" for the entity.
Additionally, if you identify alternative names, nicknames, acronyms, or slightly different spellings that refer to the *same* entity, include them in an "aliases" array for that entity. For example, if "United States" is the primary name, "US" and "USA" would be aliases.

**CRITICAL INSTRUCTION**: ONLY extract entities that are **EXPLICITLY MENTIONED** in the provided "Current transcript snippet" or "Recent context." **DO NOT** include entities based on general knowledge, previous interactions, or general examples. If an entity is not mentioned, it must not be in your output.

**Entity Categorization (Use these EXACT names only):**
-   **Characters**: Specific named individuals, historical figures.
-   **Locations**: Places, settings, countries, cities.
-   **Organizations**: Groups, agencies, governments, corporations.
-   **Key Objects**: Distinctive items crucial to the plot or events.
-   **Concepts/Events**: Historical periods, specific significant dates/years (when representing an event), major conflicts, scientific advancements, named projects or programs.

- **Further Instructions for Entities:**
    - Ensure "name" is non-empty for valid entities.
    - If no identifiable entities are found in a snippet, return an empty "entities" list.
    - Maintain context from conversation history; if an entity was previously identified, you can re-mention it to update its score.
    - Provide brief descriptions (max 10 words), focusing on their narrative role or key characteristic.

- **Scoring Guidance for 'base_importance_score' (1-10):**
    - This score reflects your assessment of its inherent relevance and criticality to the overall narrative, plot progression, or world-building, *re-evaluating its importance based on all context seen so far*.
    -   **Characters, Locations, Organizations, Key Objects**: These generally hold more concrete and direct narrative weight. Assign a score typically in the range of **5-10**. A score of 10 indicates a central, foundational, or highly impactful entity.
    -   **Concepts/Events**: These can vary greatly in their direct impact. Assign a score typically in the range of **1-7**. A higher score (6-7) implies a major plot event or a fundamental concept crucial to the story's core themes. A lower score (1-5) might be for more general themes or events that are less pivotal.
    - Aim for a nuanced understanding: If an entity is frequently mentioned but isn't inherently narratively significant (e.g., a common object that isn't a 'Key Object'), its 'base_importance_score' should remain modest. If it's rarely mentioned but critically impacts the plot (e.g., a twist event, a hidden MacGuffin), its 'base_importance_score' should be high.
"""

==================================================
File: .\main.py
==================================================
import sys
from PyQt5.QtWidgets import QApplication
from frontend.main_window import NarrativeNavigator

if __name__ == "__main__":
    app = QApplication(sys.argv)

    # Apply QSS stylesheet
    try:
        with open('style.qss', 'r') as f:
            app.setStyleSheet(f.read())
    except FileNotFoundError:
        print("Warning: 'style.qss' not found. UI will not be styled.", file=sys.stderr)
    except Exception as e:
        print(f"Error loading stylesheet: {e}", file=sys.stderr)

    window = NarrativeNavigator()
    window.show()
    sys.exit(app.exec_())

==================================================
File: .\style.qss
==================================================
/* General App Styling */
QWidget {
    font-family: "Segoe UI", "Helvetica Neue", Arial, sans-serif; /* Modern font */
    font-size: 14px;
    color: #333333; /* Dark grey text */
    background-color: #f0f2f5; /* Light background for general widgets */
}

/* Main Window background */
QMainWindow {
    background-color: #f0f2f5;
}

/* Header Bar */
#headerWidget { /* Use setObjectName("headerWidget") on your header QWidget */
    background-color: #ffffff;
    border-bottom: 1px solid #e0e0e0;
    padding: 10px 20px;
}
#appNameLabel { /* For the "Narrative Navigator" QLabel */
    color: #6a0dad; /* Purple accent */
    font-size: 20px;
    font-weight: bold;
}
#analysisStatusLabel { /* For the "Analyzing..." QLabel */
    color: #555555;
    font-size: 14px;
    margin-left: 10px;
}

/* Buttons in Header */
QPushButton {
    background-color: #e0e0e0; /* Default button background */
    color: #333333;
    border: none;
    border-radius: 15px;
    padding: 8px 15px;
    font-weight: 500;
    min-width: 80px; /* Ensure a minimum width for text buttons */
}
QPushButton:hover {
    background-color: #d0d0d0;
}
QPushButton:pressed {
    background-color: #c0c0c0;
}

QPushButton#stopRecordingButton { /* Specific style for stop button */
    background-color: #e74c3c; /* Red */
    color: white;
    font-weight: bold;
}
QPushButton#stopRecordingButton:hover {
    background-color: #c0392b; /* Darker red on hover */
}
QPushButton#stopRecordingButton:pressed {
    background-color: #a02a1d;
}

/* Icon-only buttons */
QPushButton#iconButton {
    background-color: transparent;
    border: none;
    border-radius: 18px; /* Half of fixed size for perfect circle */
    padding: 0;
    margin: 0;
}
QPushButton#iconButton:hover {
    background-color: #e9ecef;
}
QPushButton#iconButton:pressed {
    background-color: #dcdcdc;
}

/* Tab Widget Navigation */
QTabWidget::pane { /* The content area of the tab widget */
    border: 1px solid #dcdcdc;
    border-top-left-radius: 12px;
    border-top-right-radius: 12px;
    border-bottom-left-radius: 12px;
    border-bottom-right-radius: 12px;
    background-color: #ffffff;
    margin: 10px; /* Margin around the whole content pane */
    padding: 0; /* Content padding handled by tab page layouts */
}

QTabBar {
    qproperty-drawBase: 0; /* Crucial to remove base line */
    background-color: transparent;
    padding: 0 10px; /* Padding for the tab bar itself */
}

QTabBar::tab {
    background: #f0f2f5; /* Background for unselected tabs */
    border: 1px solid #dcdcdc;
    border-top-left-radius: 8px; /* Rounded corners for the tabs */
    border-top-right-radius: 8px;
    padding: 10px 20px;
    margin-right: 2px; /* Space between tabs */
    color: #555555;
    font-weight: 500;
    min-width: 100px; /* Ensure consistent tab width */
    text-align: center;
}

QTabBar::tab:selected {
    background: #ffffff; /* White background for selected tab */
    border-color: #dcdcdc;
    border-bottom-color: transparent; /* Makes it look connected to the content */
    color: #6a0dad; /* Purple text for selected tab */
    font-weight: bold;
    margin-top: -1px; /* Slightly raise selected tab to overlap pane border */
}

QTabBar::tab:hover:!selected { /* Hover effect for unselected tabs */
    background: #e9ecef;
}

/* Section Titles within tabs */
QLabel#sectionTitle {
    font-size: 20px;
    font-weight: bold;
    color: #333333;
    margin-bottom: 15px; /* Space below titles */
}

/* General Content Cards (Applied via setProperty("class", "contentCard")) */
QFrame.contentCard {
    background-color: #ffffff;
    border: 1px solid #e0e0e0;
    border-radius: 8px;
    padding: 15px;
}

/* Category Tags (e.g., "Characters", "Locations", "Processing") */
QLabel.categoryTag {
    background-color: #e0e7ff; /* Light purple */
    color: #4a148c; /* Darker purple text */
    border-radius: 10px;
    padding: 3px 8px;
    font-size: 11px;
    font-weight: bold;
    min-width: 60px;
    text-align: center;
}
QLabel.processingTag { /* Green for "Processing" */
    background-color: #d4edda;
    color: #155724;
    border-radius: 10px;
    padding: 3px 8px;
    font-size: 11px;
    font-weight: bold;
    min-width: 60px;
    text-align: center;
}

/* Text Edits & Line Edits */
QTextEdit, QLineEdit {
    border: 1px solid #dcdcdc;
    border-radius: 8px;
    padding: 10px;
    background-color: #ffffff;
    selection-background-color: #e0e7ff; /* Light purple selection */
}

/* Chat Input specific styling */
QFrame#chatInputContainer { /* The container for the line edit and send button */
    border: 1px solid #dcdcdc;
    border-radius: 8px;
    background-color: #ffffff;
    padding: 0;
    margin-top: 10px; /* Space above the input container */
}
QFrame#chatInputContainer QLineEdit {
    border: none; /* Remove border from line edit inside container */
    padding: 10px;
    background-color: transparent;
}
QFrame#chatInputContainer QPushButton#sendButton { /* Send button inside container */
    background-color: #6a0dad; /* Purple */
    color: white;
    border-top-right-radius: 8px;
    border-bottom-right-radius: 8px;
    border-top-left-radius: 0;
    border-bottom-left-radius: 0;
    padding: 0;
    margin: 0;
    min-width: 40px; /* For the send icon */
}
QFrame#chatInputContainer QPushButton#sendButton:hover {
    background-color: #5a0ca0;
}
QFrame#chatInputContainer QPushButton#sendButton:pressed {
    background-color: #4a0b8f;
}

/* ScrollArea for story elements and other scrollable content */
QScrollArea {
    border: none;
    background-color: transparent;
}
QScrollArea > QWidget > QWidget { /* This targets the actual content widget inside the scroll area */
    background-color: transparent; /* Ensure content background is transparent */
}
QScrollBar:vertical {
    border: none;
    background: #f0f2f5; /* Scrollbar track background */
    width: 8px;
    margin: 0px 0px 0px 0px;
    border-radius: 4px;
}
QScrollBar::handle:vertical {
    background: #c0c0c0; /* Scrollbar handle color */
    border-radius: 4px;
    min-height: 20px;
}
QScrollBar::handle:vertical:hover {
    background: #a0a0a0;
}
QScrollBar::add-line:vertical, QScrollBar::sub-line:vertical {
    border: none;
    background: none;
}
QScrollBar::up-arrow:vertical, QScrollBar::down-arrow:vertical {
    background: none;
}
QScrollBar::add-page:vertical, QScrollBar::sub-page:vertical {
    background: none;
}
/* Table Widget (Cheat Sheet - right panel) */
QTableWidget#cheatSheetTable {
    border: 1px solid #dcdcdc;
    border-radius: 8px;
    background-color: #ffffff;
    gridline-color: #e0e0e0;
    selection-background-color: #e0e7ff; /* Light purple selection */
    selection-color: #333333;
    padding: 5px;
}
QHeaderView::section {
    background-color: #f8f9fa;
    padding: 8px;
    border: 1px solid #dcdcdc;
    font-weight: bold;
    color: #333333;
}
QTableWidget::item {
    padding: 8px;
    border-bottom: 1px solid #e0e0e0;
}
QTableWidget::item:selected {
    background-color: #e0e7ff;
}
/* For compact story element cards in the "Story Elements" tab */
QFrame.storyElementCard {
    background-color: #f9f9f9;
    border: 1px solid #eeeeee;
    border-radius: 5px;
    padding: 8px 12px; /* Vertical padding, horizontal padding */
}
QFrame.storyElementCard QLabel { /* General font size for labels inside compact card */
    font-size: 13px;
    color: #333333;
    /* Reset any specific padding/margins from general QLabel styles */
    margin: 0;
    padding: 0;
}
QFrame.storyElementCard QLabel[property="nameLabel"] { /* Specific style for the entity name */
    font-weight: bold;
    color: #333333;
    white-space: nowrap; /* Prevent wrapping for the name */
}
QFrame.storyElementCard QLabel[property="descriptionLabel"] { /* Specific style for the description */
    color: #555555;
    /* overflow: hidden and text-overflow: ellipsis are not supported in QSS */
    /* Text wrapping is controlled by the QLabel's wordWrap property in Python code */
}
QFrame.storyElementCard QLabel[property="timeLabel"] { /* Specific style for the timestamp */
    font-size: 10px;
    color: #777777;
    white-space: nowrap; /* Prevent wrapping for the timestamp */
    margin-left: 10px; /* Provide some space from description */
}
